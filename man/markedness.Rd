% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/class-markedness.R
\name{markedness}
\alias{markedness}
\alias{markedness.data.frame}
\alias{markedness_vec}
\title{Markedness}
\usage{
markedness(data, ...)

\method{markedness}{data.frame}(
  data,
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  case_weights = NULL,
  event_level = yardstick_event_level(),
  ...
)

markedness_vec(
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  case_weights = NULL,
  event_level = yardstick_event_level(),
  ...
)
}
\arguments{
\item{data}{Either a \code{data.frame} containing the columns specified by the
\code{truth} and \code{estimate} arguments, or a \code{table}/\code{matrix} where the true
class results should be in the columns of the table.}

\item{...}{Not currently used.}

\item{truth}{The column identifier for the true class results
(that is a \code{factor}). This should be an unquoted column name although
this argument is passed by expression and supports
\link[rlang:topic-inject]{quasiquotation} (you can unquote column
names). For \verb{_vec()} functions, a \code{factor} vector.}

\item{estimate}{The column identifier for the predicted class
results (that is also \code{factor}). As with \code{truth} this can be
specified different ways but the primary method is to use an
unquoted variable name. For \verb{_vec()} functions, a \code{factor} vector.}

\item{estimator}{One of: \code{"binary"}, \code{"macro"}, \code{"macro_weighted"},
or \code{"micro"} to specify the type of averaging to be done. \code{"binary"} is
only relevant for the two class case. The other three are general methods
for calculating multiclass metrics. The default will automatically choose
\code{"binary"} or \code{"macro"} based on \code{estimate}.}

\item{na_rm}{A \code{logical} value indicating whether \code{NA}
values should be stripped before the computation proceeds.}

\item{case_weights}{The optional column identifier for case weights.
This should be an unquoted column name that evaluates to a numeric column
in \code{data}. For \verb{_vec()} functions, a numeric vector,
\code{\link[hardhat:importance_weights]{hardhat::importance_weights()}}, or \code{\link[hardhat:frequency_weights]{hardhat::frequency_weights()}}.}

\item{event_level}{A single string. Either \code{"first"} or \code{"second"} to specify
which level of \code{truth} to consider as the "event". This argument is only
applicable when \code{estimator = "binary"}. The default uses an internal helper
that defaults to \code{"first"}.}
}
\value{
A \code{tibble} with columns \code{.metric}, \code{.estimator},
and \code{.estimate} and 1 row of values.

For grouped data frames, the number of rows returned will be the same as
the number of groups.

For \code{markedness_vec()}, a single \code{numeric} value (or \code{NA}).
}
\description{
Markedness is defined as:

\code{\link[=precision]{precision()}} + "inverse precision" - 1

where "inverse precision" is the proportion of true negatives among all
predicted negatives. A related metric is Informedness, see the Details
section for the relationship.
}
\details{
Suppose a 2x2 table with notation:

\tabular{rcc}{ \tab Reference \tab \cr Predicted \tab Positive \tab Negative
\cr Positive \tab A \tab B \cr Negative \tab C \tab D \cr }

The formulas used here are:

\deqn{\text{Precision} = \frac{A}{A + B}}

\deqn{\text{Inverse Precision} = \frac{D}{C + D}}

\deqn{\text{Markedness} = \text{Precision} + \text{Inverse Precision} - 1}

Markedness is a metric that should be maximized. The
output ranges from -1 to
1, with 1 indicating
perfect predictions.

Markedness is to the predicted condition (precision and inverse precision)
what Informedness (\code{\link[=j_index]{j_index()}}) is to the actual condition (sensitivity and
specificity).
}
\section{Relevant Level}{


There is no common convention on which factor level should
automatically be considered the "event" or "positive" result
when computing binary classification metrics. In \code{yardstick}, the default
is to use the \emph{first} level. To alter this, change the argument
\code{event_level} to \code{"second"} to consider the \emph{last} level of the factor the
level of interest. For multiclass extensions involving one-vs-all
comparisons (such as macro averaging), this option is ignored and
the "one" level is always the relevant result.
}

\section{Multiclass}{


Macro, micro, and macro-weighted averaging is available for this metric.
The default is to select macro averaging if a \code{truth} factor with more
than 2 levels is provided. Otherwise, a standard binary calculation is done.
See \code{vignette("multiclass", "yardstick")} for more information.
}

\examples{
# Two class
data("two_class_example")
markedness(two_class_example, truth, predicted)

# Multiclass
library(dplyr)
data(hpc_cv)

hpc_cv |>
  filter(Resample == "Fold01") |>
  markedness(obs, pred)

# Groups are respected
hpc_cv |>
  group_by(Resample) |>
  markedness(obs, pred)

# Weighted macro averaging
hpc_cv |>
  group_by(Resample) |>
  markedness(obs, pred, estimator = "macro_weighted")

# Vector version
markedness_vec(
  two_class_example$truth,
  two_class_example$predicted
)

# Making Class2 the "relevant" level
markedness_vec(
  two_class_example$truth,
  two_class_example$predicted,
  event_level = "second"
)
}
\references{
Powers, David M W (2011). "Evaluation: From Precision, Recall and F-Score to
ROC, Informedness, Markedness and Correlation". Journal of Machine Learning
Technologies. 2 (1): 37-63.
}
\seealso{
\link[=class-metrics]{All class metrics}

Other class metrics: 
\code{\link{accuracy}()},
\code{\link{bal_accuracy}()},
\code{\link{detection_prevalence}()},
\code{\link{f_meas}()},
\code{\link{fall_out}()},
\code{\link{j_index}()},
\code{\link{kap}()},
\code{\link{mcc}()},
\code{\link{miss_rate}()},
\code{\link{npv}()},
\code{\link{ppv}()},
\code{\link{precision}()},
\code{\link{recall}()},
\code{\link{roc_dist}()},
\code{\link{sens}()},
\code{\link{spec}()}
}
\concept{class metrics}
