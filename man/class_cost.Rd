% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prob-class_cost.R
\name{class_cost}
\alias{class_cost}
\alias{class_cost.data.frame}
\alias{class_cost_vec}
\title{Costs function for poor classification}
\usage{
class_cost(data, ...)

\method{class_cost}{data.frame}(data, truth, ..., na_rm = TRUE, costs = NULL)

class_cost_vec(truth, estimate, na_rm = TRUE, costs = NULL, ...)
}
\arguments{
\item{data}{A \code{data.frame} containing the \code{truth} and \code{estimate}
columns.}

\item{...}{A set of unquoted column names or one or more
\code{dplyr} selector functions to choose which variables contain the
class probabilities. If \code{truth} is binary, only 1 column should be selected.
Otherwise, there should be as many columns as factor levels of \code{truth}.}

\item{truth}{The column identifier for the true class results
(that is a \code{factor}). This should be an unquoted column name although
this argument is passed by expression and supports
\link[rlang:nse-force]{quasiquotation} (you can unquote column
names). For \verb{_vec()} functions, a \code{factor} vector.}

\item{na_rm}{A \code{logical} value indicating whether \code{NA}
values should be stripped before the computation proceeds.}

\item{costs}{A data frame with columns \code{truth}, \code{.pred_class}, and \code{costs}.
The first two columns contain the levels of the outcome factor. The \code{costs}
column is a numeric value for the cost of the result. It is not required but
typical that the costs when \code{truth == .pred_class} are zero. If any
combinations are missing, their costs are assumed to be zero. If
\code{costs = NULL}, equal costs across columns are used.}

\item{estimate}{If \code{truth} is binary, a numeric vector of class probabilities
corresponding to the "relevant" class. Otherwise, a matrix with as many
columns as factor levels of \code{truth}. \emph{It is assumed that these are in the
same order as the levels of \code{truth}.}}
}
\value{
A \code{tibble} with columns \code{.metric}, \code{.estimator},
and \code{.estimate} and 1 row of values.

For grouped data frames, the number of rows returned will be the same as
the number of groups.

For \code{class_cost_vec()}, a single \code{numeric} value (or \code{NA}).
}
\description{
\code{class_cost()} calculates the cost of a poor prediction based on user-defined
costs. The costs are combined with the estimated class probabilities and
the mean cost is returned.
}
\details{
As an example, suppose that there are three classes: \code{"A"}, \code{"B"}, and \code{"C"}.
Suppose there is a truly \code{"A"} data point with class probabilities
\code{A = 0.3}, \code{B = 0.3}, and \code{C = 0.4}. A cost matrix is created for all
combinations of the observed and predicted classes. Suppose that, when the
true result is class \code{"A"}, the costs for each class were \code{A = 0}, \code{B = 5},
and \code{C = 10}, the cost for this prediction would be \code{0 + 0.3 * 5 + 0.4 * 10}.
This calculation is done for each sample and the individual costs are
averaged.
}
\examples{
# Multiclass
library(dplyr)
data(hpc_cv)

# Define costs matrix from Kuhn and Johnson (2013):

hpc_costs <-
  dplyr::tribble(
    ~.pred_class, ~truth, ~cost,
    "VF",   "VF",     0,
    "VF",    "F",     1,
    "VF",    "M",     5,
    "VF",    "L",    10,
    "F",    "VF",     1,
    "F",     "F",     0,
    "F",     "M",     5,
    "F",     "L",     5,
    "M",    "VF",     1,
    "M",     "F",     1,
    "M",     "M",     0,
    "M",     "L",     1,
    "L",    "VF",     1,
    "L",     "F",     1,
    "L",     "M",     1,
    "L",     "L",     0
  )

# You can use the col1:colN tidyselect syntax
hpc_cv \%>\%
  filter(Resample == "Fold01") \%>\%
  class_cost(obs, VF:L, costs = hpc_costs)

# Groups are respected
hpc_cv \%>\%
  group_by(Resample) \%>\%
  class_cost(obs, VF:L, costs = hpc_costs)

# ------------------------------------------------------------------------------
# To include in a metric set, a wrapper must be used. Based on the advice in
# ?metric_set:

hpc_cost_metric <- function(data, truth, estimate, na_rm = TRUE, ...) {
  class_cost(
    data = data,
    truth = {{truth}},
    estimate = {{estimate}},
    # set specific costs
    costs = hpc_costs,
    na_rm = na_rm,
    ...
  )
}

hpc_cost_metric <- new_prob_metric(hpc_cost_metric, "minimize")

# On its own:
hpc_cv \%>\% hpc_cost_metric(obs, VF:L)

# In a metric set:
two_metrics <- metric_set(roc_auc, class_cost)
hpc_cv \%>\% two_metrics(obs, VF:L)

}
\seealso{
Other class probability metrics: 
\code{\link{average_precision}()},
\code{\link{gain_capture}()},
\code{\link{mn_log_loss}()},
\code{\link{pr_auc}()},
\code{\link{roc_auc}()},
\code{\link{roc_aunp}()},
\code{\link{roc_aunu}()}
}
\author{
Max Kuhn
}
\concept{class probability metrics}
