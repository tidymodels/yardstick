[{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@posit.co. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla‚Äôs code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to tidymodels","title":"Contributing to tidymodels","text":"detailed information contributing tidymodels packages, see development contributing guide.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CONTRIBUTING.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Contributing to tidymodels","text":"Typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES ‚úÖ: edit roxygen comment .R file R/ directory. üö´: edit .Rd file man/ directory. use roxygen2, Markdown syntax, documentation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contributing to tidymodels","text":"submit üéØ pull request tidymodels package, always file issue confirm tidymodels team agrees idea happy basic proposal. tidymodels packages work together. package contains unit tests, integration tests tests using packages contained extratests. pull requests, recommend create fork repo usethis::create_from_github(), initiate new branch usethis::pr_init(). Look build status making changes. README contains badges continuous integration services used package. New code follow tidyverse style guide. can use styler package apply styles, please don‚Äôt restyle code nothing PR. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s). use testthat. Contributions test cases included easier accept. contribution spans use one package, consider building extratests changes check breakages /adding new tests . Let us know PR ran extra tests. yardstick package, test objects created via helper functions tests/testthat/ folder.","code":""},{"path":"https://yardstick.tidymodels.org/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"Code","what":"Code of Conduct","title":"Contributing to tidymodels","text":"project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://yardstick.tidymodels.org/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 yardstick authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://yardstick.tidymodels.org/dev/MAINTENANCE.html","id":"current-state","dir":"","previous_headings":"","what":"Current state","title":"NA","text":"yardstick reached 1.0.0 status stable. majority users, 3 types metrics, internal class defined new_metric(): Numeric metrics Class metrics Class probability metrics yardstick bit unique actual functions exports, like accuracy(), extra classes attributes attached . allows used metric_set(), decide whether two metric functions allowed combined metric set . example, two numeric metric functions can combined, can‚Äôt combine numeric metric class metric. exception can combine class metric class probability metric - resulting function get back metric_set(), class metric use estimate interface class probability metric use ‚Ä¶ one. current public facing API, don‚Äôt see major changes needing made. ‚Äôm fairly happy 3 core metric classes work. think work yardstick done improving internal helpers (see Known issues), extending yardstick new metric class types (see Future directions). likely internal helpers improved first can add new metric class types, quite complex , making extending yardstick fairly difficult.","code":""},{"path":"https://yardstick.tidymodels.org/dev/MAINTENANCE.html","id":"known-issues","dir":"","previous_headings":"","what":"Known issues","title":"NA","text":"similar problem metric_vec_template(). currently tries handle validation function calling different types metrics. makes extremely complex, hard extend, probably bit brittle. particular validate_truth_estimate_checks() fairly complex S3 dispatch perform validation (kind home grown double dispatch truth estimate) might able rewritten cleaner way separate metric_vec_template() functions different kinds metric types. issues high cognitive overhead comes play, making hard add features: https://github.com/tidymodels/yardstick/issues/311 https://github.com/tidymodels/yardstick/issues/305 https://github.com/tidymodels/yardstick/issues/251 complexity validate_truth_estimate_checks() reduced instead creating check_*() helpers force metric writers call . provide useful ones, just call metric_vec() function ‚Äôd avoid double dispatch altogether ‚Äôd charge calling correct check_*() function based type truth estimate metric works . Something like check_factor_truth_factor_estimate(truth, estimate). probably help #305.","code":""},{"path":"https://yardstick.tidymodels.org/dev/MAINTENANCE.html","id":"future-directions","dir":"","previous_headings":"","what":"Future directions","title":"NA","text":"‚Äôd like officially hard deprecate support yardstick.event_first, global option soft deprecated awhile favor explicit event_level argument. definitely run revdeps removing , fairly aggressive getting rid point. can probably remove next minor release. https://github.com/tidymodels/yardstick/issues/173 number people seem interested calibration metrics calibration curves. might combined probably package way https://github.com/tidymodels/yardstick/issues/150. Fairness metrics seem fairly popular might fit yardstick, don‚Äôt clear sense ‚Äôd implemented. https://github.com/tidymodels/yardstick/issues/176 know want add survival metrics yardstick point. POC pull request adds basic infrastructure, isn‚Äôt fully fleshed https://github.com/tidymodels/yardstick/pull/222. Adding yardstick bit challenging reasons: metrics actually care adding? isn‚Äôt entirely clear list metrics really care . think critical scope survival support narrowly, example, PR supports right censoring right now. Trying add everything hard. API look like? Right now, well-defined API yardstick functions work. take truth estimate vectors, columns data frame. probability metrics take ‚Ä¶ instead single estimate column need supply multiple estimate columns. survival metrics, things bit complex consider censorship aspect. PR linked requires truth Surv object, censorship baked . estimate column, PR requires list-tibbles (length truth), .e.¬†output predict() function censored. makes API rather complex normal usage, think goal align nicely usage within tidymodels. metric PR dummy/naive roc auc curve survival analysis. imagine ‚Äúreal‚Äù survival metrics might need take kind time argument, probably required argument, might make API little tricky use tune metric_set()s. metric PR also adds new .time column output metric. yardstick functions . special nature function signature survival metrics, extra .time column output, probably can‚Äôt combined non-survival metrics metric_set(). reason, survival metric functions get class, .e.¬†new_metric(), metric_set() use allow metrics class combined together. think _vec() variant PR little strange. _vec() variants return single numeric value, one return data frame. might just function work, might also consider exporting _vec() variant survival metrics. thing remember adding new truth types like Surv validation estimator helpers gain new S3 methods handle . example finalize_estimator_default() validate_truth_estimate_types() internal generics needed new S3 methods handle Surv (PR).","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/grouping.html","id":"group-awareness","dir":"Articles","previous_headings":"","what":"Group-awareness","title":"Grouping behavior in yardstick","text":"Even implementation groupwise metrics, yardstick metrics group-aware. grouped data passed group-aware metric, return metric values calculated group. demonstrate, ‚Äôll make use hpc_cv data set, containing class probabilities class predictions linear discriminant analysis fit HPC data set Kuhn Johnson (2013). model evaluated via 10-fold cross-validation, predictions folds included. purposes vignette, ‚Äôll also add column batch data select columns class probabilities, don‚Äôt need. wanted compute accuracy first resampled model, write: metric function returns one row, giving .metric, .estimator, .estimate whole data set passed. instead group data fold, metric functions like accuracy know compute values group; output, row correspond Resample. Note first row, corresponding Fold01, gives value manually filtering observations corresponding first resample computing accuracy. behavior mean group-awareness. grouped data passed group-aware metric functions, return values group.","code":"tibble(hpc_cv) #> # A tibble: 3,467 √ó 7 #>    obs   pred     VF      F       M          L Resample #>    <fct> <fct> <dbl>  <dbl>   <dbl>      <dbl> <chr>    #>  1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01   #>  2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01   #>  3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01   #>  4 VF    VF    0.929 0.0653 0.00579 0.0000156  Fold01   #>  5 VF    VF    0.942 0.0543 0.00381 0.00000729 Fold01   #>  6 VF    VF    0.951 0.0462 0.00272 0.00000384 Fold01   #>  7 VF    VF    0.914 0.0782 0.00767 0.0000354  Fold01   #>  8 VF    VF    0.918 0.0744 0.00726 0.0000157  Fold01   #>  9 VF    VF    0.843 0.128  0.0296  0.000192   Fold01   #> 10 VF    VF    0.920 0.0728 0.00703 0.0000147  Fold01   #> # ‚Ñπ 3,457 more rows set.seed(1)  hpc <-   tibble(hpc_cv) %>%   mutate(batch = sample(c(\"a\", \"b\"), nrow(.), replace = TRUE)) %>%   select(-c(VF, F, M, L))  hpc #> # A tibble: 3,467 √ó 4 #>    obs   pred  Resample batch #>    <fct> <fct> <chr>    <chr> #>  1 VF    VF    Fold01   a     #>  2 VF    VF    Fold01   b     #>  3 VF    VF    Fold01   a     #>  4 VF    VF    Fold01   a     #>  5 VF    VF    Fold01   b     #>  6 VF    VF    Fold01   a     #>  7 VF    VF    Fold01   a     #>  8 VF    VF    Fold01   a     #>  9 VF    VF    Fold01   b     #> 10 VF    VF    Fold01   b     #> # ‚Ñπ 3,457 more rows hpc %>%    filter(Resample == \"Fold01\") %>%   accuracy(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy multiclass     0.726 hpc %>%    group_by(Resample) %>%   accuracy(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699"},{"path":"https://yardstick.tidymodels.org/dev/articles/grouping.html","id":"groupwise-metrics","dir":"Articles","previous_headings":"","what":"Groupwise metrics","title":"Grouping behavior in yardstick","text":"Groupwise metrics associated data-column , passed data column, metric temporarily group column, compute values groups defined column, aggregate values computed temporary grouping back level input data‚Äôs grouping. concretely, let‚Äôs turn example pre-existing grouping data. Consider portion HPC data pertaining first resample: Suppose batches data represent two groups model performance differ. quantify degree model performance differs two groups, compute accuracy values either group separately, take difference. First, computing accuracies: Now, taking difference: Groupwise metrics encode group_by() aggregation step (case, subtraction) shown yardstick metric. can define new groupwise metric new_groupwise_metric() function: fn argument yardstick metric computed data group. name argument gives name new metric ‚Äôve created; ‚Äôll call ‚Äúaccuracy difference.‚Äù aggregate argument function defining go fn output group single numeric value. output, accuracy_diff, function subclass called metric_factory: accuracy_diff now knows take accuracy values group return difference accuracy first second result output. last thing need associate object name grouping variable pass group_by(); can pass variable name accuracy_diff : output, accuracy_diff_by_batch, yardstick metric function like : can use accuracy_diff_by_batch() metric way use accuracy(). : can also add accuracy_diff_by_batch() metric sets: Groupwise metrics group-aware. passed data grouping variables column passed first argument accuracy_diff()‚Äîcase, group‚Äîaccuracy_diff_by_batch() behave like yardstick metric. example: Groupwise metrics form backend fairness metrics tidymodels. learn groupwise metrics applications fairness problems, see new_groupwise_metric().","code":"hpc %>%    filter(Resample == \"Fold01\") #> # A tibble: 347 √ó 4 #>    obs   pred  Resample batch #>    <fct> <fct> <chr>    <chr> #>  1 VF    VF    Fold01   a     #>  2 VF    VF    Fold01   b     #>  3 VF    VF    Fold01   a     #>  4 VF    VF    Fold01   a     #>  5 VF    VF    Fold01   b     #>  6 VF    VF    Fold01   a     #>  7 VF    VF    Fold01   a     #>  8 VF    VF    Fold01   a     #>  9 VF    VF    Fold01   b     #> 10 VF    VF    Fold01   b     #> # ‚Ñπ 337 more rows acc_by_group <-    hpc %>%    filter(Resample == \"Fold01\") %>%   group_by(batch) %>%   accuracy(obs, pred)  acc_by_group #> # A tibble: 2 √ó 4 #>   batch .metric  .estimator .estimate #>   <chr> <chr>    <chr>          <dbl> #> 1 a     accuracy multiclass     0.713 #> 2 b     accuracy multiclass     0.739 diff(c(acc_by_group$.estimate[2], acc_by_group$.estimate[1])) #> [1] -0.02518607 accuracy_diff <-   new_groupwise_metric(     fn = accuracy,     name = \"accuracy_diff\",     aggregate = function(acc_by_group) {       diff(c(acc_by_group$.estimate[2], acc_by_group$.estimate[1]))     }   ) class(accuracy_diff) #> [1] \"metric_factory\" \"function\" accuracy_diff_by_batch <- accuracy_diff(batch) class(accuracy) #> [1] \"class_metric\" \"metric\"       \"function\"  class(accuracy_diff_by_batch) #> [1] \"class_metric\" \"metric\"       \"function\" hpc %>%    filter(Resample == \"Fold01\") %>%   accuracy_diff_by_batch(obs, pred) #> # A tibble: 1 √ó 4 #>   .metric       .by   .estimator .estimate #>   <chr>         <chr> <chr>          <dbl> #> 1 accuracy_diff batch multiclass   -0.0252 acc_ms <- metric_set(accuracy, accuracy_diff_by_batch)  hpc %>%    filter(Resample == \"Fold01\") %>%   acc_ms(truth = obs, estimate = pred) #> # A tibble: 2 √ó 4 #>   .metric       .estimator .estimate .by   #>   <chr>         <chr>          <dbl> <chr> #> 1 accuracy      multiclass    0.726  NA    #> 2 accuracy_diff multiclass   -0.0252 batch hpc %>%    group_by(Resample) %>%   accuracy_diff_by_batch(obs, pred) #> # A tibble: 10 √ó 5 #>    Resample .metric       .by   .estimator .estimate #>    <chr>    <chr>         <chr> <chr>          <dbl> #>  1 Fold01   accuracy_diff batch multiclass -0.0252   #>  2 Fold02   accuracy_diff batch multiclass  0.106    #>  3 Fold03   accuracy_diff batch multiclass  0.0220   #>  4 Fold04   accuracy_diff batch multiclass -0.000300 #>  5 Fold05   accuracy_diff batch multiclass -0.0361   #>  6 Fold06   accuracy_diff batch multiclass  0.0153   #>  7 Fold07   accuracy_diff batch multiclass -0.0323   #>  8 Fold08   accuracy_diff batch multiclass -0.0159   #>  9 Fold09   accuracy_diff batch multiclass -0.0131   #> 10 Fold10   accuracy_diff batch multiclass -0.0255"},{"path":"https://yardstick.tidymodels.org/dev/articles/metric-types.html","id":"metric-types","dir":"Articles","previous_headings":"","what":"Metric types","title":"Metric types","text":"three main metric types yardstick: class, class probability, numeric. type metric standardized argument syntax, metrics return kind output (tibble 3 columns). standardization allows metrics easily grouped together used grouped data frames computing multiple resamples . five types metrics, along types inputs take. Class metrics (hard predictions) truth - factor estimate - factor Class probability metrics (soft predictions) truth - factor estimate / ... - multiple numeric columns containing class probabilities Ordered probability metrics (soft predictions) truth - ordered factor estimate / ... - multiple numeric columns containing class probabilities Numeric metrics truth - numeric estimate - numeric Static survival metircs truth - Surv estimate - numeric Dynamic survival metrics truth - Surv ... - list data.frames, containing 3 columns .eval_time, .pred_survival, .weight_censored`","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/metric-types.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Metric types","text":"following example, hpc_cv data set used. contains class probabilities class predictions linear discriminant analysis fit HPC data set Kuhn Johnson (2013). fit 10 fold cross-validation, predictions folds included. 1 metric, 1 resample 1 metric, 10 resamples 2 metrics, 10 resamples","code":"library(yardstick) library(dplyr) data(\"hpc_cv\")  hpc_cv %>%   group_by(Resample) %>%   slice(1:3) #> # A tibble: 30 √ó 7 #> # Groups:   Resample [10] #>    obs   pred     VF      F       M          L Resample #>    <fct> <fct> <dbl>  <dbl>   <dbl>      <dbl> <chr>    #>  1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01   #>  2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01   #>  3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01   #>  4 VF    VF    0.941 0.0544 0.00441 0.0000123  Fold02   #>  5 VF    VF    0.948 0.0483 0.00347 0.00000792 Fold02   #>  6 VF    VF    0.958 0.0395 0.00236 0.00000310 Fold02   #>  7 VF    VF    0.939 0.0556 0.00513 0.00000790 Fold03   #>  8 VF    VF    0.928 0.0642 0.00777 0.0000148  Fold03   #>  9 VF    VF    0.927 0.0653 0.00786 0.0000150  Fold03   #> 10 VF    VF    0.949 0.0469 0.00398 0.00000935 Fold04   #> # ‚Ñπ 20 more rows hpc_cv %>%   filter(Resample == \"Fold01\") %>%   accuracy(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy multiclass     0.726 hpc_cv %>%   group_by(Resample) %>%   accuracy(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699 class_metrics <- metric_set(accuracy, kap)  hpc_cv %>%   group_by(Resample) %>%   class_metrics(obs, estimate = pred) #> # A tibble: 20 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699 #> 11 Fold01   kap      multiclass     0.533 #> 12 Fold02   kap      multiclass     0.512 #> 13 Fold03   kap      multiclass     0.594 #> 14 Fold04   kap      multiclass     0.511 #> 15 Fold05   kap      multiclass     0.514 #> 16 Fold06   kap      multiclass     0.486 #> 17 Fold07   kap      multiclass     0.454 #> 18 Fold08   kap      multiclass     0.531 #> 19 Fold09   kap      multiclass     0.454 #> 20 Fold10   kap      multiclass     0.492"},{"path":"https://yardstick.tidymodels.org/dev/articles/metric-types.html","id":"metrics","dir":"Articles","previous_headings":"","what":"Metrics","title":"Metric types","text":"table metrics available yardstick, grouped type.","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/multiclass.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multiclass averaging","text":"Classification metrics yardstick truth estimate columns factors implemented binary multiclass case. multiclass implementations use micro, macro, macro_weighted averaging applicable, metrics specialized multiclass implementations.","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/multiclass.html","id":"macro-averaging","dir":"Articles","previous_headings":"","what":"Macro averaging","title":"Multiclass averaging","text":"Macro averaging reduces multiclass predictions multiple sets binary predictions, calculates corresponding metric binary cases, averages results together. example, consider precision binary case. Pr=TPTP+FP Pr = \\frac{TP}{TP + FP} multiclass case, levels , B, C D, macro averaging reduces problem multiple one-vs-comparisons. truth estimate columns recoded two levels , precision calculated based recoded columns, ‚Äúrelevant‚Äù column. process repeated 3 levels get total 4 precision values. results averaged together. formula representation looks like . k classes: Prmacro=Pr1+Pr2+‚Ä¶+Prkk=Pr11k+Pr21k+‚Ä¶+Prk1k Pr_{macro} = \\frac{Pr_1 + Pr_2 + \\ldots + Pr_k}{k} = Pr_1 \\frac{1}{k} + Pr_2 \\frac{1}{k} + \\ldots + Pr_k \\frac{1}{k} PR1PR_1 precision calculated recoding multiclass predictions just class 1 . Note macro averaging, classes get equal weight contributing portion precision value total (1/4). might realistic calculation large amount class imbalance. case, weighted macro average might make sense, weights calculated frequency class truth column. Prweighted‚àímacro=Pr1#Obs1N+Pr2#Obs2N+‚Ä¶+Prk#ObskN Pr_{weighted-macro} = Pr_1 \\frac{\\#Obs_1}{N} + Pr_2 \\frac{\\#Obs_2}{N} + \\ldots + Pr_k \\frac{\\#Obs_k}{N}","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/multiclass.html","id":"micro-averaging","dir":"Articles","previous_headings":"","what":"Micro averaging","title":"Multiclass averaging","text":"Micro averaging treats entire set data aggregate result, calculates 1 metric rather k metrics get averaged together. precision, works calculating true positive results class using numerator, calculating true positive false positive results class, using denominator. Prmicro=TP1+TP2+‚Ä¶+TPk(TP1+TP2+‚Ä¶+TPk)+(FP1+FP2+‚Ä¶+FPk) Pr_{micro} = \\frac{TP_1 + TP_2 + \\ldots + TP_k}{(TP_1 + TP_2 + \\ldots + TP_k) + (FP_1 + FP_2 + \\ldots + FP_k)}  case, rather class equal weight, observation gets equal weight. gives classes observations power.","code":""},{"path":"https://yardstick.tidymodels.org/dev/articles/multiclass.html","id":"specialized-multiclass-implementations","dir":"Articles","previous_headings":"","what":"Specialized multiclass implementations","title":"Multiclass averaging","text":"metrics known analytical multiclass extensions, need use averaging get estimate multiclass performance. Accuracy Kappa use definitions binary counterpart, accuracy counting number correctly predicted true values total number true values, kappa linear combination two accuracy values. Matthews correlation coefficient (MCC) known multiclass generalization well, sometimes called RKR_K statistic. Refer page details. ROC AUC interesting metric intuitively makes sense perform macro averaging, computes multiclass AUC average area multiple binary ROC curves. However, loses important property ROC AUC statistic binary case insensitive class distribution. combat , multiclass metric created retains insensitivity class distribution, easy visual interpretation like macro averaging. implemented \"hand_till\" method, default metric.","code":""},{"path":"https://yardstick.tidymodels.org/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Max Kuhn. Author. Davis Vaughan. Author. Emil Hvitfeldt. Author, maintainer. . Copyright holder, funder.","code":""},{"path":"https://yardstick.tidymodels.org/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kuhn M, Vaughan D, Hvitfeldt E (2025). yardstick: Tidy Characterizations Model Performance. R package version 1.3.2.9000, https://yardstick.tidymodels.org, https://github.com/tidymodels/yardstick.","code":"@Manual{,   title = {yardstick: Tidy Characterizations of Model Performance},   author = {Max Kuhn and Davis Vaughan and Emil Hvitfeldt},   year = {2025},   note = {R package version 1.3.2.9000,     https://yardstick.tidymodels.org},   url = {https://github.com/tidymodels/yardstick}, }"},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tidy Characterizations of Model Performance","text":"yardstick package estimate well models working using tidy data principles. See package webpage information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tidy Characterizations of Model Performance","text":"install package:","code":"install.packages(\"yardstick\")  # Development version: # install.packages(\"pak\") pak::pak(\"tidymodels/yardstick\")"},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"two-class-metric","dir":"","previous_headings":"","what":"Two class metric","title":"Tidy Characterizations of Model Performance","text":"example, suppose create classification model predict new data set. might data looks like : can use dplyr-like syntax compute common performance characteristics model get back data frame:","code":"library(yardstick) library(dplyr)  head(two_class_example) #>    truth  Class1   Class2 predicted #> 1 Class2 0.00359 0.996411    Class2 #> 2 Class1 0.67862 0.321379    Class1 #> 3 Class2 0.11089 0.889106    Class2 #> 4 Class1 0.73516 0.264838    Class1 #> 5 Class2 0.01624 0.983760    Class2 #> 6 Class1 0.99928 0.000725    Class1 metrics(two_class_example, truth, predicted) #> # A tibble: 2 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy binary         0.838 #> 2 kap      binary         0.675  # or  two_class_example %>%   roc_auc(truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 roc_auc binary         0.939"},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"multiclass-metrics","dir":"","previous_headings":"","what":"Multiclass metrics","title":"Tidy Characterizations of Model Performance","text":"classification metrics least one multiclass extension, many multiple ways calculate multiclass metrics.","code":"data(\"hpc_cv\") hpc_cv <- as_tibble(hpc_cv) hpc_cv #> # A tibble: 3,467 √ó 7 #>    obs   pred     VF      F       M          L Resample #>    <fct> <fct> <dbl>  <dbl>   <dbl>      <dbl> <chr>    #>  1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01   #>  2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01   #>  3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01   #>  4 VF    VF    0.929 0.0653 0.00579 0.0000156  Fold01   #>  5 VF    VF    0.942 0.0543 0.00381 0.00000729 Fold01   #>  6 VF    VF    0.951 0.0462 0.00272 0.00000384 Fold01   #>  7 VF    VF    0.914 0.0782 0.00767 0.0000354  Fold01   #>  8 VF    VF    0.918 0.0744 0.00726 0.0000157  Fold01   #>  9 VF    VF    0.843 0.128  0.0296  0.000192   Fold01   #> 10 VF    VF    0.920 0.0728 0.00703 0.0000147  Fold01   #> # ‚Ñπ 3,457 more rows # Macro averaged multiclass precision precision(hpc_cv, obs, pred) #> # A tibble: 1 √ó 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision macro          0.631  # Micro averaged multiclass precision precision(hpc_cv, obs, pred, estimator = \"micro\") #> # A tibble: 1 √ó 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision micro          0.709"},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"calculating-metrics-on-resamples","dir":"","previous_headings":"","what":"Calculating metrics on resamples","title":"Tidy Characterizations of Model Performance","text":"multiple resamples model, can use metric grouped data frame calculate metric across resamples . calculates multiclass ROC AUC using method described Hand, Till (2001), across 10 resamples .","code":"hpc_cv %>%   group_by(Resample) %>%   roc_auc(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   roc_auc hand_till      0.813 #>  2 Fold02   roc_auc hand_till      0.817 #>  3 Fold03   roc_auc hand_till      0.869 #>  4 Fold04   roc_auc hand_till      0.849 #>  5 Fold05   roc_auc hand_till      0.811 #>  6 Fold06   roc_auc hand_till      0.836 #>  7 Fold07   roc_auc hand_till      0.825 #>  8 Fold08   roc_auc hand_till      0.846 #>  9 Fold09   roc_auc hand_till      0.828 #> 10 Fold10   roc_auc hand_till      0.812"},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"autoplot-methods-for-easy-visualization","dir":"","previous_headings":"","what":"Autoplot methods for easy visualization","title":"Tidy Characterizations of Model Performance","text":"Curve based methods roc_curve(), pr_curve() gain_curve() ggplot2::autoplot() methods allow powerful easy visualization.","code":"library(ggplot2)  hpc_cv %>%   group_by(Resample) %>%   roc_curve(obs, VF:L) %>%   autoplot()"},{"path":"https://yardstick.tidymodels.org/dev/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tidy Characterizations of Model Performance","text":"project released Contributor Code Conduct. contributing project, agree abide terms. questions discussions tidymodels packages, modeling, machine learning, please post RStudio Community. think encountered bug, please submit issue. Either way, learn create share reprex (minimal, reproducible example), clearly communicate code. Check details contributing guidelines tidymodels packages get help.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Accuracy ‚Äî accuracy","title":"Accuracy ‚Äî accuracy","text":"Accuracy proportion data predicted correctly.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accuracy ‚Äî accuracy","text":"","code":"accuracy(data, ...)  # S3 method for class 'data.frame' accuracy(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  accuracy_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Accuracy ‚Äî accuracy","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Accuracy ‚Äî accuracy","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. accuracy_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Accuracy ‚Äî accuracy","text":"Accuracy extends naturally multiclass scenarios. , macro micro averaging implemented.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Accuracy ‚Äî accuracy","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Accuracy ‚Äî accuracy","text":"","code":"library(dplyr) #>  #> Attaching package: ‚Äòdplyr‚Äô #> The following objects are masked from ‚Äòpackage:stats‚Äô: #>  #>     filter, lag #> The following objects are masked from ‚Äòpackage:base‚Äô: #>  #>     intersect, setdiff, setequal, union data(\"two_class_example\") data(\"hpc_cv\")  # Two class accuracy(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy binary         0.838  # Multiclass # accuracy() has a natural multiclass extension hpc_cv %>%   filter(Resample == \"Fold01\") %>%   accuracy(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy multiclass     0.726  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   accuracy(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699"},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the precision recall curve ‚Äî average_precision","title":"Area under the precision recall curve ‚Äî average_precision","text":"average_precision() alternative pr_auc() avoids ambiguity value precision recall == 0 yet false positive values (say 0, others say 1, others say undefined). computes weighted average precision values returned pr_curve(), weights increase recall previous threshold. See pr_curve() full curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the precision recall curve ‚Äî average_precision","text":"","code":"average_precision(data, ...)  # S3 method for class 'data.frame' average_precision(   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )  average_precision_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the precision recall curve ‚Äî average_precision","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimator One \"binary\", \"macro\", \"macro_weighted\" specify type averaging done. \"binary\" relevant two class case. two general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based truth. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the precision recall curve ‚Äî average_precision","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. average_precision_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Area under the precision recall curve ‚Äî average_precision","text":"computation average precision weighted average precision values. Assuming n rows returned pr_curve(), sum 2 n, multiplying precision value p_i increase recall previous threshold, r_i - r_(-1). $$AP = \\sum (r_{} - r_{-1}) * p_i$$ summing 2 n, precision value p_1 never used. pr_curve() returns value p_1, technically undefined tp / (tp + fp) tp = 0 fp = 0. common convention use 1 p_1, metric nice property avoiding ambiguity. hand, r_1 well defined long events (p), tp / p tp = 0, r_1 = 0. p_1 defined 1, average_precision() roc_auc() values often close one another.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Area under the precision recall curve ‚Äî average_precision","text":"Macro macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Area under the precision recall curve ‚Äî average_precision","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/average_precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the precision recall curve ‚Äî average_precision","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. average_precision(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric           .estimator .estimate #>   <chr>             <chr>          <dbl> #> 1 average_precision binary         0.947  # --------------------------------------------------------------------------- # Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   average_precision(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric           .estimator .estimate #>   <chr>             <chr>          <dbl> #> 1 average_precision macro          0.617  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   average_precision(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric           .estimator .estimate #>   <chr>             <chr>          <dbl> #> 1 average_precision macro          0.617  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   average_precision(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric           .estimator .estimate #>    <chr>    <chr>             <chr>          <dbl> #>  1 Fold01   average_precision macro          0.617 #>  2 Fold02   average_precision macro          0.625 #>  3 Fold03   average_precision macro          0.699 #>  4 Fold04   average_precision macro          0.685 #>  5 Fold05   average_precision macro          0.625 #>  6 Fold06   average_precision macro          0.656 #>  7 Fold07   average_precision macro          0.617 #>  8 Fold08   average_precision macro          0.659 #>  9 Fold09   average_precision macro          0.632 #> 10 Fold10   average_precision macro          0.611  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   average_precision(obs, VF:L, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric           .estimator     .estimate #>    <chr>    <chr>             <chr>              <dbl> #>  1 Fold01   average_precision macro_weighted     0.750 #>  2 Fold02   average_precision macro_weighted     0.745 #>  3 Fold03   average_precision macro_weighted     0.794 #>  4 Fold04   average_precision macro_weighted     0.757 #>  5 Fold05   average_precision macro_weighted     0.740 #>  6 Fold06   average_precision macro_weighted     0.747 #>  7 Fold07   average_precision macro_weighted     0.751 #>  8 Fold08   average_precision macro_weighted     0.759 #>  9 Fold09   average_precision macro_weighted     0.714 #> 10 Fold10   average_precision macro_weighted     0.742  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  average_precision_vec(    truth = fold1$obs,    matrix(      c(fold1$VF, fold1$F, fold1$M, fold1$L),      ncol = 4    ) ) #> [1] 0.6173363"},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Balanced accuracy ‚Äî bal_accuracy","title":"Balanced accuracy ‚Äî bal_accuracy","text":"Balanced accuracy computed average sens() spec().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balanced accuracy ‚Äî bal_accuracy","text":"","code":"bal_accuracy(data, ...)  # S3 method for class 'data.frame' bal_accuracy(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  bal_accuracy_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balanced accuracy ‚Äî bal_accuracy","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balanced accuracy ‚Äî bal_accuracy","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. bal_accuracy_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Balanced accuracy ‚Äî bal_accuracy","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Balanced accuracy ‚Äî bal_accuracy","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balanced accuracy ‚Äî bal_accuracy","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/bal_accuracy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balanced accuracy ‚Äî bal_accuracy","text":"","code":"# Two class data(\"two_class_example\") bal_accuracy(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric      .estimator .estimate #>   <chr>        <chr>          <dbl> #> 1 bal_accuracy binary         0.837  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   bal_accuracy(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric      .estimator .estimate #>   <chr>        <chr>          <dbl> #> 1 bal_accuracy macro          0.717  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   bal_accuracy(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric      .estimator .estimate #>    <chr>    <chr>        <chr>          <dbl> #>  1 Fold01   bal_accuracy macro          0.717 #>  2 Fold02   bal_accuracy macro          0.711 #>  3 Fold03   bal_accuracy macro          0.767 #>  4 Fold04   bal_accuracy macro          0.724 #>  5 Fold05   bal_accuracy macro          0.715 #>  6 Fold06   bal_accuracy macro          0.707 #>  7 Fold07   bal_accuracy macro          0.699 #>  8 Fold08   bal_accuracy macro          0.734 #>  9 Fold09   bal_accuracy macro          0.717 #> 10 Fold10   bal_accuracy macro          0.706  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   bal_accuracy(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric      .estimator     .estimate #>    <chr>    <chr>        <chr>              <dbl> #>  1 Fold01   bal_accuracy macro_weighted     0.771 #>  2 Fold02   bal_accuracy macro_weighted     0.763 #>  3 Fold03   bal_accuracy macro_weighted     0.799 #>  4 Fold04   bal_accuracy macro_weighted     0.758 #>  5 Fold05   bal_accuracy macro_weighted     0.762 #>  6 Fold06   bal_accuracy macro_weighted     0.746 #>  7 Fold07   bal_accuracy macro_weighted     0.733 #>  8 Fold08   bal_accuracy macro_weighted     0.768 #>  9 Fold09   bal_accuracy macro_weighted     0.734 #> 10 Fold10   bal_accuracy macro_weighted     0.750  # Vector version bal_accuracy_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.8366167  # Making Class2 the \"relevant\" level bal_accuracy_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.8366167"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Brier score for classification models ‚Äî brier_class","title":"Brier score for classification models ‚Äî brier_class","text":"Compute Brier score classification model.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brier score for classification models ‚Äî brier_class","text":"","code":"brier_class(data, ...)  # S3 method for class 'data.frame' brier_class(data, truth, ..., na_rm = TRUE, case_weights = NULL)  brier_class_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brier score for classification models ‚Äî brier_class","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brier score for classification models ‚Äî brier_class","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. brier_class_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Brier score for classification models ‚Äî brier_class","text":"Brier score analogous mean squared error regression models. difference binary indicator class corresponding class probability squared averaged. function uses convention Kruppa et al (2014) divides result two. Smaller values score associated better model performance.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Brier score for classification models ‚Äî brier_class","text":"Brier scores can computed way number classes. , averaging types supported.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Brier score for classification models ‚Äî brier_class","text":"Kruppa, J., Liu, Y., Diener, H.-C., Holste, T., Weimar, C., Koonig, . R., Ziegler, . (2014) Probability estimation machine learning methods dichotomous multicategory outcome: Applications. Biometrical Journal, 56 (4): 564-583.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Brier score for classification models ‚Äî brier_class","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brier score for classification models ‚Äî brier_class","text":"","code":"# Two class data(\"two_class_example\") brier_class(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 brier_class binary         0.106  # Multiclass library(dplyr) data(hpc_cv)  # You can use the col1:colN tidyselect syntax hpc_cv %>%   filter(Resample == \"Fold01\") %>%   brier_class(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 brier_class multiclass     0.202  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   brier_class(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric     .estimator .estimate #>    <chr>    <chr>       <chr>          <dbl> #>  1 Fold01   brier_class multiclass     0.202 #>  2 Fold02   brier_class multiclass     0.215 #>  3 Fold03   brier_class multiclass     0.177 #>  4 Fold04   brier_class multiclass     0.204 #>  5 Fold05   brier_class multiclass     0.213 #>  6 Fold06   brier_class multiclass     0.214 #>  7 Fold07   brier_class multiclass     0.221 #>  8 Fold08   brier_class multiclass     0.209 #>  9 Fold09   brier_class multiclass     0.235 #> 10 Fold10   brier_class multiclass     0.218"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"Compute time-dependent Brier score right censored data, mean squared error time point .eval_time.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"","code":"brier_survival(data, ...)  # S3 method for class 'data.frame' brier_survival(data, truth, ..., na_rm = TRUE, case_weights = NULL)  brier_survival_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"data data.frame containing columns specified truth .... ... column identifier survival probabilities list column data.frames corresponding output given predicting censored model. unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, dots used. truth column identifier true survival result (created using survival::Surv().). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, survival::Surv() object. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate list column data.frames corresponding output given predicting censored model. See details information regarding format.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"tibble columns .metric, .estimator, .estimate. ungrouped data frame, result one row values. grouped data frame, number rows returned number groups. brier_survival_vec(), numeric vector length input argument eval_time. (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"formulation takes survival probability predictions one specific evaluation times , time, computes Brier score. account censoring, inverse probability censoring weights (IPCW) used calculations. column passed ... list column one element per independent experiential unit (e.g. patient). list column contain data frames several columns: .eval_time: time prediction made. .pred_survival: predicted probability survival .eval_time .weight_censored: case weight inverse probability censoring. last column can produced using parsnip::.censoring_weights_graf(). corresponds weighting scheme  Graf et al (1999). internal data set lung_surv shows example format. method automatically groups .eval_time argument. Smaller values score associated better model performance.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"E. Graf, C. Schmoor, W. Sauerbrei, M. Schumacher, ‚ÄúAssessment comparison prognostic classification schemes survival data,‚Äù Statistics Medicine, vol. 18, . 17-18, pp. 2529‚Äì2545, 1999.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"Emil Hvitfeldt","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-Dependent Brier score for right censored data ‚Äî brier_survival","text":"","code":"# example code  library(dplyr)  lung_surv %>%   brier_survival(     truth = surv_obj,     .pred   ) #> # A tibble: 5 √ó 4 #>   .metric        .estimator .eval_time .estimate #>   <chr>          <chr>           <dbl>     <dbl> #> 1 brier_survival standard          100     0.109 #> 2 brier_survival standard          200     0.194 #> 3 brier_survival standard          300     0.219 #> 4 brier_survival standard          400     0.222 #> 5 brier_survival standard          500     0.197"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"Compute integrated Brier score right censored data, overall calculation model performance values .eval_time.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"","code":"brier_survival_integrated(data, ...)  # S3 method for class 'data.frame' brier_survival_integrated(data, truth, ..., na_rm = TRUE, case_weights = NULL)  brier_survival_integrated_vec(   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"data data.frame containing columns specified truth .... ... column identifier survival probabilities list column data.frames corresponding output given predicting censored model. unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, dots used. truth column identifier true survival result (created using survival::Surv().). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, survival::Surv() object. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate list column data.frames corresponding output given predicting censored model. See details information regarding format.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"tibble columns .metric, .estimator, .estimate. ungrouped data frame, result one row values. grouped data frame, number rows returned number groups. brier_survival_integrated_vec(), numeric vector length input argument eval_time. (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"integrated time-dependent brier score calculated \"area curve\" fashion. brier score calculated value .eval_time. area calculated via trapezoidal rule. area divided largest value .eval_time bring scale traditional brier score. Smaller values score associated better model performance. formulation takes survival probability predictions one specific evaluation times , time, computes Brier score. account censoring, inverse probability censoring weights (IPCW) used calculations. column passed ... list column one element per independent experiential unit (e.g. patient). list column contain data frames several columns: .eval_time: time prediction made. .pred_survival: predicted probability survival .eval_time .weight_censored: case weight inverse probability censoring. last column can produced using parsnip::.censoring_weights_graf(). corresponds weighting scheme  Graf et al (1999). internal data set lung_surv shows example format. method automatically groups .eval_time argument.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"E. Graf, C. Schmoor, W. Sauerbrei, M. Schumacher, ‚ÄúAssessment comparison prognostic classification schemes survival data,‚Äù Statistics Medicine, vol. 18, . 17-18, pp. 2529‚Äì2545, 1999.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"Emil Hvitfeldt","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/brier_survival_integrated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrated Brier score for right censored data ‚Äî brier_survival_integrated","text":"","code":"library(dplyr)  lung_surv %>%   brier_survival_integrated(     truth = surv_obj,     .pred   ) #> # A tibble: 1 √ó 3 #>   .metric                   .estimator .estimate #>   <chr>                     <chr>          <dbl> #> 1 brier_survival_integrated standard       0.158"},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":null,"dir":"Reference","previous_headings":"","what":"Concordance correlation coefficient ‚Äî ccc","title":"Concordance correlation coefficient ‚Äî ccc","text":"Calculate concordance correlation coefficient.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Concordance correlation coefficient ‚Äî ccc","text":"","code":"ccc(data, ...)  # S3 method for class 'data.frame' ccc(   data,   truth,   estimate,   bias = FALSE,   na_rm = TRUE,   case_weights = NULL,   ... )  ccc_vec(truth, estimate, bias = FALSE, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Concordance correlation coefficient ‚Äî ccc","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. bias logical; biased estimate variance used (Lin (1989))? na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Concordance correlation coefficient ‚Äî ccc","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. ccc_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Concordance correlation coefficient ‚Äî ccc","text":"ccc() metric consistency/correlation accuracy, metrics rmse() strictly accuracy metrics rsq() strictly consistency/correlation","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Concordance correlation coefficient ‚Äî ccc","text":"Lin, L. (1989). concordance correlation coefficient evaluate reproducibility. Biometrics, 45 (1), 255-268. Nickerson, C. (1997). note \"concordance correlation coefficient evaluate reproducibility\". Biometrics, 53(4), 1503-1507.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Concordance correlation coefficient ‚Äî ccc","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ccc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Concordance correlation coefficient ‚Äî ccc","text":"","code":"# Supply truth and predictions as bare column names ccc(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 ccc     standard       0.937  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   ccc(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        ccc     standard       0.935 #>  2 10       ccc     standard       0.937 #>  3 2        ccc     standard       0.943 #>  4 3        ccc     standard       0.956 #>  5 4        ccc     standard       0.944 #>  6 5        ccc     standard       0.925 #>  7 6        ccc     standard       0.933 #>  8 7        ccc     standard       0.922 #>  9 8        ccc     standard       0.955 #> 10 9        ccc     standard       0.940  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.939"},{"path":"https://yardstick.tidymodels.org/dev/reference/check_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for checking inputs in new metrics ‚Äî check_metric","title":"Developer function for checking inputs in new metrics ‚Äî check_metric","text":"check_numeric_metric(), check_class_metric(), check_prob_metric() useful alongside metric-summarizers implementing new custom metrics. metric-summarizers call metric function inside dplyr::summarise(). functions perform checks inputs accordance type metric used.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/check_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for checking inputs in new metrics ‚Äî check_metric","text":"","code":"check_numeric_metric(truth, estimate, case_weights, call = caller_env())  check_class_metric(   truth,   estimate,   case_weights,   estimator,   call = caller_env() )  check_prob_metric(   truth,   estimate,   case_weights,   estimator,   call = caller_env() )  check_ordered_prob_metric(   truth,   estimate,   case_weights,   estimator,   call = caller_env() )  check_dynamic_survival_metric(   truth,   estimate,   case_weights,   call = caller_env() )  check_static_survival_metric(   truth,   estimate,   case_weights,   call = caller_env() )"},{"path":"https://yardstick.tidymodels.org/dev/reference/check_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for checking inputs in new metrics ‚Äî check_metric","text":"truth realized vector truth. check_numeric_metric(), numeric vector. check_class_metric(), factor. check_prob_metric(), factor. check_ordered_prob_metric(), ordered factor. check_dynamic_survival_metric(), Surv object. check_static_survival_metric(), Surv object. estimate realized estimate result. check_numeric_metric(), numeric vector. check_class_metric(), factor. check_prob_metric(), numeric vector binary truth, numeric matrix multic-class truth. check_ordered_prob_metric(), numeric vector binary truth, numeric matrix multic-class truth. check_dynamic_survival_metric(), list-column data.frames. check_static_survival_metric(), numeric vector. case_weights realized case weights, numeric vector. must length truth. call execution environment currently running function, e.g. caller_env(). function mentioned error messages source error. See call argument abort() information. estimator can either NULL default auto-selection averaging (\"binary\" \"macro\"), single character pass along metric implementation describing kind averaging use.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":null,"dir":"Reference","previous_headings":"","what":"Costs function for poor classification ‚Äî classification_cost","title":"Costs function for poor classification ‚Äî classification_cost","text":"classification_cost() calculates cost poor prediction based user-defined costs. costs multiplied estimated class probabilities mean cost returned.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Costs function for poor classification ‚Äî classification_cost","text":"","code":"classification_cost(data, ...)  # S3 method for class 'data.frame' classification_cost(   data,   truth,   ...,   costs = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )  classification_cost_vec(   truth,   estimate,   costs = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Costs function for poor classification ‚Äî classification_cost","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. costs data frame columns \"truth\", \"estimate\", \"cost\". \"truth\" \"estimate\" character columns containing unique combinations levels truth factor. \"costs\" numeric column representing cost applied \"estimate\" predicted, true result \"truth\". often case \"truth\" == \"estimate\", cost zero (penalty correct predictions). combinations levels truth missing, costs assumed zero. NULL, equal costs used, applying cost 0 correct predictions, cost 1 incorrect predictions. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Costs function for poor classification ‚Äî classification_cost","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. class_cost_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Costs function for poor classification ‚Äî classification_cost","text":"example, suppose three classes: \"\", \"B\", \"C\". Suppose truly \"\" observation class probabilities = 0.3 / B = 0.3 / C = 0.4. Suppose , true result class \"\", costs class = 0 / B = 5 / C = 10, penalizing probability incorrectly predicting \"C\" predicting \"B\". cost prediction 0.3 * 0 + 0.3 * 5 + 0.4 * 10. calculation done sample individual costs averaged.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Costs function for poor classification ‚Äî classification_cost","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/classification_cost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Costs function for poor classification ‚Äî classification_cost","text":"","code":"library(dplyr)  # --------------------------------------------------------------------------- # Two class example data(two_class_example)  # Assuming `Class1` is our \"event\", this penalizes false positives heavily costs1 <- tribble(   ~truth,   ~estimate, ~cost,   \"Class1\", \"Class2\",  1,   \"Class2\", \"Class1\",  2 )  # Assuming `Class1` is our \"event\", this penalizes false negatives heavily costs2 <- tribble(   ~truth,   ~estimate, ~cost,   \"Class1\", \"Class2\",  2,   \"Class2\", \"Class1\",  1 )  classification_cost(two_class_example, truth, Class1, costs = costs1) #> # A tibble: 1 √ó 3 #>   .metric             .estimator .estimate #>   <chr>               <chr>          <dbl> #> 1 classification_cost binary         0.288  classification_cost(two_class_example, truth, Class1, costs = costs2) #> # A tibble: 1 √ó 3 #>   .metric             .estimator .estimate #>   <chr>               <chr>          <dbl> #> 1 classification_cost binary         0.260  # --------------------------------------------------------------------------- # Multiclass data(hpc_cv)  # Define cost matrix from Kuhn and Johnson (2013) hpc_costs <- tribble(   ~estimate, ~truth, ~cost,   \"VF\",      \"VF\",    0,   \"VF\",      \"F\",     1,   \"VF\",      \"M\",     5,   \"VF\",      \"L\",    10,   \"F\",       \"VF\",    1,   \"F\",       \"F\",     0,   \"F\",       \"M\",     5,   \"F\",       \"L\",     5,   \"M\",       \"VF\",    1,   \"M\",       \"F\",     1,   \"M\",       \"M\",     0,   \"M\",       \"L\",     1,   \"L\",       \"VF\",    1,   \"L\",       \"F\",     1,   \"L\",       \"M\",     1,   \"L\",       \"L\",     0 )  # You can use the col1:colN tidyselect syntax hpc_cv %>%   filter(Resample == \"Fold01\") %>%   classification_cost(obs, VF:L, costs = hpc_costs) #> # A tibble: 1 √ó 3 #>   .metric             .estimator .estimate #>   <chr>               <chr>          <dbl> #> 1 classification_cost multiclass     0.779  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   classification_cost(obs, VF:L, costs = hpc_costs) #> # A tibble: 10 √ó 4 #>    Resample .metric             .estimator .estimate #>    <chr>    <chr>               <chr>          <dbl> #>  1 Fold01   classification_cost multiclass     0.779 #>  2 Fold02   classification_cost multiclass     0.735 #>  3 Fold03   classification_cost multiclass     0.654 #>  4 Fold04   classification_cost multiclass     0.754 #>  5 Fold05   classification_cost multiclass     0.777 #>  6 Fold06   classification_cost multiclass     0.737 #>  7 Fold07   classification_cost multiclass     0.743 #>  8 Fold08   classification_cost multiclass     0.749 #>  9 Fold09   classification_cost multiclass     0.760 #> 10 Fold10   classification_cost multiclass     0.771"},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":null,"dir":"Reference","previous_headings":"","what":"Concordance index for right-censored data ‚Äî concordance_survival","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"Compute Concordance index right-censored data","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"","code":"concordance_survival(data, ...)  # S3 method for class 'data.frame' concordance_survival(   data,   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   ... )  concordance_survival_vec(   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"data data.frame containing columns specified truth .... ... Currently used. truth column identifier true survival result (created using survival::Surv().). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, survival::Surv() object. estimate column identifier predicted time, numeric variables. unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. concordance_survival_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"concordance index defined proportion comparable pairs predictions outcomes concordant. Two observations comparable : observations experienced event (different times), observation shorter observed survival time experienced event, case event-free subject ‚Äúoutlived‚Äù . pair comparable experienced events time. Concordance intuitively means two samples ordered correctly model. specifically, two samples concordant, one higher estimated risk score shorter actual survival time. Larger values score associated better model performance.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"Harrell, F.E., Califf, R.M., Pryor, D.B., Lee, K.L., Rosati, R., ‚ÄúMultivariable prognostic models: issues developing models, evaluating assumptions adequacy, measuring reducing errors‚Äù, Statistics Medicine, 15(4), 361-87, 1996.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"Emil Hvitfeldt","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/concordance_survival.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Concordance index for right-censored data ‚Äî concordance_survival","text":"","code":"concordance_survival(   data = lung_surv,   truth = surv_obj,   estimate = .pred_time ) #> # A tibble: 1 √ó 3 #>   .metric              .estimator .estimate #>   <chr>                <chr>          <dbl> #> 1 concordance_survival standard       0.637"},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Confusion Matrix for Categorical Data ‚Äî conf_mat","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"Calculates cross-tabulation observed predicted classes.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"","code":"conf_mat(data, ...)  # S3 method for class 'data.frame' conf_mat(   data,   truth,   estimate,   dnn = c(\"Prediction\", \"Truth\"),   case_weights = NULL,   ... )  # S3 method for class 'conf_mat' tidy(x, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"data data frame base::table(). ... used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. dnn character vector dimnames table. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). x conf_mat object.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"conf_mat() produces object class conf_mat. contains table objects. tidy.conf_mat() generates tibble columns name (cell identifier) value (cell count). used grouped data frame, conf_mat() returns tibble containing columns groups along conf_mat, list-column element conf_mat object.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"conf_mat() objects, broom tidy() method created collapses cell counts cell data frame easy manipulation. also summary() method computes various classification metrics . See summary.conf_mat() ggplot2::autoplot() method quickly visualizing matrix. heatmap mosaic type implemented. function requires factors exactly levels.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/conf_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confusion Matrix for Categorical Data ‚Äî conf_mat","text":"","code":"library(dplyr) data(\"hpc_cv\")  # The confusion matrix from a single assessment set (i.e. fold) cm <- hpc_cv %>%   filter(Resample == \"Fold01\") %>%   conf_mat(obs, pred) cm #>           Truth #> Prediction  VF   F   M   L #>         VF 166  33   8   1 #>         F   11  71  24   7 #>         M    0   3   5   3 #>         L    0   1   4  10  # Now compute the average confusion matrix across all folds in # terms of the proportion of the data contained in each cell. # First get the raw cell counts per fold using the `tidy` method library(tidyr)  cells_per_resample <- hpc_cv %>%   group_by(Resample) %>%   conf_mat(obs, pred) %>%   mutate(tidied = lapply(conf_mat, tidy)) %>%   unnest(tidied)  # Get the totals per resample counts_per_resample <- hpc_cv %>%   group_by(Resample) %>%   summarize(total = n()) %>%   left_join(cells_per_resample, by = \"Resample\") %>%   # Compute the proportions   mutate(prop = value / total) %>%   group_by(name) %>%   # Average   summarize(prop = mean(prop))  counts_per_resample #> # A tibble: 16 √ó 2 #>    name         prop #>    <chr>       <dbl> #>  1 cell_1_1 0.467    #>  2 cell_1_2 0.107    #>  3 cell_1_3 0.0185   #>  4 cell_1_4 0.00259  #>  5 cell_2_1 0.0407   #>  6 cell_2_2 0.187    #>  7 cell_2_3 0.0632   #>  8 cell_2_4 0.0173   #>  9 cell_3_1 0.00173  #> 10 cell_3_2 0.00692  #> 11 cell_3_3 0.0228   #> 12 cell_3_4 0.00807  #> 13 cell_4_1 0.000575 #> 14 cell_4_2 0.0104   #> 15 cell_4_3 0.0144   #> 16 cell_4_4 0.0320    # Now reshape these into a matrix mean_cmat <- matrix(counts_per_resample$prop, byrow = TRUE, ncol = 4) rownames(mean_cmat) <- levels(hpc_cv$obs) colnames(mean_cmat) <- levels(hpc_cv$obs)  round(mean_cmat, 3) #>       VF     F     M     L #> VF 0.467 0.107 0.018 0.003 #> F  0.041 0.187 0.063 0.017 #> M  0.002 0.007 0.023 0.008 #> L  0.001 0.010 0.014 0.032  # The confusion matrix can quickly be visualized using autoplot() library(ggplot2)  autoplot(cm, type = \"mosaic\")  autoplot(cm, type = \"heatmap\")"},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":null,"dir":"Reference","previous_headings":"","what":"Demographic parity ‚Äî demographic_parity","title":"Demographic parity ‚Äî demographic_parity","text":"Demographic parity satisfied model's predictions predicted positive rate across groups. value 0 indicates parity across groups. Note definition depend true outcome; truth argument included outputted metrics consistency. demographic_parity() calculated difference largest smallest value detection_prevalence() across groups. Demographic parity sometimes referred group fairness, disparate impact, statistical parity. See \"Measuring Disparity\" section details implementation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Demographic parity ‚Äî demographic_parity","text":"","code":"demographic_parity(by)"},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Demographic parity ‚Äî demographic_parity","text":"column identifier sensitive feature. unquoted column name referring column un-preprocessed data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Demographic parity ‚Äî demographic_parity","text":"function outputs yardstick fairness metric function. Given grouping variable , demographic_parity() return yardstick metric function associated data-variable grouping post-processor. outputted function first generate set detection_prevalence metric values group summarizing across groups using post-processing function. outputted function data frame method intended used part metric set.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"measuring-disparity","dir":"Reference","previous_headings":"","what":"Measuring Disparity","title":"Demographic parity ‚Äî demographic_parity","text":"default, function takes difference range detection_prevalence .estimates across groups. , maximum pair-wise disparity groups return value demographic_parity()'s .estimate. finer control group treatment, construct context-aware fairness metric new_groupwise_metric() function passing custom aggregate function:   aggregate(), x metric_set() output detection_prevalence values group, ... gives additional arguments (grouping level refer \"baseline\") pass function outputted demographic_parity_2() context.","code":"# the actual default `aggregate` is: diff_range <- function(x, ...) {diff(range(x$.estimate))}  demographic_parity_2 <-   new_groupwise_metric(     fn = detection_prevalence,     name = \"demographic_parity_2\",     aggregate = diff_range   )"},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Demographic parity ‚Äî demographic_parity","text":"Agarwal, ., Beygelzimer, ., Dudik, M., Langford, J., & Wallach, H. (2018). \"Reductions Approach Fair Classification.\" Proceedings 35th International Conference Machine Learning, Proceedings Machine Learning Research. 80:60-69. Verma, S., & Rubin, J. (2018). \"Fairness definitions explained\". Proceedings international workshop software fairness (pp. 1-7). Bird, S., Dud√≠k, M., Edgar, R., Horn, B., Lutz, R., Milan, V., ... & Walker, K. (2020). \"Fairlearn: toolkit assessing improving fairness AI\". Microsoft, Tech. Rep. MSR-TR-2020-32.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/demographic_parity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Demographic parity ‚Äî demographic_parity","text":"","code":"library(dplyr)  data(hpc_cv)  head(hpc_cv) #>   obs pred        VF          F           M            L Resample #> 1  VF   VF 0.9136340 0.07786694 0.008479147 1.991225e-05   Fold01 #> 2  VF   VF 0.9380672 0.05710623 0.004816447 1.011557e-05   Fold01 #> 3  VF   VF 0.9473710 0.04946767 0.003156287 4.999849e-06   Fold01 #> 4  VF   VF 0.9289077 0.06528949 0.005787179 1.564496e-05   Fold01 #> 5  VF   VF 0.9418764 0.05430830 0.003808013 7.294581e-06   Fold01 #> 6  VF   VF 0.9510978 0.04618223 0.002716177 3.841455e-06   Fold01  # evaluate `demographic_parity()` by Resample m_set <- metric_set(demographic_parity(Resample))  # use output like any other metric set hpc_cv %>%   m_set(truth = obs, estimate = pred) #> # A tibble: 1 √ó 4 #>   .metric            .by      .estimator .estimate #>   <chr>              <chr>    <chr>          <dbl> #> 1 demographic_parity Resample macro       2.78e-17  # can mix fairness metrics and regular metrics m_set_2 <- metric_set(sens, demographic_parity(Resample))  hpc_cv %>%   m_set_2(truth = obs, estimate = pred) #> # A tibble: 2 √ó 4 #>   .metric            .estimator .estimate .by      #>   <chr>              <chr>          <dbl> <chr>    #> 1 sens               macro       5.60e- 1 NA       #> 2 demographic_parity macro       2.78e-17 Resample"},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":null,"dir":"Reference","previous_headings":"","what":"Detection prevalence ‚Äî detection_prevalence","title":"Detection prevalence ‚Äî detection_prevalence","text":"Detection prevalence defined number predicted positive events (true positive false positive) divided total number predictions.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detection prevalence ‚Äî detection_prevalence","text":"","code":"detection_prevalence(data, ...)  # S3 method for class 'data.frame' detection_prevalence(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  detection_prevalence_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detection prevalence ‚Äî detection_prevalence","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detection prevalence ‚Äî detection_prevalence","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. detection_prevalence_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Detection prevalence ‚Äî detection_prevalence","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Detection prevalence ‚Äî detection_prevalence","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detection prevalence ‚Äî detection_prevalence","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/detection_prevalence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detection prevalence ‚Äî detection_prevalence","text":"","code":"# Two class data(\"two_class_example\") detection_prevalence(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric              .estimator .estimate #>   <chr>                <chr>          <dbl> #> 1 detection_prevalence binary         0.554  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   detection_prevalence(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric              .estimator .estimate #>   <chr>                <chr>          <dbl> #> 1 detection_prevalence macro           0.25  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   detection_prevalence(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric              .estimator .estimate #>    <chr>    <chr>                <chr>          <dbl> #>  1 Fold01   detection_prevalence macro           0.25 #>  2 Fold02   detection_prevalence macro           0.25 #>  3 Fold03   detection_prevalence macro           0.25 #>  4 Fold04   detection_prevalence macro           0.25 #>  5 Fold05   detection_prevalence macro           0.25 #>  6 Fold06   detection_prevalence macro           0.25 #>  7 Fold07   detection_prevalence macro           0.25 #>  8 Fold08   detection_prevalence macro           0.25 #>  9 Fold09   detection_prevalence macro           0.25 #> 10 Fold10   detection_prevalence macro           0.25  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   detection_prevalence(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric              .estimator     .estimate #>    <chr>    <chr>                <chr>              <dbl> #>  1 Fold01   detection_prevalence macro_weighted     0.413 #>  2 Fold02   detection_prevalence macro_weighted     0.409 #>  3 Fold03   detection_prevalence macro_weighted     0.404 #>  4 Fold04   detection_prevalence macro_weighted     0.411 #>  5 Fold05   detection_prevalence macro_weighted     0.407 #>  6 Fold06   detection_prevalence macro_weighted     0.411 #>  7 Fold07   detection_prevalence macro_weighted     0.405 #>  8 Fold08   detection_prevalence macro_weighted     0.406 #>  9 Fold09   detection_prevalence macro_weighted     0.402 #> 10 Fold10   detection_prevalence macro_weighted     0.408  # Vector version detection_prevalence_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.554  # Making Class2 the \"relevant\" level detection_prevalence_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.446"},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer helpers ‚Äî developer-helpers","title":"Developer helpers ‚Äî developer-helpers","text":"Helpers used alongside check_metric, yardstick_remove_missing metric summarizers creating new metrics. See Custom performance metrics information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer helpers ‚Äî developer-helpers","text":"","code":"dots_to_estimate(data, ...)  get_weights(data, estimator)  finalize_estimator(   x,   estimator = NULL,   metric_class = \"default\",   call = caller_env() )  finalize_estimator_internal(   metric_dispatcher,   x,   estimator,   call = caller_env() )  validate_estimator(estimator, estimator_override = NULL, call = caller_env())"},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer helpers ‚Äî developer-helpers","text":"data table truth values columns predicted values rows. ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. estimator Either NULL auto-selection, single character type estimator use. x column used autoselect estimator. generally truth column, can also table metric table methods. metric_class single character name metric autoselect estimator . match method name created finalize_estimator_internal(). call execution environment currently running function, e.g. caller_env(). function mentioned error messages source error. See call argument abort() information. metric_dispatcher simple dummy object class provided metric_class. created passed along . estimator_override character vector overriding default allowed estimator list c(\"binary\", \"macro\", \"micro\", \"macro_weighted\"). Set classification estimator support methods.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"dots-gt-estimate","dir":"Reference","previous_headings":"","what":"Dots -> Estimate","title":"Developer helpers ‚Äî developer-helpers","text":"dots_to_estimate() useful class probability metrics take ... rather estimate argument. constructs either single name 1 input provided ... constructs quosure expression constructs matrix many columns provided .... eventually evaluated summarise() call metric-summarizers evaluate either vector matrix use underlying vector functions.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"weight-calculation","dir":"Reference","previous_headings":"","what":"Weight Calculation","title":"Developer helpers ‚Äî developer-helpers","text":"get_weights() accepts confusion matrix estimator type \"macro\", \"micro\", \"macro_weighted\" returns correct weights. useful creating multiclass metrics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"estimator-selection","dir":"Reference","previous_headings":"","what":"Estimator Selection","title":"Developer helpers ‚Äî developer-helpers","text":"finalize_estimator() engine auto-selection estimator based type x. Generally x truth column. function called vector method metric. finalize_estimator_internal() S3 generic extend metric implement following estimator types: \"binary\", \"macro\", \"micro\", \"macro_weighted\". metric support , default version finalize_estimator_internal() autoselect estimator appropriately. need create method, take form: finalize_estimator_internal.metric_name. method finalize_estimator_internal() two things: estimator NULL, autoselect estimator based type x return single character estimator. estimator NULL, validate allowed estimator metric return . using default finalize_estimator_internal(), estimator selected using following heuristics: estimator NULL, validated returned immediately auto-selection needed. x : factor - \"binary\" returned 2 levels, otherwise \"macro\" returned. numeric - \"binary\" returned. table - \"binary\" returned 2 columns, otherwise \"macro\" returned. useful table methods. matrix - \"macro\" returned.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/developer-helpers.html","id":"estimator-validation","dir":"Reference","previous_headings":"","what":"Estimator Validation","title":"Developer helpers ‚Äî developer-helpers","text":"validate_estimator() called metric specific method finalize_estimator_internal() ensures user provided estimator right format one allowed values.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":null,"dir":"Reference","previous_headings":"","what":"Equal opportunity ‚Äî equal_opportunity","title":"Equal opportunity ‚Äî equal_opportunity","text":"Equal opportunity satisfied model's predictions true positive false negative rates across protected groups. value 0 indicates parity across groups. equal_opportunity() calculated difference largest smallest value sens() across groups. Equal opportunity sometimes referred equality opportunity. See \"Measuring Disparity\" section details implementation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equal opportunity ‚Äî equal_opportunity","text":"","code":"equal_opportunity(by)"},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equal opportunity ‚Äî equal_opportunity","text":"column identifier sensitive feature. unquoted column name referring column un-preprocessed data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Equal opportunity ‚Äî equal_opportunity","text":"function outputs yardstick fairness metric function. Given grouping variable , equal_opportunity() return yardstick metric function associated data-variable grouping post-processor. outputted function first generate set sens metric values group summarizing across groups using post-processing function. outputted function data frame method intended used part metric set.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"measuring-disparity","dir":"Reference","previous_headings":"","what":"Measuring Disparity","title":"Equal opportunity ‚Äî equal_opportunity","text":"default, function takes difference range sens .estimates across groups. , maximum pair-wise disparity groups return value equal_opportunity()'s .estimate. finer control group treatment, construct context-aware fairness metric new_groupwise_metric() function passing custom aggregate function:   aggregate(), x metric_set() output sens values group, ... gives additional arguments (grouping level refer \"baseline\") pass function outputted equal_opportunity_2() context.","code":"# the actual default `aggregate` is: diff_range <- function(x, ...) {diff(range(x$.estimate))}  equal_opportunity_2 <-   new_groupwise_metric(     fn = sens,     name = \"equal_opportunity_2\",     aggregate = diff_range   )"},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Equal opportunity ‚Äî equal_opportunity","text":"Hardt, M., Price, E., & Srebro, N. (2016). \"Equality opportunity supervised learning\". Advances neural information processing systems, 29. Verma, S., & Rubin, J. (2018). \"Fairness definitions explained\". Proceedings international workshop software fairness (pp. 1-7). Bird, S., Dud√≠k, M., Edgar, R., Horn, B., Lutz, R., Milan, V., ... & Walker, K. (2020). \"Fairlearn: toolkit assessing improving fairness AI\". Microsoft, Tech. Rep. MSR-TR-2020-32.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/equal_opportunity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equal opportunity ‚Äî equal_opportunity","text":"","code":"library(dplyr)  data(hpc_cv)  head(hpc_cv) #>   obs pred        VF          F           M            L Resample #> 1  VF   VF 0.9136340 0.07786694 0.008479147 1.991225e-05   Fold01 #> 2  VF   VF 0.9380672 0.05710623 0.004816447 1.011557e-05   Fold01 #> 3  VF   VF 0.9473710 0.04946767 0.003156287 4.999849e-06   Fold01 #> 4  VF   VF 0.9289077 0.06528949 0.005787179 1.564496e-05   Fold01 #> 5  VF   VF 0.9418764 0.05430830 0.003808013 7.294581e-06   Fold01 #> 6  VF   VF 0.9510978 0.04618223 0.002716177 3.841455e-06   Fold01  # evaluate `equal_opportunity()` by Resample m_set <- metric_set(equal_opportunity(Resample))  # use output like any other metric set hpc_cv %>%   m_set(truth = obs, estimate = pred) #> # A tibble: 1 √ó 4 #>   .metric           .by      .estimator .estimate #>   <chr>             <chr>    <chr>          <dbl> #> 1 equal_opportunity Resample macro          0.103  # can mix fairness metrics and regular metrics m_set_2 <- metric_set(sens, equal_opportunity(Resample))  hpc_cv %>%   m_set_2(truth = obs, estimate = pred) #> # A tibble: 2 √ó 4 #>   .metric           .estimator .estimate .by      #>   <chr>             <chr>          <dbl> <chr>    #> 1 sens              macro          0.560 NA       #> 2 equal_opportunity macro          0.103 Resample"},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":null,"dir":"Reference","previous_headings":"","what":"Equalized odds ‚Äî equalized_odds","title":"Equalized odds ‚Äî equalized_odds","text":"Equalized odds satisfied model's predictions false positive, true positive, false negative, true negative rates across protected groups. value 0 indicates parity across groups. default, function takes maximum difference range sens() spec() .estimates across groups. , maximum pair-wise disparity sens() spec() groups return value equalized_odds()'s .estimate. Equalized odds sometimes referred conditional procedure accuracy equality disparate mistreatment. See \"Measuring disparity\" section details implementation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equalized odds ‚Äî equalized_odds","text":"","code":"equalized_odds(by)"},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equalized odds ‚Äî equalized_odds","text":"column identifier sensitive feature. unquoted column name referring column un-preprocessed data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Equalized odds ‚Äî equalized_odds","text":"function outputs yardstick fairness metric function. Given grouping variable , equalized_odds() return yardstick metric function associated data-variable grouping post-processor. outputted function first generate set sens() spec() metric values group summarizing across groups using post-processing function. outputted function data frame method intended used part metric set.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"measuring-disparity","dir":"Reference","previous_headings":"","what":"Measuring Disparity","title":"Equalized odds ‚Äî equalized_odds","text":"finer control group treatment, construct context-aware fairness metric new_groupwise_metric() function passing custom aggregate function:   aggregate(), x metric_set() output sens() spec() values group, ... gives additional arguments (grouping level refer \"baseline\") pass function outputted equalized_odds_2() context.","code":"# see yardstick:::max_positive_rate_diff for the actual `aggregate()` diff_range <- function(x, ...) {diff(range(x$.estimate))}  equalized_odds_2 <-   new_groupwise_metric(     fn = metric_set(sens, spec),     name = \"equalized_odds_2\",     aggregate = diff_range   )"},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Equalized odds ‚Äî equalized_odds","text":"Agarwal, ., Beygelzimer, ., Dudik, M., Langford, J., & Wallach, H. (2018). \"Reductions Approach Fair Classification.\" Proceedings 35th International Conference Machine Learning, Proceedings Machine Learning Research. 80:60-69. Verma, S., & Rubin, J. (2018). \"Fairness definitions explained\". Proceedings international workshop software fairness (pp. 1-7). Bird, S., Dud√≠k, M., Edgar, R., Horn, B., Lutz, R., Milan, V., ... & Walker, K. (2020). \"Fairlearn: toolkit assessing improving fairness AI\". Microsoft, Tech. Rep. MSR-TR-2020-32.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/equalized_odds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equalized odds ‚Äî equalized_odds","text":"","code":"library(dplyr)  data(hpc_cv)  head(hpc_cv) #>   obs pred        VF          F           M            L Resample #> 1  VF   VF 0.9136340 0.07786694 0.008479147 1.991225e-05   Fold01 #> 2  VF   VF 0.9380672 0.05710623 0.004816447 1.011557e-05   Fold01 #> 3  VF   VF 0.9473710 0.04946767 0.003156287 4.999849e-06   Fold01 #> 4  VF   VF 0.9289077 0.06528949 0.005787179 1.564496e-05   Fold01 #> 5  VF   VF 0.9418764 0.05430830 0.003808013 7.294581e-06   Fold01 #> 6  VF   VF 0.9510978 0.04618223 0.002716177 3.841455e-06   Fold01  # evaluate `equalized_odds()` by Resample m_set <- metric_set(equalized_odds(Resample))  # use output like any other metric set hpc_cv %>%   m_set(truth = obs, estimate = pred) #> # A tibble: 1 √ó 4 #>   .metric        .by      .estimator .estimate #>   <chr>          <chr>    <chr>          <dbl> #> 1 equalized_odds Resample macro          0.103  # can mix fairness metrics and regular metrics m_set_2 <- metric_set(sens, equalized_odds(Resample))  hpc_cv %>%   m_set_2(truth = obs, estimate = pred) #> # A tibble: 2 √ó 4 #>   .metric        .estimator .estimate .by      #>   <chr>          <chr>          <dbl> <chr>    #> 1 sens           macro          0.560 NA       #> 2 equalized_odds macro          0.103 Resample"},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":null,"dir":"Reference","previous_headings":"","what":"F Measure ‚Äî f_meas","title":"F Measure ‚Äî f_meas","text":"functions calculate f_meas() measurement system finding relevant documents compared reference results (truth regarding relevance). Highly related functions recall() precision().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"F Measure ‚Äî f_meas","text":"","code":"f_meas(data, ...)  # S3 method for class 'data.frame' f_meas(   data,   truth,   estimate,   beta = 1,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  f_meas_vec(   truth,   estimate,   beta = 1,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"F Measure ‚Äî f_meas","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. beta numeric value used weight precision recall. value 1 traditionally used corresponds harmonic mean two values values weight recall beta times important precision. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"F Measure ‚Äî f_meas","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. f_meas_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"F Measure ‚Äî f_meas","text":"measure \"F\" combination precision recall (see ).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"F Measure ‚Äî f_meas","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"F Measure ‚Äî f_meas","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"F Measure ‚Äî f_meas","text":"Suppose 2x2 table notation: formulas used : $$recall = /(+C)$$ $$precision = /(+B)$$ $$F_{meas} = (1+\\beta^2) * precision * recall/((\\beta^2 * precision)+recall)$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"F Measure ‚Äî f_meas","text":"Buckland, M., & Gey, F. (1994). relationship Recall Precision. Journal American Society Information Science, 45(1), 12-19. Powers, D. (2007). Evaluation: Precision, Recall F Factor ROC, Informedness, Markedness Correlation. Technical Report SIE-07-001, Flinders University","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"F Measure ‚Äî f_meas","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/f_meas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"F Measure ‚Äî f_meas","text":"","code":"# Two class data(\"two_class_example\") f_meas(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 f_meas  binary         0.849  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   f_meas(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 f_meas  macro          0.563  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   f_meas(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   f_meas  macro          0.563 #>  2 Fold02   f_meas  macro          0.542 #>  3 Fold03   f_meas  macro          0.641 #>  4 Fold04   f_meas  macro          0.593 #>  5 Fold05   f_meas  macro          0.570 #>  6 Fold06   f_meas  macro          0.554 #>  7 Fold07   f_meas  macro          0.516 #>  8 Fold08   f_meas  macro          0.601 #>  9 Fold09   f_meas  macro          0.555 #> 10 Fold10   f_meas  macro          0.560  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   f_meas(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   f_meas  macro_weighted     0.696 #>  2 Fold02   f_meas  macro_weighted     0.684 #>  3 Fold03   f_meas  macro_weighted     0.739 #>  4 Fold04   f_meas  macro_weighted     0.689 #>  5 Fold05   f_meas  macro_weighted     0.692 #>  6 Fold06   f_meas  macro_weighted     0.673 #>  7 Fold07   f_meas  macro_weighted     0.646 #>  8 Fold08   f_meas  macro_weighted     0.701 #>  9 Fold09   f_meas  macro_weighted     0.652 #> 10 Fold10   f_meas  macro_weighted     0.680  # Vector version f_meas_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.8485981  # Making Class2 the \"relevant\" level f_meas_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.8258065"},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":null,"dir":"Reference","previous_headings":"","what":"Gain capture ‚Äî gain_capture","title":"Gain capture ‚Äî gain_capture","text":"gain_capture() measure performance similar AUC calculation, applied gain curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gain capture ‚Äî gain_capture","text":"","code":"gain_capture(data, ...)  # S3 method for class 'data.frame' gain_capture(   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )  gain_capture_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gain capture ‚Äî gain_capture","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimator One \"binary\", \"macro\", \"macro_weighted\" specify type averaging done. \"binary\" relevant two class case. two general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based truth. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gain capture ‚Äî gain_capture","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. gain_capture_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gain capture ‚Äî gain_capture","text":"gain_capture() calculates area gain curve, baseline, divides area perfect gain curve, baseline. meant represent amount potential gain \"captured\" model. gain_capture() metric identical accuracy ratio (AR), also sometimes called gini coefficient. two generally calculated cumulative accuracy profile curve, gain curve. See Engelmann reference information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Gain capture ‚Äî gain_capture","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Gain capture ‚Äî gain_capture","text":"Macro macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gain capture ‚Äî gain_capture","text":"Engelmann, Bernd & Hayden, Evelyn & Tasche, Dirk (2003). \"Measuring Discriminative Power Rating Systems,\" Discussion Paper Series 2: Banking Financial Studies 2003,01, Deutsche Bundesbank.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gain capture ‚Äî gain_capture","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_capture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gain capture ‚Äî gain_capture","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. gain_capture(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric      .estimator .estimate #>   <chr>        <chr>          <dbl> #> 1 gain_capture binary         0.879  # --------------------------------------------------------------------------- # Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   gain_capture(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric      .estimator .estimate #>   <chr>        <chr>          <dbl> #> 1 gain_capture macro          0.743  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   gain_capture(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric      .estimator .estimate #>   <chr>        <chr>          <dbl> #> 1 gain_capture macro          0.743  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   gain_capture(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric      .estimator .estimate #>    <chr>    <chr>        <chr>          <dbl> #>  1 Fold01   gain_capture macro          0.743 #>  2 Fold02   gain_capture macro          0.727 #>  3 Fold03   gain_capture macro          0.796 #>  4 Fold04   gain_capture macro          0.748 #>  5 Fold05   gain_capture macro          0.730 #>  6 Fold06   gain_capture macro          0.754 #>  7 Fold07   gain_capture macro          0.730 #>  8 Fold08   gain_capture macro          0.747 #>  9 Fold09   gain_capture macro          0.710 #> 10 Fold10   gain_capture macro          0.731  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   gain_capture(obs, VF:L, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric      .estimator     .estimate #>    <chr>    <chr>        <chr>              <dbl> #>  1 Fold01   gain_capture macro_weighted     0.759 #>  2 Fold02   gain_capture macro_weighted     0.745 #>  3 Fold03   gain_capture macro_weighted     0.811 #>  4 Fold04   gain_capture macro_weighted     0.734 #>  5 Fold05   gain_capture macro_weighted     0.733 #>  6 Fold06   gain_capture macro_weighted     0.730 #>  7 Fold07   gain_capture macro_weighted     0.737 #>  8 Fold08   gain_capture macro_weighted     0.730 #>  9 Fold09   gain_capture macro_weighted     0.681 #> 10 Fold10   gain_capture macro_weighted     0.737  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  gain_capture_vec(    truth = fold1$obs,    matrix(      c(fold1$VF, fold1$F, fold1$M, fold1$L),      ncol = 4    ) ) #> [1] 0.7428922  # --------------------------------------------------------------------------- # Visualize gain_capture()  # Visually, this represents the area under the black curve, but above the # 45 degree line, divided by the area of the shaded triangle. library(ggplot2) autoplot(gain_curve(two_class_example, truth, Class1))"},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Gain curve ‚Äî gain_curve","title":"Gain curve ‚Äî gain_curve","text":"gain_curve() constructs full gain curve returns tibble. See gain_capture() relevant area gain curve. Also see lift_curve() closely related concept.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gain curve ‚Äî gain_curve","text":"","code":"gain_curve(data, ...)  # S3 method for class 'data.frame' gain_curve(   data,   truth,   ...,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )"},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gain curve ‚Äî gain_curve","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gain curve ‚Äî gain_curve","text":"tibble class gain_df gain_grouped_df columns: .n index current sample. .n_events index current unique sample. Values repeated estimate values given identical indices column. .percent_tested cumulative percentage values tested. .percent_found cumulative percentage true results relative total number true results. using case_weights argument, columns weighted. makes sense frequency weights, integer weights representing number times particular observation repeated.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gain curve ‚Äî gain_curve","text":"ggplot2::autoplot() method quickly visualizing curve. works binary multiclass output, also works grouped data (.e. resamples). See examples. greater area gain curve baseline, better model. Gain curves identical CAP curves (cumulative accuracy profile). See Engelmann reference information CAP curves.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"gain-and-lift-curves","dir":"Reference","previous_headings":"","what":"Gain and Lift Curves","title":"Gain curve ‚Äî gain_curve","text":"motivation behind cumulative gain lift charts visual method determine effectiveness model compared results one might expect without model. example, without model, advertise random 10% customer base, might expect capture 10% total number positive responses advertised entire customer base. Given model predicts customers likely respond, hope can accurately target 10% customer base capture >10% total number positive responses. calculation construct gain curves follows: truth estimate placed descending order estimate values (estimate single column supplied ...). cumulative number samples true results relative entire number true results found. y-axis gain chart.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Gain curve ‚Äî gain_curve","text":"multiclass truth column provided, one-vs-approach taken calculate multiple curves, one per level. case, additional column, .level, identifying \"one\" column one-vs-calculation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Gain curve ‚Äî gain_curve","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gain curve ‚Äî gain_curve","text":"Engelmann, Bernd & Hayden, Evelyn & Tasche, Dirk (2003). \"Measuring Discriminative Power Rating Systems,\" Discussion Paper Series 2: Banking Financial Studies 2003,01, Deutsche Bundesbank.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gain curve ‚Äî gain_curve","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/gain_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gain curve ‚Äî gain_curve","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. gain_curve(two_class_example, truth, Class1) #> # A tibble: 501 √ó 4 #>       .n .n_events .percent_tested .percent_found #>    <dbl>     <dbl>           <dbl>          <dbl> #>  1     0         0             0            0     #>  2     1         1             0.2          0.388 #>  3     2         2             0.4          0.775 #>  4     3         3             0.6          1.16  #>  5     4         4             0.8          1.55  #>  6     5         5             1            1.94  #>  7     6         6             1.2          2.33  #>  8     7         7             1.4          2.71  #>  9     8         8             1.6          3.10  #> 10     9         9             1.8          3.49  #> # ‚Ñπ 491 more rows  # --------------------------------------------------------------------------- # `autoplot()`  library(ggplot2) library(dplyr)  # Use autoplot to visualize # The top left hand corner of the grey triangle is a \"perfect\" gain curve autoplot(gain_curve(two_class_example, truth, Class1))   # Multiclass one-vs-all approach # One curve per level hpc_cv %>%   filter(Resample == \"Fold01\") %>%   gain_curve(obs, VF:L) %>%   autoplot()   # Same as above, but will all of the resamples # The resample with the minimum (farthest to the left) \"perfect\" value is # used to draw the shaded region hpc_cv %>%   group_by(Resample) %>%   gain_curve(obs, VF:L) %>%   autoplot()"},{"path":"https://yardstick.tidymodels.org/dev/reference/hpc_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiclass Probability Predictions ‚Äî hpc_cv","title":"Multiclass Probability Predictions ‚Äî hpc_cv","text":"Multiclass Probability Predictions","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/hpc_cv.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Multiclass Probability Predictions ‚Äî hpc_cv","text":"Kuhn, M., Johnson, K. (2013) Applied Predictive Modeling, Springer","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/hpc_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiclass Probability Predictions ‚Äî hpc_cv","text":"hpc_cv data frame","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/hpc_cv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiclass Probability Predictions ‚Äî hpc_cv","text":"data frame contains predicted classes class probabilities linear discriminant analysis model fit HPC data set Kuhn Johnson (2013). data assessment sets 10-fold cross-validation scheme. data column columns true class (obs), class prediction (pred) columns class probability (columns VF, F, M, L). Additionally, column resample indicator included.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/hpc_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiclass Probability Predictions ‚Äî hpc_cv","text":"","code":"data(hpc_cv) str(hpc_cv) #> 'data.frame':\t3467 obs. of  7 variables: #>  $ obs     : Factor w/ 4 levels \"VF\",\"F\",\"M\",\"L\": 1 1 1 1 1 1 1 1 1 1 ... #>  $ pred    : Factor w/ 4 levels \"VF\",\"F\",\"M\",\"L\": 1 1 1 1 1 1 1 1 1 1 ... #>  $ VF      : num  0.914 0.938 0.947 0.929 0.942 ... #>  $ F       : num  0.0779 0.0571 0.0495 0.0653 0.0543 ... #>  $ M       : num  0.00848 0.00482 0.00316 0.00579 0.00381 ... #>  $ L       : num  1.99e-05 1.01e-05 5.00e-06 1.56e-05 7.29e-06 ... #>  $ Resample: chr  \"Fold01\" \"Fold01\" \"Fold01\" \"Fold01\" ...  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section in any classification function (such as `?pr_auc`) to see how # to change this. levels(hpc_cv$obs) #> [1] \"VF\" \"F\"  \"M\"  \"L\""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Huber loss ‚Äî huber_loss","title":"Huber loss ‚Äî huber_loss","text":"Calculate Huber loss, loss function used robust regression. loss function less sensitive outliers rmse(). function quadratic small residual values linear large residual values.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Huber loss ‚Äî huber_loss","text":"","code":"huber_loss(data, ...)  # S3 method for class 'data.frame' huber_loss(   data,   truth,   estimate,   delta = 1,   na_rm = TRUE,   case_weights = NULL,   ... )  huber_loss_vec(   truth,   estimate,   delta = 1,   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Huber loss ‚Äî huber_loss","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. delta single numeric value. Defines boundary loss function transitions quadratic linear. Defaults 1. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Huber loss ‚Äî huber_loss","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. huber_loss_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Huber loss ‚Äî huber_loss","text":"Huber, P. (1964). Robust Estimation Location Parameter. Annals Statistics, 53 (1), 73-101.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Huber loss ‚Äî huber_loss","text":"James Blair","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Huber loss ‚Äî huber_loss","text":"","code":"# Supply truth and predictions as bare column names huber_loss(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric    .estimator .estimate #>   <chr>      <chr>          <dbl> #> 1 huber_loss standard       0.234  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   huber_loss(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric    .estimator .estimate #>    <chr>    <chr>      <chr>          <dbl> #>  1 1        huber_loss standard       0.215 #>  2 10       huber_loss standard       0.212 #>  3 2        huber_loss standard       0.229 #>  4 3        huber_loss standard       0.197 #>  5 4        huber_loss standard       0.249 #>  6 5        huber_loss standard       0.208 #>  7 6        huber_loss standard       0.293 #>  8 7        huber_loss standard       0.268 #>  9 8        huber_loss standard       0.190 #> 10 9        huber_loss standard       0.218  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.228"},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":null,"dir":"Reference","previous_headings":"","what":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"Calculate Pseudo-Huber Loss, smooth approximation huber_loss(). Like huber_loss(), less sensitive outliers rmse().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"","code":"huber_loss_pseudo(data, ...)  # S3 method for class 'data.frame' huber_loss_pseudo(   data,   truth,   estimate,   delta = 1,   na_rm = TRUE,   case_weights = NULL,   ... )  huber_loss_pseudo_vec(   truth,   estimate,   delta = 1,   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. delta single numeric value. Defines boundary loss function transitions quadratic linear. Defaults 1. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. huber_loss_pseudo_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"Huber, P. (1964). Robust Estimation Location Parameter. Annals Statistics, 53 (1), 73-101. Hartley, Richard (2004). Multiple View Geometry Computer Vision. (Second Edition). Page 619.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"James Blair","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/huber_loss_pseudo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Psuedo-Huber Loss ‚Äî huber_loss_pseudo","text":"","code":"# Supply truth and predictions as bare column names huber_loss_pseudo(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric           .estimator .estimate #>   <chr>             <chr>          <dbl> #> 1 huber_loss_pseudo standard       0.199  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   huber_loss_pseudo(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric           .estimator .estimate #>    <chr>    <chr>             <chr>          <dbl> #>  1 1        huber_loss_pseudo standard       0.185 #>  2 10       huber_loss_pseudo standard       0.179 #>  3 2        huber_loss_pseudo standard       0.196 #>  4 3        huber_loss_pseudo standard       0.168 #>  5 4        huber_loss_pseudo standard       0.212 #>  6 5        huber_loss_pseudo standard       0.177 #>  7 6        huber_loss_pseudo standard       0.246 #>  8 7        huber_loss_pseudo standard       0.227 #>  9 8        huber_loss_pseudo standard       0.161 #> 10 9        huber_loss_pseudo standard       0.188  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.194"},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":null,"dir":"Reference","previous_headings":"","what":"Index of ideality of correlation ‚Äî iic","title":"Index of ideality of correlation ‚Äî iic","text":"Calculate index ideality correlation. metric studied QSPR/QSAR models good criterion predictive potential models. highly dependent correlation coefficient well mean absolute error. Note application IIC useless two conditions: negative mean absolute error positive mean absolute error zero. outliers symmetric. Since outliers context dependent, please use checks validate whether restriction holds whether resulting IIC interpretative value. IIC seen alternative traditional correlation coefficient units original data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index of ideality of correlation ‚Äî iic","text":"","code":"iic(data, ...)  # S3 method for class 'data.frame' iic(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  iic_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index of ideality of correlation ‚Äî iic","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Index of ideality of correlation ‚Äî iic","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. iic_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Index of ideality of correlation ‚Äî iic","text":"Toropova, . Toropov, . (2017). \"index ideality correlation. criterion predictability QSAR models skin permeability?\" Science Total Environment. 586: 466-472.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Index of ideality of correlation ‚Äî iic","text":"Joyce Cahoon","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/iic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Index of ideality of correlation ‚Äî iic","text":"","code":"# Supply truth and predictions as bare column names iic(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 iic     standard       0.890  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   iic(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        iic     standard       0.730 #>  2 10       iic     standard       0.731 #>  3 2        iic     standard       0.906 #>  4 3        iic     standard       0.877 #>  5 4        iic     standard       0.732 #>  6 5        iic     standard       0.821 #>  7 6        iic     standard       0.896 #>  8 7        iic     standard       0.867 #>  9 8        iic     standard       0.881 #> 10 9        iic     standard       0.748  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.819"},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":null,"dir":"Reference","previous_headings":"","what":"J-index ‚Äî j_index","title":"J-index ‚Äî j_index","text":"Youden's J statistic defined : sens() + spec() - 1 related metric Informedness, see Details section relationship.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"J-index ‚Äî j_index","text":"","code":"j_index(data, ...)  # S3 method for class 'data.frame' j_index(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  j_index_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"J-index ‚Äî j_index","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"J-index ‚Äî j_index","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. j_index_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"J-index ‚Äî j_index","text":"value J-index ranges [0, 1] 1 false positives false negatives. binary version J-index equivalent binary concept Informedness. Macro-weighted J-index equivalent multiclass informedness defined Powers, David M W (2011), equation (42).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"J-index ‚Äî j_index","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"J-index ‚Äî j_index","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"J-index ‚Äî j_index","text":"Youden, W.J. (1950). \"Index rating diagnostic tests\". Cancer. 3: 32-35. Powers, David M W (2011). \"Evaluation: Precision, Recall F-Score ROC, Informedness, Markedness Correlation\". Journal Machine Learning Technologies. 2 (1): 37-63.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"J-index ‚Äî j_index","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/j_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"J-index ‚Äî j_index","text":"","code":"# Two class data(\"two_class_example\") j_index(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 j_index binary         0.673  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   j_index(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 j_index macro          0.434  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   j_index(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   j_index macro          0.434 #>  2 Fold02   j_index macro          0.422 #>  3 Fold03   j_index macro          0.533 #>  4 Fold04   j_index macro          0.449 #>  5 Fold05   j_index macro          0.431 #>  6 Fold06   j_index macro          0.413 #>  7 Fold07   j_index macro          0.398 #>  8 Fold08   j_index macro          0.468 #>  9 Fold09   j_index macro          0.435 #> 10 Fold10   j_index macro          0.412  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   j_index(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   j_index macro_weighted     0.542 #>  2 Fold02   j_index macro_weighted     0.527 #>  3 Fold03   j_index macro_weighted     0.597 #>  4 Fold04   j_index macro_weighted     0.515 #>  5 Fold05   j_index macro_weighted     0.524 #>  6 Fold06   j_index macro_weighted     0.492 #>  7 Fold07   j_index macro_weighted     0.466 #>  8 Fold08   j_index macro_weighted     0.535 #>  9 Fold09   j_index macro_weighted     0.468 #> 10 Fold10   j_index macro_weighted     0.501  # Vector version j_index_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.6732334  # Making Class2 the \"relevant\" level j_index_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.6732334"},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":null,"dir":"Reference","previous_headings":"","what":"Kappa ‚Äî kap","title":"Kappa ‚Äî kap","text":"Kappa similar measure accuracy(), normalized accuracy expected chance alone useful one classes large frequency distributions.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kappa ‚Äî kap","text":"","code":"kap(data, ...)  # S3 method for class 'data.frame' kap(   data,   truth,   estimate,   weighting = \"none\",   na_rm = TRUE,   case_weights = NULL,   ... )  kap_vec(   truth,   estimate,   weighting = \"none\",   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kappa ‚Äî kap","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. weighting weighting apply computing scores. One : \"none\", \"linear\", \"quadratic\". Linear quadratic weighting penalizes mis-predictions \"far away\" true value. Note distance judged based ordering levels truth estimate. recommended provide ordered factors truth estimate explicitly code ordering, required. binary case, 3 weightings produce value, since ever possible 1 unit away true value. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kappa ‚Äî kap","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. kap_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Kappa ‚Äî kap","text":"Kappa extends naturally multiclass scenarios. , macro micro averaging implemented.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kappa ‚Äî kap","text":"Cohen, J. (1960). \"coefficient agreement nominal scales\". Educational Psychological Measurement. 20 (1): 37-46. Cohen, J. (1968). \"Weighted kappa: Nominal scale agreement provision scaled disagreement partial credit\". Psychological Bulletin. 70 (4): 213-220.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Kappa ‚Äî kap","text":"Max Kuhn Jon Harmon","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/kap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kappa ‚Äî kap","text":"","code":"library(dplyr) data(\"two_class_example\") data(\"hpc_cv\")  # Two class kap(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 kap     binary         0.675  # Multiclass # kap() has a natural multiclass extension hpc_cv %>%   filter(Resample == \"Fold01\") %>%   kap(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 kap     multiclass     0.533  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   kap(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   kap     multiclass     0.533 #>  2 Fold02   kap     multiclass     0.512 #>  3 Fold03   kap     multiclass     0.594 #>  4 Fold04   kap     multiclass     0.511 #>  5 Fold05   kap     multiclass     0.514 #>  6 Fold06   kap     multiclass     0.486 #>  7 Fold07   kap     multiclass     0.454 #>  8 Fold08   kap     multiclass     0.531 #>  9 Fold09   kap     multiclass     0.454 #> 10 Fold10   kap     multiclass     0.492"},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Lift curve ‚Äî lift_curve","title":"Lift curve ‚Äî lift_curve","text":"lift_curve() constructs full lift curve returns tibble. See gain_curve() closely related concept.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lift curve ‚Äî lift_curve","text":"","code":"lift_curve(data, ...)  # S3 method for class 'data.frame' lift_curve(   data,   truth,   ...,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )"},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lift curve ‚Äî lift_curve","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lift curve ‚Äî lift_curve","text":"tibble class lift_df lift_grouped_df columns: .n index current sample. .n_events index current unique sample. Values repeated estimate values given identical indices column. .percent_tested cumulative percentage values tested. .lift First calculate cumulative percentage true results relative total number true results. divide .percent_tested. using case_weights argument, columns weighted. makes sense frequency weights, integer weights representing number times particular observation repeated.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lift curve ‚Äî lift_curve","text":"ggplot2::autoplot() method quickly visualizing curve. works binary multiclass output, also works grouped data (.e. resamples). See examples.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"gain-and-lift-curves","dir":"Reference","previous_headings":"","what":"Gain and Lift Curves","title":"Lift curve ‚Äî lift_curve","text":"motivation behind cumulative gain lift charts visual method determine effectiveness model compared results one might expect without model. example, without model, advertise random 10% customer base, might expect capture 10% total number positive responses advertised entire customer base. Given model predicts customers likely respond, hope can accurately target 10% customer base capture >10% total number positive responses. calculation construct lift curves follows: truth estimate placed descending order estimate values (estimate single column supplied ...). cumulative number samples true results relative entire number true results found. cumulative % found divided cumulative % tested construct lift value. ratio represents factor improvement uninformed model. Values >1 represent valuable model. y-axis lift chart.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Lift curve ‚Äî lift_curve","text":"multiclass truth column provided, one-vs-approach taken calculate multiple curves, one per level. case, additional column, .level, identifying \"one\" column one-vs-calculation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Lift curve ‚Äî lift_curve","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lift curve ‚Äî lift_curve","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lift_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lift curve ‚Äî lift_curve","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. lift_curve(two_class_example, truth, Class1) #> # A tibble: 501 √ó 4 #>       .n .n_events .percent_tested  .lift #>    <dbl>     <dbl>           <dbl>  <dbl> #>  1     0         0             0   NaN    #>  2     1         1             0.2   1.94 #>  3     2         2             0.4   1.94 #>  4     3         3             0.6   1.94 #>  5     4         4             0.8   1.94 #>  6     5         5             1     1.94 #>  7     6         6             1.2   1.94 #>  8     7         7             1.4   1.94 #>  9     8         8             1.6   1.94 #> 10     9         9             1.8   1.94 #> # ‚Ñπ 491 more rows  # --------------------------------------------------------------------------- # `autoplot()`  library(ggplot2) library(dplyr)  # Use autoplot to visualize autoplot(lift_curve(two_class_example, truth, Class1))   # Multiclass one-vs-all approach # One curve per level hpc_cv %>%   filter(Resample == \"Fold01\") %>%   lift_curve(obs, VF:L) %>%   autoplot()   # Same as above, but will all of the resamples hpc_cv %>%   group_by(Resample) %>%   lift_curve(obs, VF:L) %>%   autoplot()"},{"path":"https://yardstick.tidymodels.org/dev/reference/lung_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Survival Analysis Results ‚Äî lung_surv","title":"Survival Analysis Results ‚Äî lung_surv","text":"Survival Analysis Results","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lung_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Survival Analysis Results ‚Äî lung_surv","text":"lung_surv data frame","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lung_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Survival Analysis Results ‚Äî lung_surv","text":"data contain plausible results applying predictive survival models  lung data set using censored package.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/lung_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Survival Analysis Results ‚Äî lung_surv","text":"","code":"data(lung_surv) str(lung_surv) #> tibble [228 √ó 3] (S3: tbl_df/tbl/data.frame) #>  $ .pred     :List of 228 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.819 0.597 0.407 0.264 0.164 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 306 306 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.735 0.735 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.36 1.36 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.888 0.737 0.588 0.455 0.344 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 455 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.627 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.59 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.901 0.763 0.625 0.498 0.389 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.845 0.648 0.47 0.326 0.219 #>   .. ..$ .weight_time    : num [1:5] 100 200 210 210 210 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.915 0.915 0.915 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.09 1.09 1.09 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.897 0.755 0.613 0.484 0.374 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.819 0.597 0.407 0.264 0.164 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.841 0.64 0.46 0.316 0.209 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 310 310 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.735 0.735 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.36 1.36 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.837 0.631 0.449 0.305 0.2 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 361 361 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.707 0.707 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.41 1.41 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.851 0.659 0.484 0.341 0.233 #>   .. ..$ .weight_time    : num [1:5] 100 200 218 218 218 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.909 0.909 0.909 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.1 1.1 1.1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7568 0.4871 0.2858 0.1563 0.0806 #>   .. ..$ .weight_time    : num [1:5] 100 166 166 166 166 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.845 0.648 0.47 0.326 0.219 #>   .. ..$ .weight_time    : num [1:5] 100 170 170 170 170 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.841 0.64 0.46 0.316 0.209 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.897 0.755 0.614 0.485 0.374 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] NA NA NA NA NA #>   .. ..$ .weight_time    : num [1:5] 71 71 71 71 71 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.845 0.648 0.47 0.326 0.219 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.83 0.618 0.433 0.289 0.186 #>   .. ..$ .weight_time    : num [1:5] 100 144 144 144 144 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.825 0.609 0.422 0.278 0.176 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7524 0.4799 0.2785 0.1504 0.0765 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.858 0.674 0.503 0.361 0.251 #>   .. ..$ .weight_time    : num [1:5] 61 61 61 61 61 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.845 0.648 0.47 0.326 0.219 #>   .. ..$ .weight_time    : num [1:5] 88 88 88 88 88 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.83 0.618 0.433 0.289 0.186 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 301 301 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.752 0.752 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.33 1.33 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.945 0.865 0.777 0.688 0.602 #>   .. ..$ .weight_time    : num [1:5] 81 81 81 81 81 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.855 0.668 0.495 0.353 0.243 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.899 0.759 0.619 0.491 0.381 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 371 371 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.697 0.697 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.44 1.44 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.884 0.728 0.575 0.44 0.329 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 394 394 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.663 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.51 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.895 0.751 0.607 0.478 0.367 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.897 0.755 0.613 0.484 0.374 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.6149 0.2851 0.1125 0.0392 0.0123 #>   .. ..$ .weight_time    : num [1:5] 100 118 118 118 118 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.851 0.659 0.484 0.341 0.233 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 390 390 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.663 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.51 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7274 0.4398 0.2392 0.12 0.0563 #>   .. ..$ .weight_time    : num [1:5] 12 12 12 12 12 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.896 0.753 0.611 0.481 0.371 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 473 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.73 0.443 0.243 0.123 0.058 #>   .. ..$ .weight_time    : num [1:5] 26 26 26 26 26 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.783 0.533 0.334 0.197 0.11 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.853 0.663 0.489 0.346 0.237 #>   .. ..$ .weight_time    : num [1:5] 100 107 107 107 107 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7568 0.4871 0.2858 0.1563 0.0806 #>   .. ..$ .weight_time    : num [1:5] 53 53 53 53 53 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.85 0.657 0.481 0.338 0.23 #>   .. ..$ .weight_time    : num [1:5] 100 122 122 122 122 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.748 0.4727 0.2713 0.1446 0.0725 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.899 0.76 0.62 0.492 0.382 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7274 0.4398 0.2392 0.12 0.0563 #>   .. ..$ .weight_time    : num [1:5] 93 93 93 93 93 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.995 0.995 0.995 0.995 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.901 0.764 0.626 0.499 0.389 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.825 0.609 0.422 0.278 0.176 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 460 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.834 0.625 0.441 0.297 0.193 #>   .. ..$ .weight_time    : num [1:5] 100 153 153 153 153 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.94 0.851 0.756 0.66 0.569 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 433 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.64 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.56 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.853 0.663 0.489 0.346 0.237 #>   .. ..$ .weight_time    : num [1:5] 100 145 145 145 145 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.829 0.615 0.429 0.286 0.183 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.829 0.616 0.43 0.286 0.183 #>   .. ..$ .weight_time    : num [1:5] 95 95 95 95 95 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.995 0.995 0.995 0.995 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.882 0.723 0.568 0.433 0.321 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 303 303 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.744 0.744 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.34 1.34 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.836 0.63 0.448 0.304 0.199 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.882 0.723 0.568 0.433 0.321 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.914 0.792 0.666 0.548 0.442 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.893 0.747 0.601 0.47 0.359 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.894 0.748 0.604 0.473 0.362 #>   .. ..$ .weight_time    : num [1:5] 100 189 189 189 189 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.954 0.954 0.954 0.954 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.05 1.05 1.05 1.05 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.888 0.737 0.588 0.455 0.344 #>   .. ..$ .weight_time    : num [1:5] 53 53 53 53 53 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.899 0.759 0.619 0.491 0.381 #>   .. ..$ .weight_time    : num [1:5] 100 200 246 246 246 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.845 0.845 0.845 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.18 1.18 1.18 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.842 0.642 0.463 0.319 0.212 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.895 0.751 0.607 0.477 0.366 #>   .. ..$ .weight_time    : num [1:5] 65 65 65 65 65 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.936 0.843 0.743 0.643 0.55 #>   .. ..$ .weight_time    : num [1:5] 5 5 5 5 5 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7653 0.5014 0.3005 0.1683 0.0891 #>   .. ..$ .weight_time    : num [1:5] 100 132 132 132 132 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.907 0.776 0.643 0.52 0.412 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.901 0.764 0.626 0.499 0.389 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 345 345 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.717 0.717 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.39 1.39 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.83 0.619 0.434 0.29 0.187 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 444 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.64 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.56 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.858 0.673 0.502 0.36 0.25 #>   .. ..$ .weight_time    : num [1:5] 100 200 223 223 223 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.895 0.895 0.895 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.12 1.12 1.12 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.82 0.6 0.411 0.267 0.167 #>   .. ..$ .weight_time    : num [1:5] 100 175 175 175 175 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.978 0.978 0.978 0.978 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.02 1.02 1.02 1.02 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.9 0.762 0.623 0.496 0.386 #>   .. ..$ .weight_time    : num [1:5] 60 60 60 60 60 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.827 0.612 0.426 0.282 0.179 #>   .. ..$ .weight_time    : num [1:5] 100 163 163 163 163 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7413 0.4618 0.2605 0.1362 0.0668 #>   .. ..$ .weight_time    : num [1:5] 65 65 65 65 65 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.843 0.643 0.463 0.32 0.213 #>   .. ..$ .weight_time    : num [1:5] 100 200 208 208 208 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.915 0.915 0.915 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.09 1.09 1.09 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.937 0.844 0.745 0.646 0.553 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.888 0.737 0.588 0.455 0.344 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 428 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.64 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.56 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.83 0.618 0.433 0.289 0.186 #>   .. ..$ .weight_time    : num [1:5] 100 200 230 230 230 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.874 0.874 0.874 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.14 1.14 1.14 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.894 0.748 0.604 0.473 0.362 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.915 0.796 0.672 0.554 0.449 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 305 305 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.735 0.735 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.36 1.36 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7274 0.4398 0.2392 0.12 0.0563 #>   .. ..$ .weight_time    : num [1:5] 11 11 11 11 11 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.868 0.694 0.53 0.39 0.279 #>   .. ..$ .weight_time    : num [1:5] 100 132 132 132 132 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.911 0.786 0.658 0.537 0.431 #>   .. ..$ .weight_time    : num [1:5] 100 200 226 226 226 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.874 0.874 0.874 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.14 1.14 1.14 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.894 0.749 0.604 0.474 0.363 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 426 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.64 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.56 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.944 0.862 0.773 0.682 0.595 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.908 0.78 0.649 0.527 0.419 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 363 363 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.707 0.707 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.41 1.41 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.874 0.706 0.545 0.407 0.295 #>   .. ..$ .weight_time    : num [1:5] 11 11 11 11 11 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.883 0.725 0.572 0.437 0.325 #>   .. ..$ .weight_time    : num [1:5] 100 176 176 176 176 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.972 0.972 0.972 0.972 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.03 1.03 1.03 1.03 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.898 0.757 0.616 0.488 0.377 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.848 0.654 0.477 0.334 0.226 #>   .. ..$ .weight_time    : num [1:5] 95 95 95 95 95 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.995 0.995 0.995 0.995 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.866 0.689 0.523 0.383 0.272 #>   .. ..$ .weight_time    : num [1:5] 100 NA NA NA NA #>   .. ..$ .pred_censored  : num [1:5] 0.995 NA NA NA NA #>   .. ..$ .weight_censored: num [1:5] 1.01 NA NA NA NA #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.918 0.803 0.682 0.568 0.464 #>   .. ..$ .weight_time    : num [1:5] 100 167 167 167 167 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.863 0.684 0.516 0.375 0.264 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.824 0.606 0.418 0.275 0.173 #>   .. ..$ .weight_time    : num [1:5] 100 200 284 284 284 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.793 0.793 0.793 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.26 1.26 1.26 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.903 0.768 0.632 0.506 0.397 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.896 0.753 0.61 0.48 0.37 #>   .. ..$ .weight_time    : num [1:5] 100 147 147 147 147 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.918 0.803 0.682 0.568 0.464 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7321 0.4471 0.2462 0.1253 0.0597 #>   .. ..$ .weight_time    : num [1:5] 100 163 163 163 163 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.99 0.99 0.99 0.99 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.01 1.01 1.01 1.01 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.894 0.748 0.604 0.473 0.362 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.825 0.609 0.422 0.278 0.176 #>   .. ..$ .weight_time    : num [1:5] 100 200 239 239 239 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.86 0.86 0.86 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.16 1.16 1.16 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.832 0.621 0.437 0.293 0.189 #>   .. ..$ .weight_time    : num [1:5] 88 88 88 88 88 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.907 0.778 0.646 0.524 0.416 #>   .. ..$ .weight_time    : num [1:5] 100 200 245 245 245 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.845 0.845 0.845 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.18 1.18 1.18 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.933 0.837 0.733 0.632 0.536 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.7321 0.4471 0.2462 0.1253 0.0597 #>   .. ..$ .weight_time    : num [1:5] 30 30 30 30 30 #>   .. ..$ .pred_censored  : num [1:5] 1 1 1 1 1 #>   .. ..$ .weight_censored: num [1:5] 1 1 1 1 1 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.827 0.612 0.426 0.282 0.179 #>   .. ..$ .weight_time    : num [1:5] 100 179 179 179 179 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.966 0.966 0.966 0.966 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.03 1.03 1.03 1.03 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.824 0.606 0.418 0.275 0.173 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 310 310 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.735 0.735 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.36 1.36 #>   ..$ : tibble [5 √ó 5] (S3: tbl_df/tbl/data.frame) #>   .. ..$ .eval_time      : num [1:5] 100 200 300 400 500 #>   .. ..$ .pred_survival  : num [1:5] 0.835 0.627 0.444 0.3 0.196 #>   .. ..$ .weight_time    : num [1:5] 100 200 300 400 477 #>   .. ..$ .pred_censored  : num [1:5] 0.995 0.928 0.76 0.663 0.613 #>   .. ..$ .weight_censored: num [1:5] 1.01 1.08 1.31 1.51 1.63 #>   .. [list output truncated] #>  $ .pred_time: num [1:228] 324 476 521 368 506 ... #>  $ surv_obj  : 'Surv' num [1:228, 1:2]  306   455  1010+  210   883  1022+  310   361   218   166  ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:2] \"time\" \"status\" #>   ..- attr(*, \"type\")= chr \"right\"  # `surv_obj` is a `Surv()` object"},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute error ‚Äî mae","title":"Mean absolute error ‚Äî mae","text":"Calculate mean absolute error. metric units original data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute error ‚Äî mae","text":"","code":"mae(data, ...)  # S3 method for class 'data.frame' mae(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  mae_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean absolute error ‚Äî mae","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean absolute error ‚Äî mae","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mae_vec(), single numeric value (NA).","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean absolute error ‚Äî mae","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mae.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean absolute error ‚Äî mae","text":"","code":"# Supply truth and predictions as bare column names mae(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mae     standard       0.545  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   mae(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        mae     standard       0.512 #>  2 10       mae     standard       0.504 #>  3 2        mae     standard       0.545 #>  4 3        mae     standard       0.496 #>  5 4        mae     standard       0.587 #>  6 5        mae     standard       0.500 #>  7 6        mae     standard       0.627 #>  8 7        mae     standard       0.566 #>  9 8        mae     standard       0.473 #> 10 9        mae     standard       0.540  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.535"},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute percent error ‚Äî mape","title":"Mean absolute percent error ‚Äî mape","text":"Calculate mean absolute percentage error. metric relative units.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute percent error ‚Äî mape","text":"","code":"mape(data, ...)  # S3 method for class 'data.frame' mape(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  mape_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean absolute percent error ‚Äî mape","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean absolute percent error ‚Äî mape","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mape_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean absolute percent error ‚Äî mape","text":"Note value Inf returned mape() observed value negative.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean absolute percent error ‚Äî mape","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean absolute percent error ‚Äî mape","text":"","code":"# Supply truth and predictions as bare column names mape(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mape    standard         Inf  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   mape(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        mape    standard       Inf   #>  2 10       mape    standard       Inf   #>  3 2        mape    standard       Inf   #>  4 3        mape    standard        28.5 #>  5 4        mape    standard        95.3 #>  6 5        mape    standard       Inf   #>  7 6        mape    standard        73.1 #>  8 7        mape    standard       Inf   #>  9 8        mape    standard       Inf   #> 10 9        mape    standard        37.9  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1          Inf"},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute scaled error ‚Äî mase","title":"Mean absolute scaled error ‚Äî mase","text":"Calculate mean absolute scaled error. metric scale independent symmetric. generally used comparing forecast error time series settings. Due time series nature metric, necessary order observations ascending order time.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute scaled error ‚Äî mase","text":"","code":"mase(data, ...)  # S3 method for class 'data.frame' mase(   data,   truth,   estimate,   m = 1L,   mae_train = NULL,   na_rm = TRUE,   case_weights = NULL,   ... )  mase_vec(   truth,   estimate,   m = 1L,   mae_train = NULL,   na_rm = TRUE,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean absolute scaled error ‚Äî mase","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. m integer value number lags used calculate -sample seasonal naive error. default used non-seasonal time series. observation daily level data showed weekly seasonality, m = 7L reasonable choice 7-day seasonal naive calculation. mae_train numeric value allows user provide -sample seasonal naive mean absolute error. value provided, --sample seasonal naive mean absolute error calculated truth used instead. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean absolute scaled error ‚Äî mase","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mase_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean absolute scaled error ‚Äî mase","text":"mase() different numeric metrics. original implementation mase() calls using -sample naive mean absolute error compute scaled errors . uses instead --sample error chance --sample error computed forecasting short horizon (.e. sample size 1 2). However, yardstick knows --sample truth estimate values. , --sample error used computation default. -sample naive mean absolute error required known, can passed mae_train argument used instead. -sample data available, naive mean absolute error can easily computed mae(data, truth, lagged_truth).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean absolute scaled error ‚Äî mase","text":"Rob J. Hyndman (2006). ANOTHER LOOK FORECAST-ACCURACY METRICS INTERMITTENT DEMAND. Foresight, 4, 46.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean absolute scaled error ‚Äî mase","text":"Alex Hallam","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean absolute scaled error ‚Äî mase","text":"","code":"# Supply truth and predictions as bare column names mase(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mase    standard        3.56  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   mase(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        mase    standard       0.256 #>  2 10       mase    standard       0.240 #>  3 2        mase    standard       0.238 #>  4 3        mase    standard       0.219 #>  5 4        mase    standard       0.229 #>  6 5        mase    standard       0.261 #>  7 6        mase    standard       0.217 #>  8 7        mase    standard       0.267 #>  9 8        mase    standard       0.216 #> 10 9        mase    standard       0.251  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.240"},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":null,"dir":"Reference","previous_headings":"","what":"Matthews correlation coefficient ‚Äî mcc","title":"Matthews correlation coefficient ‚Äî mcc","text":"Matthews correlation coefficient","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matthews correlation coefficient ‚Äî mcc","text":"","code":"mcc(data, ...)  # S3 method for class 'data.frame' mcc(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  mcc_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matthews correlation coefficient ‚Äî mcc","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matthews correlation coefficient ‚Äî mcc","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mcc_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Matthews correlation coefficient ‚Äî mcc","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Matthews correlation coefficient ‚Äî mcc","text":"mcc() known multiclass generalization computed automatically factor 2 levels provided. , averaging methods provided.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Matthews correlation coefficient ‚Äî mcc","text":"Giuseppe, J. (2012). \"Comparison MCC CEN Error Measures Multi-Class Prediction\". PLOS ONE. Vol 7, Iss 8, e41882.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Matthews correlation coefficient ‚Äî mcc","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mcc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matthews correlation coefficient ‚Äî mcc","text":"","code":"library(dplyr) data(\"two_class_example\") data(\"hpc_cv\")  # Two class mcc(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mcc     binary         0.677  # Multiclass # mcc() has a natural multiclass extension hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mcc(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mcc     multiclass     0.542  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   mcc(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   mcc     multiclass     0.542 #>  2 Fold02   mcc     multiclass     0.521 #>  3 Fold03   mcc     multiclass     0.602 #>  4 Fold04   mcc     multiclass     0.519 #>  5 Fold05   mcc     multiclass     0.520 #>  6 Fold06   mcc     multiclass     0.494 #>  7 Fold07   mcc     multiclass     0.461 #>  8 Fold08   mcc     multiclass     0.538 #>  9 Fold09   mcc     multiclass     0.459 #> 10 Fold10   mcc     multiclass     0.498"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric-summarizers.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for summarizing new metrics ‚Äî metric-summarizers","title":"Developer function for summarizing new metrics ‚Äî metric-summarizers","text":"numeric_metric_summarizer(), class_metric_summarizer(), prob_metric_summarizer(), curve_metric_summarizer(), dynamic_survival_metric_summarizer(), static_survival_metric_summarizer() useful alongside check_metric yardstick_remove_missing implementing new custom metrics. functions call metric function inside dplyr::summarise() dplyr::reframe() curve_metric_summarizer(). See Custom performance metrics information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric-summarizers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for summarizing new metrics ‚Äî metric-summarizers","text":"","code":"numeric_metric_summarizer(   name,   fn,   data,   truth,   estimate,   ...,   na_rm = TRUE,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  class_metric_summarizer(   name,   fn,   data,   truth,   estimate,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = NULL,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  prob_metric_summarizer(   name,   fn,   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = NULL,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  ordered_prob_metric_summarizer(   name,   fn,   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = NULL,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  curve_metric_summarizer(   name,   fn,   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = NULL,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  dynamic_survival_metric_summarizer(   name,   fn,   data,   truth,   ...,   na_rm = TRUE,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  static_survival_metric_summarizer(   name,   fn,   data,   truth,   estimate,   ...,   na_rm = TRUE,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )  curve_survival_metric_summarizer(   name,   fn,   data,   truth,   ...,   na_rm = TRUE,   case_weights = NULL,   fn_options = list(),   error_call = caller_env() )"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric-summarizers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for summarizing new metrics ‚Äî metric-summarizers","text":"name single character representing name metric use tibble output. modified include type averaging appropriate. fn vector version custom metric function. generally takes truth, estimate, na_rm, extra arguments needed calculate metric. data data frame truth estimate columns passed data frame version metric function called numeric_metric_summarizer(), class_metric_summarizer(), prob_metric_summarizer(), curve_metric_summarizer(), dynamic_survival_metric_summarizer(), static_survival_metric_summarizer(). truth unquoted column name corresponding truth column. estimate Generally, unquoted column name corresponding estimate column. metrics take multiple columns ... like class probability metrics, result dots_to_estimate(). ... dots future extensions must empty. na_rm logical value indicating whether NA values stripped computation proceeds. removal executed yardstick_remove_missing(). case_weights metrics supporting case weights, unquoted column name corresponding case weights can passed . NULL, case weights passed fn named argument case_weights. fn_options named list metric specific options. spliced metric function call using !!! rlang. default results nothing spliced call. error_call execution environment currently running function, e.g. caller_env(). function mentioned error messages source error. See call argument abort() information. estimator can either NULL default auto-selection averaging (\"binary\" \"macro\"), single character pass along metric implementation describing kind averaging use. event_level can either NULL use default event_level value fn single string either \"first\" \"second\" pass along describing level considered \"event\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric-summarizers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Developer function for summarizing new metrics ‚Äî metric-summarizers","text":"numeric_metric_summarizer(), class_metric_summarizer(), prob_metric_summarizer(), curve_metric_summarizer(), dynamic_survival_metric_summarizer(), dynamic_survival_metric_summarizer() generally called data frame version metric function. knows call metric grouped data frames returns tibble consistent metrics.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine metric functions ‚Äî metric_set","title":"Combine metric functions ‚Äî metric_set","text":"metric_set() allows combine multiple metric functions together new function calculates .","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine metric functions ‚Äî metric_set","text":"","code":"metric_set(...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine metric functions ‚Äî metric_set","text":"... bare names functions included metric set.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_set.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine metric functions ‚Äî metric_set","text":"functions must either: numeric metrics mix class metrics class prob metrics mix dynamic, integrated, static survival metrics instance, rmse() can used mae() numeric metrics, accuracy() classification metric. accuracy() can used roc_auc(). returned metric function different argument list depending whether numeric metrics mix class/prob metrics passed .   mixing class class prob metrics, pass hard predictions (factor column) named argument estimate, soft predictions (class probability columns) bare column names tidyselect selectors .... mixing dynamic, integrated, static survival metrics, pass time predictions named argument estimate, survival predictions bare column names tidyselect selectors .... metric_tweak() used \"tweak\" one arguments, like estimator event_level, tweaked version wins. allows set estimator metric metric basis still use metric_set().","code":"# Numeric metric set signature: fn(   data,   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   ... )  # Class / prob metric set signature: fn(   data,   truth,   ...,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )  # Dynamic / integrated / static survival metric set signature: fn(   data,   truth,   ...,   estimate,   na_rm = TRUE,   case_weights = NULL )"},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine metric functions ‚Äî metric_set","text":"","code":"library(dplyr)  # Multiple regression metrics multi_metric <- metric_set(rmse, rsq, ccc)  # The returned function has arguments: # fn(data, truth, estimate, na_rm = TRUE, ...) multi_metric(solubility_test, truth = solubility, estimate = prediction) #> # A tibble: 3 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rmse    standard       0.722 #> 2 rsq     standard       0.879 #> 3 ccc     standard       0.937  # Groups are respected on the new metric function class_metrics <- metric_set(accuracy, kap)  hpc_cv %>%   group_by(Resample) %>%   class_metrics(obs, estimate = pred) #> # A tibble: 20 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699 #> 11 Fold01   kap      multiclass     0.533 #> 12 Fold02   kap      multiclass     0.512 #> 13 Fold03   kap      multiclass     0.594 #> 14 Fold04   kap      multiclass     0.511 #> 15 Fold05   kap      multiclass     0.514 #> 16 Fold06   kap      multiclass     0.486 #> 17 Fold07   kap      multiclass     0.454 #> 18 Fold08   kap      multiclass     0.531 #> 19 Fold09   kap      multiclass     0.454 #> 20 Fold10   kap      multiclass     0.492  # ---------------------------------------------------------------------------  # If you need to set options for certain metrics, # do so by wrapping the metric and setting the options inside the wrapper, # passing along truth and estimate as quoted arguments. # Then add on the function class of the underlying wrapped function, # and the direction of optimization. ccc_with_bias <- function(data, truth, estimate, na_rm = TRUE, ...) {   ccc(     data = data,     truth = !!rlang::enquo(truth),     estimate = !!rlang::enquo(estimate),     # set bias = TRUE     bias = TRUE,     na_rm = na_rm,     ...   ) }  # Use `new_numeric_metric()` to formalize this new metric function ccc_with_bias <- new_numeric_metric(ccc_with_bias, \"maximize\")  multi_metric2 <- metric_set(rmse, rsq, ccc_with_bias)  multi_metric2(solubility_test, truth = solubility, estimate = prediction) #> # A tibble: 3 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rmse    standard       0.722 #> 2 rsq     standard       0.879 #> 3 ccc     standard       0.937  # --------------------------------------------------------------------------- # A class probability example:  # Note that, when given class or class prob functions, # metric_set() returns a function with signature: # fn(data, truth, ..., estimate) # to be able to mix class and class prob metrics.  # You must provide the `estimate` column by explicitly naming # the argument  class_and_probs_metrics <- metric_set(roc_auc, pr_auc, accuracy)  hpc_cv %>%   group_by(Resample) %>%   class_and_probs_metrics(obs, VF:L, estimate = pred) #> # A tibble: 30 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   accuracy multiclass     0.726 #>  2 Fold02   accuracy multiclass     0.712 #>  3 Fold03   accuracy multiclass     0.758 #>  4 Fold04   accuracy multiclass     0.712 #>  5 Fold05   accuracy multiclass     0.712 #>  6 Fold06   accuracy multiclass     0.697 #>  7 Fold07   accuracy multiclass     0.675 #>  8 Fold08   accuracy multiclass     0.721 #>  9 Fold09   accuracy multiclass     0.673 #> 10 Fold10   accuracy multiclass     0.699 #> # ‚Ñπ 20 more rows"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_summarizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for summarizing new metrics ‚Äî metric_summarizer","title":"Developer function for summarizing new metrics ‚Äî metric_summarizer","text":"metric_summarizer() soft-deprecated yardstick 1.2.0. Please switch use class_metric_summarizer(), numeric_metric_summarizer(), prob_metric_summarizer(), curve_metric_summarizer().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_summarizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for summarizing new metrics ‚Äî metric_summarizer","text":"","code":"metric_summarizer(   metric_nm,   metric_fn,   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = NULL,   case_weights = NULL,   ...,   metric_fn_options = list() )"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_summarizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for summarizing new metrics ‚Äî metric_summarizer","text":"metric_nm single character representing name metric use tibble output. modified include type averaging appropriate. metric_fn vector version custom metric function. generally takes truth, estimate, na_rm, extra arguments needed calculate metric. data data frame truth estimate columns passed data frame version metric function called metric_summarizer(). truth unquoted column name corresponding truth column. estimate Generally, unquoted column name corresponding estimate column. metrics take multiple columns ... like class probability metrics, result dots_to_estimate(). estimator numeric metrics, left NULL averaging passed metric function implementation. classification metrics, can either NULL default auto-selection averaging (\"binary\" \"macro\"), single character pass along metric implementation describing kind averaging use. na_rm logical value indicating whether NA values stripped computation proceeds. removal executed metric_vec_template(). event_level numeric metrics, left NULL prevent passed metric function implementation. classification metrics, can either NULL use default event_level value metric_fn single string either \"first\" \"second\" pass along describing level considered \"event\". case_weights metrics supporting case weights, unquoted column name corresponding case weights can passed . NULL, case weights passed metric_fn named argument case_weights. ... Currently used. Metric specific options passed metric_fn_options. metric_fn_options named list metric specific options. spliced metric function call using !!! rlang. default results nothing spliced call.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":null,"dir":"Reference","previous_headings":"","what":"Tweak a metric function ‚Äî metric_tweak","title":"Tweak a metric function ‚Äî metric_tweak","text":"metric_tweak() allows tweak existing metric .fn, giving new .name setting new optional argument defaults .... similar purrr::partial(), designed specifically yardstick metrics. metric_tweak() especially useful constructing metric_set() tuning tune package. metric set constructed, way adjust value optional arguments (beta f_meas()). Using metric_tweak(), can set optional arguments custom values ahead time, go metric set.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tweak a metric function ‚Äî metric_tweak","text":"","code":"metric_tweak(.name, .fn, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tweak a metric function ‚Äî metric_tweak","text":".name single string giving name new metric. used \".metric\" column output. .fn existing yardstick metric function tweak. ... Name-value pairs specifying optional arguments override values replace . Arguments data, truth, estimate considered protected, overridden, optional arguments can altered.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tweak a metric function ‚Äî metric_tweak","text":"tweaked version .fn, updated use new defaults supplied ....","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tweak a metric function ‚Äî metric_tweak","text":"function returned metric_tweak() takes ... arguments, passed original .fn. Passing data, truth, estimate position generally safe, recommended pass optional arguments name ensure evaluated correctly.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_tweak.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tweak a metric function ‚Äî metric_tweak","text":"","code":"mase12 <- metric_tweak(\"mase12\", mase, m = 12)  # Defaults to `m = 1` mase(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mase    standard        3.56  # Updated to use `m = 12`. `mase12()` has this set already. mase(solubility_test, solubility, prediction, m = 12) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mase    standard       0.582 mase12(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mase12  standard       0.582  # This is most useful to set optional argument values ahead of time when # using a metric set mase10 <- metric_tweak(\"mase10\", mase, m = 10) metrics <- metric_set(mase, mase10, mase12) metrics(solubility_test, solubility, prediction) #> # A tibble: 3 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mase    standard       3.56  #> 2 mase10  standard       0.664 #> 3 mase12  standard       0.582"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_vec_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for calling new metrics ‚Äî metric_vec_template","title":"Developer function for calling new metrics ‚Äî metric_vec_template","text":"metric_vec_template() soft-deprecated yardstick 1.2.0. Please switch use check_metric yardstick_remove_missing functions.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_vec_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for calling new metrics ‚Äî metric_vec_template","text":"","code":"metric_vec_template(   metric_impl,   truth,   estimate,   na_rm = TRUE,   cls = \"numeric\",   estimator = NULL,   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/metric_vec_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for calling new metrics ‚Äî metric_vec_template","text":"metric_impl core implementation function custom metric. core implementation function generally defined inside vector method metric function. truth realized vector truth. either factor numeric. estimate realized estimate result. either numeric vector, factor vector, numeric matrix (case multiple class probability columns) depending metric function. na_rm logical value indicating whether NA values stripped computation proceeds. NA values removed getting core implementation function worry handling . na_rm=FALSE NA values exist, NA automatically returned. cls character vector length 1 2 corresponding class truth estimate , respectively. truth estimate class, just supply vector length 1. different, supply vector length 2. matrices, best supply \"numeric\" class check . estimator type averaging use. point, averaging type finalized, character vector length 1\\. default, character value required one : \"binary\", \"macro\", \"micro\", \"macro_weighted\". metric allows less averaging methods, override averaging_override. case_weights Optionally, realized case weights, numeric vector. must length truth, considered na_rm checks. supplied, passed metric_impl named argument case_weights. ... Extra arguments core metric function, metric_impl, can technically passed , generally extra args added R's scoping rules core metric function created fly vector method called.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"General Function to Estimate Performance ‚Äî metrics","title":"General Function to Estimate Performance ‚Äî metrics","text":"function estimates one common performance estimates depending class truth (see Value ) returns three column tibble. wish modify metrics used used see metric_set().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General Function to Estimate Performance ‚Äî metrics","text":"","code":"metrics(data, ...)  # S3 method for class 'data.frame' metrics(data, truth, estimate, ..., na_rm = TRUE, options = list())"},{"path":"https://yardstick.tidymodels.org/dev/reference/metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General Function to Estimate Performance ‚Äî metrics","text":"data data.frame containing columns specified truth, estimate, .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true results (numeric factor). unquoted column name although argument passed expression support quasiquotation (can unquote column names). estimate column identifier predicted results (also numeric factor). truth can specified different ways primary method use unquoted variable name. na_rm logical value indicating whether NA values stripped computation proceeds. options [deprecated] longer supported yardstick 1.0.0. pass something ignored warning. Previously, options passed pROC::roc(). need support , use pROC package directly.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General Function to Estimate Performance ‚Äî metrics","text":"three column tibble. truth factor, rows accuracy() Kappa statistic (kap()). truth two levels 1 column class probabilities passed ..., rows two class versions mn_log_loss() roc_auc(). truth two levels full set class probabilities passed ..., rows multiclass version mn_log_loss() Hand Till generalization roc_auc(). truth numeric, rows rmse(), rsq(), mae().","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General Function to Estimate Performance ‚Äî metrics","text":"","code":"# Accuracy and kappa metrics(two_class_example, truth, predicted) #> # A tibble: 2 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 accuracy binary         0.838 #> 2 kap      binary         0.675  # Add on multinomal log loss and ROC AUC by specifying class prob columns metrics(two_class_example, truth, predicted, Class1) #> # A tibble: 4 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 accuracy    binary         0.838 #> 2 kap         binary         0.675 #> 3 mn_log_loss binary         0.328 #> 4 roc_auc     binary         0.939  # Regression metrics metrics(solubility_test, truth = solubility, estimate = prediction) #> # A tibble: 3 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rmse    standard       0.722 #> 2 rsq     standard       0.879 #> 3 mae     standard       0.545  # Multiclass metrics work, but you cannot specify any averaging # for roc_auc() besides the default, hand_till. Use the specific function # if you need more customization library(dplyr)  hpc_cv %>%   group_by(Resample) %>%   metrics(obs, pred, VF:L) %>%   print(n = 40) #> # A tibble: 40 √ó 4 #>    Resample .metric     .estimator .estimate #>    <chr>    <chr>       <chr>          <dbl> #>  1 Fold01   accuracy    multiclass     0.726 #>  2 Fold02   accuracy    multiclass     0.712 #>  3 Fold03   accuracy    multiclass     0.758 #>  4 Fold04   accuracy    multiclass     0.712 #>  5 Fold05   accuracy    multiclass     0.712 #>  6 Fold06   accuracy    multiclass     0.697 #>  7 Fold07   accuracy    multiclass     0.675 #>  8 Fold08   accuracy    multiclass     0.721 #>  9 Fold09   accuracy    multiclass     0.673 #> 10 Fold10   accuracy    multiclass     0.699 #> 11 Fold01   kap         multiclass     0.533 #> 12 Fold02   kap         multiclass     0.512 #> 13 Fold03   kap         multiclass     0.594 #> 14 Fold04   kap         multiclass     0.511 #> 15 Fold05   kap         multiclass     0.514 #> 16 Fold06   kap         multiclass     0.486 #> 17 Fold07   kap         multiclass     0.454 #> 18 Fold08   kap         multiclass     0.531 #> 19 Fold09   kap         multiclass     0.454 #> 20 Fold10   kap         multiclass     0.492 #> 21 Fold01   mn_log_loss multiclass     0.734 #> 22 Fold02   mn_log_loss multiclass     0.808 #> 23 Fold03   mn_log_loss multiclass     0.705 #> 24 Fold04   mn_log_loss multiclass     0.747 #> 25 Fold05   mn_log_loss multiclass     0.799 #> 26 Fold06   mn_log_loss multiclass     0.766 #> 27 Fold07   mn_log_loss multiclass     0.927 #> 28 Fold08   mn_log_loss multiclass     0.855 #> 29 Fold09   mn_log_loss multiclass     0.861 #> 30 Fold10   mn_log_loss multiclass     0.821 #> 31 Fold01   roc_auc     hand_till      0.813 #> 32 Fold02   roc_auc     hand_till      0.817 #> 33 Fold03   roc_auc     hand_till      0.869 #> 34 Fold04   roc_auc     hand_till      0.849 #> 35 Fold05   roc_auc     hand_till      0.811 #> 36 Fold06   roc_auc     hand_till      0.836 #> 37 Fold07   roc_auc     hand_till      0.825 #> 38 Fold08   roc_auc     hand_till      0.846 #> 39 Fold09   roc_auc     hand_till      0.828 #> 40 Fold10   roc_auc     hand_till      0.812"},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean log loss for multinomial data ‚Äî mn_log_loss","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"Compute logarithmic loss classification model.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"","code":"mn_log_loss(data, ...)  # S3 method for class 'data.frame' mn_log_loss(   data,   truth,   ...,   na_rm = TRUE,   sum = FALSE,   event_level = yardstick_event_level(),   case_weights = NULL )  mn_log_loss_vec(   truth,   estimate,   na_rm = TRUE,   sum = FALSE,   event_level = yardstick_event_level(),   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. sum logical. sum likelihood contributions returned (instead mean value)? event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mn_log_loss_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"Log loss measure performance classification model. perfect model log loss 0. Compared accuracy(), log loss takes account uncertainty prediction gives detailed view actual performance. example, given two input probabilities .6 .9 classified predicting positive value, say, \"Yes\", accuracy metric interpret value. true output \"Yes\", log loss penalizes .6 \"less sure\" result compared probability .9.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"Log loss known multiclass extension, simply sum log loss values class prediction. , averaging types supported.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mn_log_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean log loss for multinomial data ‚Äî mn_log_loss","text":"","code":"# Two class data(\"two_class_example\") mn_log_loss(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 mn_log_loss binary         0.328  # Multiclass library(dplyr) data(hpc_cv)  # You can use the col1:colN tidyselect syntax hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mn_log_loss(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 mn_log_loss multiclass     0.734  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   mn_log_loss(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric     .estimator .estimate #>    <chr>    <chr>       <chr>          <dbl> #>  1 Fold01   mn_log_loss multiclass     0.734 #>  2 Fold02   mn_log_loss multiclass     0.808 #>  3 Fold03   mn_log_loss multiclass     0.705 #>  4 Fold04   mn_log_loss multiclass     0.747 #>  5 Fold05   mn_log_loss multiclass     0.799 #>  6 Fold06   mn_log_loss multiclass     0.766 #>  7 Fold07   mn_log_loss multiclass     0.927 #>  8 Fold08   mn_log_loss multiclass     0.855 #>  9 Fold09   mn_log_loss multiclass     0.861 #> 10 Fold10   mn_log_loss multiclass     0.821   # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  mn_log_loss_vec(   truth = fold1$obs,   matrix(     c(fold1$VF, fold1$F, fold1$M, fold1$L),     ncol = 4   ) ) #> [1] 0.7338423  # Supply `...` with quasiquotation prob_cols <- levels(two_class_example$truth) mn_log_loss(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 mn_log_loss binary         0.328 mn_log_loss(two_class_example, truth, !!prob_cols[1]) #> # A tibble: 1 √ó 3 #>   .metric     .estimator .estimate #>   <chr>       <chr>          <dbl> #> 1 mn_log_loss binary         0.328"},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean percentage error ‚Äî mpe","title":"Mean percentage error ‚Äî mpe","text":"Calculate mean percentage error. metric relative units. can used measure estimate's bias. Note truth values 0, value : -Inf (estimate > 0), Inf (estimate < 0), NaN (estimate == 0) returned mpe().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean percentage error ‚Äî mpe","text":"","code":"mpe(data, ...)  # S3 method for class 'data.frame' mpe(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  mpe_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean percentage error ‚Äî mpe","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean percentage error ‚Äî mpe","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. mpe_vec(), single numeric value (NA).","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean percentage error ‚Äî mpe","text":"Thomas Bierhance","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/mpe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean percentage error ‚Äî mpe","text":"","code":"# `solubility_test$solubility` has zero values with corresponding # `$prediction` values that are negative. By definition, this causes `Inf` # to be returned from `mpe()`. solubility_test[solubility_test$solubility == 0, ] #>     solubility prediction #> 17           0 -0.1532030 #> 220          0 -0.3876578  mpe(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mpe     standard         Inf  # We'll remove the zero values for demonstration solubility_test <- solubility_test[solubility_test$solubility != 0, ]  # Supply truth and predictions as bare column names mpe(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 mpe     standard        16.1  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   mpe(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        mpe     standard     -56.2   #>  2 10       mpe     standard      50.4   #>  3 2        mpe     standard     -27.9   #>  4 3        mpe     standard       0.470 #>  5 4        mpe     standard      -0.836 #>  6 5        mpe     standard     -35.3   #>  7 6        mpe     standard       7.51  #>  8 7        mpe     standard     -34.5   #>  9 8        mpe     standard       7.87  #> 10 9        mpe     standard      14.7    # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        -7.38"},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean signed deviation ‚Äî msd","title":"Mean signed deviation ‚Äî msd","text":"Mean signed deviation (also known mean signed difference, mean signed error) computes average differences truth estimate. related metric mean absolute error (mae()).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean signed deviation ‚Äî msd","text":"","code":"msd(data, ...)  # S3 method for class 'data.frame' msd(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  msd_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean signed deviation ‚Äî msd","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean signed deviation ‚Äî msd","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. msd_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean signed deviation ‚Äî msd","text":"Mean signed deviation rarely used, since positive negative errors cancel . example, msd_vec(c(100, -100), c(0, 0)) return seemingly \"perfect\" value 0, even though estimate wildly different truth. mae() attempts remedy taking absolute value differences computing mean. metric computed mean(truth - estimate), following convention \"error\" computed observed - predicted. expected metric computed mean(estimate - truth), reverse sign result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean signed deviation ‚Äî msd","text":"Thomas Bierhance","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/msd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean signed deviation ‚Äî msd","text":"","code":"# Supply truth and predictions as bare column names msd(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 msd     standard     -0.0143  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   msd(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        msd     standard   -0.0119   #>  2 10       msd     standard   -0.0424   #>  3 2        msd     standard    0.0111   #>  4 3        msd     standard   -0.0906   #>  5 4        msd     standard   -0.0859   #>  6 5        msd     standard   -0.0301   #>  7 6        msd     standard   -0.0132   #>  8 7        msd     standard   -0.00640  #>  9 8        msd     standard   -0.000697 #> 10 9        msd     standard   -0.0399    # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1      -0.0310"},{"path":"https://yardstick.tidymodels.org/dev/reference/new-metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a new metric function ‚Äî new-metric","title":"Construct a new metric function ‚Äî new-metric","text":"functions provide convenient wrappers create three types metric functions yardstick: numeric metrics, class metrics, class probability metrics. add metric-specific class fn attach direction attribute. features used metric_set() tune model tuning. See Custom performance metrics information creating custom metrics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/new-metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a new metric function ‚Äî new-metric","text":"","code":"new_class_metric(fn, direction)  new_prob_metric(fn, direction)  new_ordered_prob_metric(fn, direction)  new_numeric_metric(fn, direction)  new_dynamic_survival_metric(fn, direction)  new_integrated_survival_metric(fn, direction)  new_static_survival_metric(fn, direction)"},{"path":"https://yardstick.tidymodels.org/dev/reference/new-metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a new metric function ‚Äî new-metric","text":"fn function. metric function attach metric-specific class direction attribute . direction string. One : \"maximize\" \"minimize\" \"zero\"","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create groupwise metrics ‚Äî new_groupwise_metric","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"Groupwise metrics quantify disparity value metric across number groups. Groupwise metrics value zero indicate underlying metric equal across groups. yardstick defines several common fairness metrics using function, demographic_parity(), equal_opportunity(), equalized_odds().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"","code":"new_groupwise_metric(fn, name, aggregate, direction = \"minimize\")"},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"fn yardstick metric function metric set. name name metric place .metric column output. aggregate function summarize generated metric set results. function takes metric set results first argument returns single numeric giving .estimate value output. See Value Examples sections example uses. direction string. One : \"maximize\" \"minimize\" \"zero\"","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"function function factory; output function. , functions function outputs also function factories. explicitly, looks like:   outputted dem_parity function takes one argument, , indicating data-masked variable giving sensitive feature. called argument, dem_parity return yardstick metric function like :   Note dem_parity take arguments , thus knows nothing data applied column name \"gender\" . output dem_parity_by_gender metric function takes arguments function supplied fn, case detection_prevalence. thus interface like yardstick function except look \"gender\" column data supplied. addition examples , see documentation return value fairness metrics like demographic_parity(), equal_opportunity(), equalized_odds() learn output function can used.","code":"# a function with similar implementation to `demographic_parity()`: diff_range <- function(x) {diff(range(x$.estimate))}  dem_parity <-   new_groupwise_metric(     fn = detection_prevalence,     name = \"dem_parity\",     aggregate = diff_range   ) dem_parity_by_gender <- dem_parity(gender)"},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"Note yardstick metrics group-aware , passed grouped data, return metric values calculated group. passed grouped data, groupwise metrics also return metric values group, metric values calculated first additionally grouping variable passed summarizing per-group metric estimates across groups using function passed aggregate argument. Learn grouping behavior yardstick using vignette(\"grouping\", \"yardstick\").","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"relevant-group-level","dir":"Reference","previous_headings":"","what":"Relevant Group Level","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"Additional arguments can passed function outputted function function outputs. :   finer control groups treated, use aggregate argument.","code":"res_fairness <- new_groupwise_metric(...) res_by <- res_fairness(by) res_by(..., additional_arguments_to_aggregate = TRUE)"},{"path":"https://yardstick.tidymodels.org/dev/reference/new_groupwise_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create groupwise metrics ‚Äî new_groupwise_metric","text":"","code":"data(hpc_cv)  # `demographic_parity`, among other fairness metrics, # is generated with `new_groupwise_metric()`: diff_range <- function(x) {diff(range(x$.estimate))} demographic_parity_ <-   new_groupwise_metric(     fn = detection_prevalence,     name = \"demographic_parity\",     aggregate = diff_range   )  m_set <- metric_set(demographic_parity_(Resample))  m_set(hpc_cv, truth = obs, estimate = pred) #> # A tibble: 1 √ó 4 #>   .metric            .by      .estimator .estimate #>   <chr>              <chr>    <chr>          <dbl> #> 1 demographic_parity Resample macro       2.78e-17  # the `post` argument can be used to accommodate a wide # variety of parameterizations. to encode demographic # parity as a ratio inside of a difference, for example: ratio_range <- function(x, ...) {   range <- range(x$.estimate)   range[1] / range[2] }  demographic_parity_ratio <-   new_groupwise_metric(     fn = detection_prevalence,     name = \"demographic_parity_ratio\",     aggregate = ratio_range   )"},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative predictive value ‚Äî npv","title":"Negative predictive value ‚Äî npv","text":"functions calculate npv() (negative predictive value) measurement system compared reference result (\"truth\" gold standard). Highly related functions spec(), sens(), ppv().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative predictive value ‚Äî npv","text":"","code":"npv(data, ...)  # S3 method for class 'data.frame' npv(   data,   truth,   estimate,   prevalence = NULL,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  npv_vec(   truth,   estimate,   prevalence = NULL,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative predictive value ‚Äî npv","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. prevalence numeric value rate \"positive\" class data. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative predictive value ‚Äî npv","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. npv_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative predictive value ‚Äî npv","text":"positive predictive value (ppv()) defined percent predicted positives actually positive negative predictive value (npv()) defined percent negative positives actually negative.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Negative predictive value ‚Äî npv","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Negative predictive value ‚Äî npv","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Negative predictive value ‚Äî npv","text":"Suppose 2x2 table notation: formulas used : $$Sensitivity = /(+C)$$ $$Specificity = D/(B+D)$$ $$Prevalence = (+C)/(+B+C+D)$$ $$PPV = (Sensitivity * Prevalence) / ((Sensitivity * Prevalence) + ((1-Specificity) * (1-Prevalence)))$$ $$NPV = (Specificity * (1-Prevalence)) / (((1-Sensitivity) * Prevalence) + ((Specificity) * (1-Prevalence)))$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative predictive value ‚Äî npv","text":"Altman, D.G., Bland, J.M. (1994) ‚ÄúDiagnostic tests 2: predictive values,‚Äù British Medical Journal, vol 309, 102.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative predictive value ‚Äî npv","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/npv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative predictive value ‚Äî npv","text":"","code":"# Two class data(\"two_class_example\") npv(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 npv     binary         0.861  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   npv(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 npv     macro          0.906  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   npv(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   npv     macro          0.906 #>  2 Fold02   npv     macro          0.901 #>  3 Fold03   npv     macro          0.917 #>  4 Fold04   npv     macro          0.897 #>  5 Fold05   npv     macro          0.897 #>  6 Fold06   npv     macro          0.892 #>  7 Fold07   npv     macro          0.882 #>  8 Fold08   npv     macro          0.902 #>  9 Fold09   npv     macro          0.879 #> 10 Fold10   npv     macro          0.890  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   npv(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   npv     macro_weighted     0.896 #>  2 Fold02   npv     macro_weighted     0.890 #>  3 Fold03   npv     macro_weighted     0.905 #>  4 Fold04   npv     macro_weighted     0.878 #>  5 Fold05   npv     macro_weighted     0.878 #>  6 Fold06   npv     macro_weighted     0.871 #>  7 Fold07   npv     macro_weighted     0.853 #>  8 Fold08   npv     macro_weighted     0.885 #>  9 Fold09   npv     macro_weighted     0.845 #> 10 Fold10   npv     macro_weighted     0.864  # Vector version npv_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.8609865  # Making Class2 the \"relevant\" level npv_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.8194946"},{"path":"https://yardstick.tidymodels.org/dev/reference/pathology.html","id":null,"dir":"Reference","previous_headings":"","what":"Liver Pathology Data ‚Äî pathology","title":"Liver Pathology Data ‚Äî pathology","text":"Liver Pathology Data","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pathology.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Liver Pathology Data ‚Äî pathology","text":"Altman, D.G., Bland, J.M. (1994) ‚ÄúDiagnostic tests 1: sensitivity specificity,‚Äù British Medical Journal, vol 308, 1552.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pathology.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Liver Pathology Data ‚Äî pathology","text":"pathology data frame","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pathology.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Liver Pathology Data ‚Äî pathology","text":"data results x-ray examination determine whether liver abnormal (scan column) versus extensive pathology results approximate truth (pathology).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pathology.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Liver Pathology Data ‚Äî pathology","text":"","code":"data(pathology) str(pathology) #> 'data.frame':\t344 obs. of  2 variables: #>  $ pathology: Factor w/ 2 levels \"abnorm\",\"norm\": 1 1 1 1 1 1 1 1 1 1 ... #>  $ scan     : Factor w/ 2 levels \"abnorm\",\"norm\": 1 1 1 1 1 1 1 1 1 1 ..."},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean log loss for Poisson data ‚Äî poisson_log_loss","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"Calculate loss function Poisson distribution.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"","code":"poisson_log_loss(data, ...)  # S3 method for class 'data.frame' poisson_log_loss(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  poisson_log_loss_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true counts (integer). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, integer vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. poisson_log_loss_vec(), single numeric value (NA).","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/poisson_log_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean log loss for Poisson data ‚Äî poisson_log_loss","text":"","code":"count_truth <- c(2L,   7L,   1L,   1L,   0L,  3L) count_pred  <- c(2.14, 5.35, 1.65, 1.56, 1.3, 2.71) count_results <- dplyr::tibble(count = count_truth, pred = count_pred)  # Supply truth and predictions as bare column names poisson_log_loss(count_results, count, pred) #> # A tibble: 1 √ó 3 #>   .metric          .estimator .estimate #>   <chr>            <chr>          <dbl> #> 1 poisson_log_loss standard        1.42"},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":null,"dir":"Reference","previous_headings":"","what":"Positive predictive value ‚Äî ppv","title":"Positive predictive value ‚Äî ppv","text":"functions calculate ppv() (positive predictive value) measurement system compared reference result (\"truth\" gold standard). Highly related functions spec(), sens(), npv().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Positive predictive value ‚Äî ppv","text":"","code":"ppv(data, ...)  # S3 method for class 'data.frame' ppv(   data,   truth,   estimate,   prevalence = NULL,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  ppv_vec(   truth,   estimate,   prevalence = NULL,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Positive predictive value ‚Äî ppv","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. prevalence numeric value rate \"positive\" class data. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Positive predictive value ‚Äî ppv","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. ppv_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Positive predictive value ‚Äî ppv","text":"positive predictive value (ppv()) defined percent predicted positives actually positive negative predictive value (npv()) defined percent negative positives actually negative.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Positive predictive value ‚Äî ppv","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Positive predictive value ‚Äî ppv","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Positive predictive value ‚Äî ppv","text":"Suppose 2x2 table notation: formulas used : $$Sensitivity = /(+C)$$ $$Specificity = D/(B+D)$$ $$Prevalence = (+C)/(+B+C+D)$$ $$PPV = (Sensitivity * Prevalence) / ((Sensitivity * Prevalence) + ((1-Specificity) * (1-Prevalence)))$$ $$NPV = (Specificity * (1-Prevalence)) / (((1-Sensitivity) * Prevalence) + ((Specificity) * (1-Prevalence)))$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Positive predictive value ‚Äî ppv","text":"Altman, D.G., Bland, J.M. (1994) ‚ÄúDiagnostic tests 2: predictive values,‚Äù British Medical Journal, vol 309, 102.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Positive predictive value ‚Äî ppv","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ppv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Positive predictive value ‚Äî ppv","text":"","code":"# Two class data(\"two_class_example\") ppv(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 ppv     binary         0.819  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   ppv(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 ppv     macro          0.637  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   ppv(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   ppv     macro          0.637 #>  2 Fold02   ppv     macro          0.603 #>  3 Fold03   ppv     macro          0.706 #>  4 Fold04   ppv     macro          0.658 #>  5 Fold05   ppv     macro          0.651 #>  6 Fold06   ppv     macro          0.626 #>  7 Fold07   ppv     macro          0.562 #>  8 Fold08   ppv     macro          0.652 #>  9 Fold09   ppv     macro          0.605 #> 10 Fold10   ppv     macro          0.625  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   ppv(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   ppv     macro_weighted     0.697 #>  2 Fold02   ppv     macro_weighted     0.690 #>  3 Fold03   ppv     macro_weighted     0.752 #>  4 Fold04   ppv     macro_weighted     0.690 #>  5 Fold05   ppv     macro_weighted     0.705 #>  6 Fold06   ppv     macro_weighted     0.682 #>  7 Fold07   ppv     macro_weighted     0.649 #>  8 Fold08   ppv     macro_weighted     0.702 #>  9 Fold09   ppv     macro_weighted     0.661 #> 10 Fold10   ppv     macro_weighted     0.683  # Vector version ppv_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.8194946  # Making Class2 the \"relevant\" level ppv_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.8609865 # But what if we think that Class 1 only occurs 40% of the time? ppv(two_class_example, truth, predicted, prevalence = 0.40) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 ppv     binary         0.740"},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the precision recall curve ‚Äî pr_auc","title":"Area under the precision recall curve ‚Äî pr_auc","text":"pr_auc() metric computes area precision recall curve. See pr_curve() full curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the precision recall curve ‚Äî pr_auc","text":"","code":"pr_auc(data, ...)  # S3 method for class 'data.frame' pr_auc(   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )  pr_auc_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the precision recall curve ‚Äî pr_auc","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimator One \"binary\", \"macro\", \"macro_weighted\" specify type averaging done. \"binary\" relevant two class case. two general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based truth. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the precision recall curve ‚Äî pr_auc","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. pr_auc_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Area under the precision recall curve ‚Äî pr_auc","text":"Macro macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Area under the precision recall curve ‚Äî pr_auc","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Area under the precision recall curve ‚Äî pr_auc","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_auc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the precision recall curve ‚Äî pr_auc","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. pr_auc(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 pr_auc  binary         0.946  # --------------------------------------------------------------------------- # Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   pr_auc(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 pr_auc  macro          0.611  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   pr_auc(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 pr_auc  macro          0.611  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   pr_auc(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   pr_auc  macro          0.611 #>  2 Fold02   pr_auc  macro          0.620 #>  3 Fold03   pr_auc  macro          0.689 #>  4 Fold04   pr_auc  macro          0.680 #>  5 Fold05   pr_auc  macro          0.620 #>  6 Fold06   pr_auc  macro          0.650 #>  7 Fold07   pr_auc  macro          0.607 #>  8 Fold08   pr_auc  macro          0.650 #>  9 Fold09   pr_auc  macro          0.628 #> 10 Fold10   pr_auc  macro          0.603  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   pr_auc(obs, VF:L, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   pr_auc  macro_weighted     0.746 #>  2 Fold02   pr_auc  macro_weighted     0.743 #>  3 Fold03   pr_auc  macro_weighted     0.789 #>  4 Fold04   pr_auc  macro_weighted     0.754 #>  5 Fold05   pr_auc  macro_weighted     0.737 #>  6 Fold06   pr_auc  macro_weighted     0.743 #>  7 Fold07   pr_auc  macro_weighted     0.748 #>  8 Fold08   pr_auc  macro_weighted     0.756 #>  9 Fold09   pr_auc  macro_weighted     0.711 #> 10 Fold10   pr_auc  macro_weighted     0.737  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  pr_auc_vec(    truth = fold1$obs,    matrix(      c(fold1$VF, fold1$F, fold1$M, fold1$L),      ncol = 4    ) ) #> [1] 0.6109931"},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Precision recall curve ‚Äî pr_curve","title":"Precision recall curve ‚Äî pr_curve","text":"pr_curve() constructs full precision recall curve returns tibble. See pr_auc() area precision recall curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precision recall curve ‚Äî pr_curve","text":"","code":"pr_curve(data, ...)  # S3 method for class 'data.frame' pr_curve(   data,   truth,   ...,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL )"},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precision recall curve ‚Äî pr_curve","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precision recall curve ‚Äî pr_curve","text":"tibble class pr_df pr_grouped_df columns .threshold, recall, precision.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Precision recall curve ‚Äî pr_curve","text":"pr_curve() computes precision every unique value probability column (addition infinity). ggplot2::autoplot() method quickly visualizing curve. works binary multiclass output, also works grouped data (.e. resamples). See examples.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Precision recall curve ‚Äî pr_curve","text":"multiclass truth column provided, one-vs-approach taken calculate multiple curves, one per level. case, additional column, .level, identifying \"one\" column one-vs-calculation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Precision recall curve ‚Äî pr_curve","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Precision recall curve ‚Äî pr_curve","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/pr_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Precision recall curve ‚Äî pr_curve","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. pr_curve(two_class_example, truth, Class1) #> # A tibble: 501 √ó 3 #>    .threshold  recall precision #>         <dbl>   <dbl>     <dbl> #>  1     Inf    0               1 #>  2       1.00 0.00388         1 #>  3       1.00 0.00775         1 #>  4       1.00 0.0116          1 #>  5       1.00 0.0155          1 #>  6       1.00 0.0194          1 #>  7       1.00 0.0233          1 #>  8       1.00 0.0271          1 #>  9       1.00 0.0310          1 #> 10       1.00 0.0349          1 #> # ‚Ñπ 491 more rows  # --------------------------------------------------------------------------- # `autoplot()`  # Visualize the curve using ggplot2 manually library(ggplot2) library(dplyr) pr_curve(two_class_example, truth, Class1) %>%   ggplot(aes(x = recall, y = precision)) +   geom_path() +   coord_equal() +   theme_bw()   # Or use autoplot autoplot(pr_curve(two_class_example, truth, Class1))   # Multiclass one-vs-all approach # One curve per level hpc_cv %>%   filter(Resample == \"Fold01\") %>%   pr_curve(obs, VF:L) %>%   autoplot()   # Same as above, but will all of the resamples hpc_cv %>%   group_by(Resample) %>%   pr_curve(obs, VF:L) %>%   autoplot()"},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Precision ‚Äî precision","title":"Precision ‚Äî precision","text":"functions calculate precision() measurement system finding relevant documents compared reference results (truth regarding relevance). Highly related functions recall() f_meas().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precision ‚Äî precision","text":"","code":"precision(data, ...)  # S3 method for class 'data.frame' precision(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  precision_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precision ‚Äî precision","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precision ‚Äî precision","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. precision_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Precision ‚Äî precision","text":"precision percentage predicted truly relevant results total number predicted relevant results characterizes \"purity retrieval performance\" (Buckland Gey, 1994). denominator calculation 0, precision undefined. happens # true_positive = 0 # false_positive = 0 true, mean predicted events. computing binary precision, NA value returned warning. computing multiclass precision, individual NA values removed, computation procede, warning.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Precision ‚Äî precision","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Precision ‚Äî precision","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Precision ‚Äî precision","text":"Suppose 2x2 table notation: formulas used : $$recall = /(+C)$$ $$precision = /(+B)$$ $$F_{meas} = (1+\\beta^2) * precision * recall/((\\beta^2 * precision)+recall)$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Precision ‚Äî precision","text":"Buckland, M., & Gey, F. (1994). relationship Recall Precision. Journal American Society Information Science, 45(1), 12-19. Powers, D. (2007). Evaluation: Precision, Recall F Factor ROC, Informedness, Markedness Correlation. Technical Report SIE-07-001, Flinders University","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Precision ‚Äî precision","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Precision ‚Äî precision","text":"","code":"# Two class data(\"two_class_example\") precision(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision binary         0.819  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   precision(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 precision macro          0.637  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   precision(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric   .estimator .estimate #>    <chr>    <chr>     <chr>          <dbl> #>  1 Fold01   precision macro          0.637 #>  2 Fold02   precision macro          0.603 #>  3 Fold03   precision macro          0.706 #>  4 Fold04   precision macro          0.658 #>  5 Fold05   precision macro          0.651 #>  6 Fold06   precision macro          0.626 #>  7 Fold07   precision macro          0.562 #>  8 Fold08   precision macro          0.652 #>  9 Fold09   precision macro          0.605 #> 10 Fold10   precision macro          0.625  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   precision(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric   .estimator     .estimate #>    <chr>    <chr>     <chr>              <dbl> #>  1 Fold01   precision macro_weighted     0.697 #>  2 Fold02   precision macro_weighted     0.690 #>  3 Fold03   precision macro_weighted     0.752 #>  4 Fold04   precision macro_weighted     0.690 #>  5 Fold05   precision macro_weighted     0.705 #>  6 Fold06   precision macro_weighted     0.682 #>  7 Fold07   precision macro_weighted     0.649 #>  8 Fold08   precision macro_weighted     0.702 #>  9 Fold09   precision macro_weighted     0.661 #> 10 Fold10   precision macro_weighted     0.683  # Vector version precision_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.8194946  # Making Class2 the \"relevant\" level precision_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.8609865"},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"Compute ranked probability score (RPS) classification model using ordered classes.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"","code":"ranked_prob_score(data, ...)  # S3 method for class 'data.frame' ranked_prob_score(data, truth, ..., na_rm = TRUE, case_weights = NULL)  ranked_prob_score_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (ordered factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector class ordered. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. ranked_prob_score_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"ranked probability score Brier score ordinal data uses cumulative probability event (.e. Pr[class <= ] = 1, 2, ..., C classes). probabilities compared indicators truth less equal class . Since cumulative sum vector probability predictions add one, embedded redundancy data. reason, raw mean divided number classes minus one. Smaller values score associated better model performance.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"Ranked probability scores can computed way number classes. , averaging types supported.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"Wilks, D. S. (2011). Statistical Methods Atmospheric Sciences. Academic press. (see Chapter 7) Janitza, S., Tutz, G., & Boulesteix, . L. (2016). Random forest ordinal responses: prediction variable selection. Computational Statistics Data Analysis, 96, 57-73. (see Section 2) Lechner, M., & Okasa, G. (2019). Random forest estimation ordered choice model. arXiv preprint arXiv:1907.02436. (see Section 5)","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/ranked_prob_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ranked probability scores for ordinal classification models ‚Äî ranked_prob_score","text":"","code":"library(dplyr) data(hpc_cv)  hpc_cv$obs <- as.ordered(hpc_cv$obs)  # You can use the col1:colN tidyselect syntax hpc_cv %>%   filter(Resample == \"Fold01\") %>%   ranked_prob_score(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric           .estimator .estimate #>   <chr>             <chr>          <dbl> #> 1 ranked_prob_score multiclass    0.0810  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   ranked_prob_score(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric           .estimator .estimate #>    <chr>    <chr>             <chr>          <dbl> #>  1 Fold01   ranked_prob_score multiclass    0.0810 #>  2 Fold02   ranked_prob_score multiclass    0.0870 #>  3 Fold03   ranked_prob_score multiclass    0.0713 #>  4 Fold04   ranked_prob_score multiclass    0.0825 #>  5 Fold05   ranked_prob_score multiclass    0.0876 #>  6 Fold06   ranked_prob_score multiclass    0.0833 #>  7 Fold07   ranked_prob_score multiclass    0.0926 #>  8 Fold08   ranked_prob_score multiclass    0.0862 #>  9 Fold09   ranked_prob_score multiclass    0.0955 #> 10 Fold10   ranked_prob_score multiclass    0.0897"},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":null,"dir":"Reference","previous_headings":"","what":"Recall ‚Äî recall","title":"Recall ‚Äî recall","text":"functions calculate recall() measurement system finding relevant documents compared reference results (truth regarding relevance). Highly related functions precision() f_meas().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recall ‚Äî recall","text":"","code":"recall(data, ...)  # S3 method for class 'data.frame' recall(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  recall_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recall ‚Äî recall","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recall ‚Äî recall","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. recall_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recall ‚Äî recall","text":"recall (aka sensitivity) defined proportion relevant results number samples actually relevant. relevant results, recall defined value NA returned. denominator calculation 0, recall undefined. happens # true_positive = 0 # false_negative = 0 true, mean true events. computing binary recall, NA value returned warning. computing multiclass recall, individual NA values removed, computation procede, warning.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Recall ‚Äî recall","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Recall ‚Äî recall","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Recall ‚Äî recall","text":"Suppose 2x2 table notation: formulas used : $$recall = /(+C)$$ $$precision = /(+B)$$ $$F_{meas} = (1+\\beta^2) * precision * recall/((\\beta^2 * precision)+recall)$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Recall ‚Äî recall","text":"Buckland, M., & Gey, F. (1994). relationship Recall Precision. Journal American Society Information Science, 45(1), 12-19. Powers, D. (2007). Evaluation: Precision, Recall F Factor ROC, Informedness, Markedness Correlation. Technical Report SIE-07-001, Flinders University","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Recall ‚Äî recall","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/recall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recall ‚Äî recall","text":"","code":"# Two class data(\"two_class_example\") recall(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 recall  binary         0.880  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   recall(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 recall  macro          0.548  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   recall(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   recall  macro          0.548 #>  2 Fold02   recall  macro          0.541 #>  3 Fold03   recall  macro          0.634 #>  4 Fold04   recall  macro          0.570 #>  5 Fold05   recall  macro          0.550 #>  6 Fold06   recall  macro          0.540 #>  7 Fold07   recall  macro          0.531 #>  8 Fold08   recall  macro          0.584 #>  9 Fold09   recall  macro          0.568 #> 10 Fold10   recall  macro          0.537  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   recall(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   recall  macro_weighted     0.726 #>  2 Fold02   recall  macro_weighted     0.712 #>  3 Fold03   recall  macro_weighted     0.758 #>  4 Fold04   recall  macro_weighted     0.712 #>  5 Fold05   recall  macro_weighted     0.712 #>  6 Fold06   recall  macro_weighted     0.697 #>  7 Fold07   recall  macro_weighted     0.675 #>  8 Fold08   recall  macro_weighted     0.721 #>  9 Fold09   recall  macro_weighted     0.673 #> 10 Fold10   recall  macro_weighted     0.699  # Vector version recall_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.879845  # Making Class2 the \"relevant\" level recall_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.7933884"},{"path":"https://yardstick.tidymodels.org/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. generics tidy","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root mean squared error ‚Äî rmse","title":"Root mean squared error ‚Äî rmse","text":"Calculate root mean squared error. rmse() metric units original data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root mean squared error ‚Äî rmse","text":"","code":"rmse(data, ...)  # S3 method for class 'data.frame' rmse(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  rmse_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root mean squared error ‚Äî rmse","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root mean squared error ‚Äî rmse","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. rmse_vec(), single numeric value (NA).","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Root mean squared error ‚Äî rmse","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rmse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Root mean squared error ‚Äî rmse","text":"","code":"# Supply truth and predictions as bare column names rmse(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rmse    standard       0.722  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   rmse(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        rmse    standard       0.715 #>  2 10       rmse    standard       0.673 #>  3 2        rmse    standard       0.716 #>  4 3        rmse    standard       0.644 #>  5 4        rmse    standard       0.737 #>  6 5        rmse    standard       0.675 #>  7 6        rmse    standard       0.807 #>  8 7        rmse    standard       0.801 #>  9 8        rmse    standard       0.635 #> 10 9        rmse    standard       0.692  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.710"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the receiver operator curve ‚Äî roc_auc","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"roc_auc() metric computes area ROC curve. See roc_curve() full curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"","code":"roc_auc(data, ...)  # S3 method for class 'data.frame' roc_auc(   data,   truth,   ...,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   options = list() )  roc_auc_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   options = list(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimator One \"binary\", \"hand_till\", \"macro\", \"macro_weighted\" specify type averaging done. \"binary\" relevant two class case. others general methods calculating multiclass metrics. default automatically choose \"binary\" truth binary, \"hand_till\" truth >2 levels case_weights specified, \"macro\" truth >2 levels case_weights specified (case \"hand_till\" well-defined). na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). options [deprecated] longer supported yardstick 1.0.0. pass something ignored warning. Previously, options passed pROC::roc(). need support , use pROC package directly. estimate truth binary, numeric vector class probabilities corresponding \"relevant\" class. Otherwise, matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. roc_auc_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"Generally, ROC AUC value 0.5 1, 1 perfect prediction model. value 0 0.5, implies meaningful information model, applied incorrectly opposite model predicts result AUC >0.5. Note combine estimator = \"hand_till\" case_weights.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"default multiclass method computing roc_auc() use method Hand, Till, (2001). Unlike macro-averaging, method insensitive class distributions like binary ROC AUC case. Additionally, multiclass techniques return NA levels truth occur zero times actual data, Hand-Till method simply ignore levels averaging calculation, warning. Macro macro-weighted averaging still provided, even though default. fact, macro-weighted averaging corresponds definition multiclass AUC given Provost Domingos (2001).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"Hand, Till (2001). \"Simple Generalisation Area ROC Curve Multiple Class Classification Problems\". Machine Learning. Vol 45, Iss 2, pp 171-186. Fawcett (2005). \"introduction ROC analysis\". Pattern Recognition Letters. 27 (2006), pp 861-874. Provost, F., Domingos, P., 2001. \"Well-trained PETs: Improving probability estimation trees\", CeDER Working Paper #-00-04, Stern School Business, New York University, NY, NY 10012.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the receiver operator curve ‚Äî roc_auc","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. roc_auc(two_class_example, truth, Class1) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 roc_auc binary         0.939  # --------------------------------------------------------------------------- # Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   roc_auc(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 roc_auc hand_till      0.813  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   roc_auc(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 roc_auc hand_till      0.813  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   roc_auc(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   roc_auc hand_till      0.813 #>  2 Fold02   roc_auc hand_till      0.817 #>  3 Fold03   roc_auc hand_till      0.869 #>  4 Fold04   roc_auc hand_till      0.849 #>  5 Fold05   roc_auc hand_till      0.811 #>  6 Fold06   roc_auc hand_till      0.836 #>  7 Fold07   roc_auc hand_till      0.825 #>  8 Fold08   roc_auc hand_till      0.846 #>  9 Fold09   roc_auc hand_till      0.828 #> 10 Fold10   roc_auc hand_till      0.812  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   roc_auc(obs, VF:L, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   roc_auc macro_weighted     0.880 #>  2 Fold02   roc_auc macro_weighted     0.873 #>  3 Fold03   roc_auc macro_weighted     0.906 #>  4 Fold04   roc_auc macro_weighted     0.867 #>  5 Fold05   roc_auc macro_weighted     0.866 #>  6 Fold06   roc_auc macro_weighted     0.865 #>  7 Fold07   roc_auc macro_weighted     0.868 #>  8 Fold08   roc_auc macro_weighted     0.865 #>  9 Fold09   roc_auc macro_weighted     0.841 #> 10 Fold10   roc_auc macro_weighted     0.869  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  roc_auc_vec(    truth = fold1$obs,    matrix(      c(fold1$VF, fold1$F, fold1$M, fold1$L),      ncol = 4    ) ) #> [1] 0.8131924"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"Compute area ROC survival curve using predicted survival probabilities corresponds different time points.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"","code":"roc_auc_survival(data, ...)  # S3 method for class 'data.frame' roc_auc_survival(data, truth, ..., na_rm = TRUE, case_weights = NULL)  roc_auc_survival_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"data data.frame containing columns specified truth .... ... column identifier survival probabilities list column data.frames corresponding output given predicting censored model. unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, dots used. truth column identifier true survival result (created using survival::Surv().). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, survival::Surv() object. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). estimate list column data.frames corresponding output given predicting censored model. See details information regarding format.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"tibble columns .metric, .estimator, .estimate. ungrouped data frame, result one row values. grouped data frame, number rows returned number groups. roc_auc_survival_vec(), numeric vector length input argument eval_time. (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"formulation takes survival probability predictions one specific evaluation times , time, computes area ROC curve. account censoring, inverse probability censoring weights (IPCW) used calculations. See equation 7 section 4.3 Blanche al (2013) details. column passed ... list column one element per independent experiential unit (e.g. patient). list column contain data frames several columns: .eval_time: time prediction made. .pred_survival: predicted probability survival .eval_time .weight_censored: case weight inverse probability censoring. last column can produced using parsnip::.censoring_weights_graf(). corresponds weighting scheme  Graf et al (1999). internal data set lung_surv shows example format. method automatically groups .eval_time argument. Larger values score associated better model performance.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"Blanche, P., Dartigues, J.-F. Jacqmin-Gadda, H. (2013), Review comparison ROC curve estimators time-dependent outcome marker-dependent censoring. Biom. J., 55: 687-704. Graf, E., Schmoor, C., Sauerbrei, W. Schumacher, M. (1999), Assessment comparison prognostic classification schemes survival data. Statist. Med., 18: 2529-2545.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"Emil Hvitfeldt","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_auc_survival.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-Dependent ROC AUC for Censored Data ‚Äî roc_auc_survival","text":"","code":"library(dplyr)  lung_surv %>%   roc_auc_survival(     truth = surv_obj,     .pred   ) #> # A tibble: 5 √ó 4 #>   .metric          .estimator .eval_time .estimate #>   <chr>            <chr>           <dbl>     <dbl> #> 1 roc_auc_survival standard          100     0.659 #> 2 roc_auc_survival standard          200     0.678 #> 3 roc_auc_survival standard          300     0.684 #> 4 roc_auc_survival standard          400     0.630 #> 5 roc_auc_survival standard          500     0.643"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"roc_aunp() multiclass metric computes area ROC curve class rest, using priori class distribution. equivalent roc_auc(estimator = \"macro_weighted\").","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"","code":"roc_aunp(data, ...)  # S3 method for class 'data.frame' roc_aunp(data, truth, ..., na_rm = TRUE, case_weights = NULL, options = list())  roc_aunp_vec(   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   options = list(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. many columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). options [deprecated] longer supported yardstick 1.0.0. pass something ignored warning. Previously, options passed pROC::roc(). need support , use pROC package directly. estimate matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. roc_aunp_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"multiclass method computing area ROC curve uses priori class distribution equivalent roc_auc(estimator = \"macro_weighted\").","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"Ferri, C., Hern√°ndez-Orallo, J., & Modroiu, R. (2009). \"experimental comparison performance measures classification\". Pattern Recognition Letters. 30 (1), pp 27-38.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"Julia Silge","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the ROC curve of each class against the rest, using the a priori class distribution ‚Äî roc_aunp","text":"","code":"# Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   roc_aunp(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 roc_aunp macro          0.880  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   roc_aunp(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 roc_aunp macro          0.880  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   roc_aunp(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   roc_aunp macro          0.880 #>  2 Fold02   roc_aunp macro          0.873 #>  3 Fold03   roc_aunp macro          0.906 #>  4 Fold04   roc_aunp macro          0.867 #>  5 Fold05   roc_aunp macro          0.866 #>  6 Fold06   roc_aunp macro          0.865 #>  7 Fold07   roc_aunp macro          0.868 #>  8 Fold08   roc_aunp macro          0.865 #>  9 Fold09   roc_aunp macro          0.841 #> 10 Fold10   roc_aunp macro          0.869  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  roc_aunp_vec(   truth = fold1$obs,   matrix(     c(fold1$VF, fold1$F, fold1$M, fold1$L),     ncol = 4   ) ) #> [1] 0.8795121"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":null,"dir":"Reference","previous_headings":"","what":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"roc_aunu() multiclass metric computes area ROC curve class rest, using uniform class distribution. equivalent roc_auc(estimator = \"macro\").","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"","code":"roc_aunu(data, ...)  # S3 method for class 'data.frame' roc_aunu(data, truth, ..., na_rm = TRUE, case_weights = NULL, options = list())  roc_aunu_vec(   truth,   estimate,   na_rm = TRUE,   case_weights = NULL,   options = list(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. many columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). options [deprecated] longer supported yardstick 1.0.0. pass something ignored warning. Previously, options passed pROC::roc(). need support , use pROC package directly. estimate matrix many columns factor levels truth. assumed order levels truth.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. roc_aunu_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"multiclass method computing area ROC curve uses uniform class distribution equivalent roc_auc(estimator = \"macro\").","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"Ferri, C., Hern√°ndez-Orallo, J., & Modroiu, R. (2009). \"experimental comparison performance measures classification\". Pattern Recognition Letters. 30 (1), pp 27-38.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"Julia Silge","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_aunu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Area under the ROC curve of each class against the rest, using the uniform class distribution ‚Äî roc_aunu","text":"","code":"# Multiclass example  # `obs` is a 4 level factor. The first level is `\"VF\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(hpc_cv)  # You can use the col1:colN tidyselect syntax library(dplyr) hpc_cv %>%   filter(Resample == \"Fold01\") %>%   roc_aunu(obs, VF:L) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 roc_aunu macro          0.871  # Change the first level of `obs` from `\"VF\"` to `\"M\"` to alter the # event of interest. The class probability columns should be supplied # in the same order as the levels. hpc_cv %>%   filter(Resample == \"Fold01\") %>%   mutate(obs = relevel(obs, \"M\")) %>%   roc_aunu(obs, M, VF:L) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 roc_aunu macro          0.871  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   roc_aunu(obs, VF:L) #> # A tibble: 10 √ó 4 #>    Resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 Fold01   roc_aunu macro          0.871 #>  2 Fold02   roc_aunu macro          0.863 #>  3 Fold03   roc_aunu macro          0.898 #>  4 Fold04   roc_aunu macro          0.874 #>  5 Fold05   roc_aunu macro          0.865 #>  6 Fold06   roc_aunu macro          0.877 #>  7 Fold07   roc_aunu macro          0.865 #>  8 Fold08   roc_aunu macro          0.873 #>  9 Fold09   roc_aunu macro          0.855 #> 10 Fold10   roc_aunu macro          0.865  # Vector version # Supply a matrix of class probabilities fold1 <- hpc_cv %>%   filter(Resample == \"Fold01\")  roc_aunu_vec(   truth = fold1$obs,   matrix(     c(fold1$VF, fold1$F, fold1$M, fold1$L),     ncol = 4   ) ) #> [1] 0.8714461"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Receiver operator curve ‚Äî roc_curve","title":"Receiver operator curve ‚Äî roc_curve","text":"roc_curve() constructs full ROC curve returns tibble. See roc_auc() area ROC curve.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Receiver operator curve ‚Äî roc_curve","text":"","code":"roc_curve(data, ...)  # S3 method for class 'data.frame' roc_curve(   data,   truth,   ...,   na_rm = TRUE,   event_level = yardstick_event_level(),   case_weights = NULL,   options = list() )"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Receiver operator curve ‚Äî roc_curve","text":"data data.frame containing columns specified truth .... ... set unquoted column names one dplyr selector functions choose variables contain class probabilities. truth binary, 1 column selected, correspond value event_level. Otherwise, many columns factor levels truth ordering columns factor levels truth. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). options [deprecated] longer supported yardstick 1.0.0. pass something ignored warning. Previously, options passed pROC::roc(). need support , use pROC package directly.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Receiver operator curve ‚Äî roc_curve","text":"tibble class roc_df roc_grouped_df columns .threshold, specificity, sensitivity.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Receiver operator curve ‚Äî roc_curve","text":"roc_curve() computes sensitivity every unique value probability column (addition infinity minus infinity). ggplot2::autoplot() method quickly visualizing curve. works binary multiclass output, also works grouped data (.e. resamples). See examples.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Receiver operator curve ‚Äî roc_curve","text":"multiclass truth column provided, one-vs-approach taken calculate multiple curves, one per level. case, additional column, .level, identifying \"one\" column one-vs-calculation.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Receiver operator curve ‚Äî roc_curve","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Receiver operator curve ‚Äî roc_curve","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Receiver operator curve ‚Äî roc_curve","text":"","code":"# --------------------------------------------------------------------------- # Two class example  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section above. data(two_class_example)  # Binary metrics using class probabilities take a factor `truth` column, # and a single class probability column containing the probabilities of # the event of interest. Here, since `\"Class1\"` is the first level of # `\"truth\"`, it is the event of interest and we pass in probabilities for it. roc_curve(two_class_example, truth, Class1) #> # A tibble: 502 √ó 3 #>    .threshold specificity sensitivity #>         <dbl>       <dbl>       <dbl> #>  1 -Inf           0                 1 #>  2    1.79e-7     0                 1 #>  3    4.50e-6     0.00413           1 #>  4    5.81e-6     0.00826           1 #>  5    5.92e-6     0.0124            1 #>  6    1.22e-5     0.0165            1 #>  7    1.40e-5     0.0207            1 #>  8    1.43e-5     0.0248            1 #>  9    2.38e-5     0.0289            1 #> 10    3.30e-5     0.0331            1 #> # ‚Ñπ 492 more rows  # --------------------------------------------------------------------------- # `autoplot()`  # Visualize the curve using ggplot2 manually library(ggplot2) library(dplyr) roc_curve(two_class_example, truth, Class1) %>%   ggplot(aes(x = 1 - specificity, y = sensitivity)) +   geom_path() +   geom_abline(lty = 3) +   coord_equal() +   theme_bw()   # Or use autoplot autoplot(roc_curve(two_class_example, truth, Class1))   if (FALSE) { # \\dontrun{  # Multiclass one-vs-all approach # One curve per level hpc_cv %>%   filter(Resample == \"Fold01\") %>%   roc_curve(obs, VF:L) %>%   autoplot()  # Same as above, but will all of the resamples hpc_cv %>%   group_by(Resample) %>%   roc_curve(obs, VF:L) %>%   autoplot() } # }"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"Compute ROC survival curve using predicted survival probabilities corresponds different time points.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"","code":"roc_curve_survival(data, ...)  # S3 method for class 'data.frame' roc_curve_survival(data, truth, ..., na_rm = TRUE, case_weights = NULL)"},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"data data.frame containing columns specified truth .... ... column identifier survival probabilities list column data.frames corresponding output given predicting censored model. unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, dots used. truth column identifier true survival result (created using survival::Surv().). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, survival::Surv() object. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"tibble class roc_survival_df, grouped_roc_survival_df columns .threshold, sensitivity, specificity, .eval_time.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"formulation takes survival probability predictions one specific evaluation times , time, computes ROC curve. account censoring, inverse probability censoring weights (IPCW) used calculations. See equation 7 section 4.3 Blanche al (2013) details. column passed ... list column one element per independent experiential unit (e.g. patient). list column contain data frames several columns: .eval_time: time prediction made. .pred_survival: predicted probability survival .eval_time .weight_censored: case weight inverse probability censoring. last column can produced using parsnip::.censoring_weights_graf(). corresponds weighting scheme  Graf et al (1999). internal data set lung_surv shows example format. method automatically groups .eval_time argument.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"Blanche, P., Dartigues, J.-F. Jacqmin-Gadda, H. (2013), Review comparison ROC curve estimators time-dependent outcome marker-dependent censoring. Biom. J., 55: 687-704. Graf, E., Schmoor, C., Sauerbrei, W. Schumacher, M. (1999), Assessment comparison prognostic classification schemes survival data. Statist. Med., 18: 2529-2545.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"Emil Hvitfeldt","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/roc_curve_survival.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-Dependent ROC surve for Censored Data ‚Äî roc_curve_survival","text":"","code":"result <- roc_curve_survival(   lung_surv,   truth = surv_obj,   .pred ) result #> # A tibble: 650 √ó 4 #>    .threshold specificity sensitivity .eval_time #>         <dbl>       <dbl>       <dbl>      <dbl> #>  1    Inf           1          0             100 #>  2      0.948       0.995      0             100 #>  3      0.947       0.985      0.0333        100 #>  4      0.946       0.985      0.133         100 #>  5      0.945       0.985      0.167         100 #>  6      0.945       0.980      0.233         100 #>  7      0.944       0.969      0.233         100 #>  8      0.944       0.964      0.267         100 #>  9      0.942       0.959      0.267         100 #> 10      0.941       0.954      0.267         100 #> # ‚Ñπ 640 more rows  # --------------------------------------------------------------------------- # `autoplot()`  # Visualize the curve using ggplot2 manually library(ggplot2) library(dplyr) result %>%   mutate(.eval_time = format(.eval_time)) %>%   ggplot(aes(     x = 1 - specificity, y = sensitivity,     group = .eval_time, col = .eval_time   )) +   geom_step(direction = \"hv\") +   geom_abline(lty = 3) +   coord_equal() +   theme_bw()   # Or use autoplot autoplot(result)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":null,"dir":"Reference","previous_headings":"","what":"Ratio of performance to deviation ‚Äî rpd","title":"Ratio of performance to deviation ‚Äî rpd","text":"functions appropriate cases model outcome numeric. ratio performance deviation (rpd()) ratio performance inter-quartile (rpiq()) measures consistency/correlation observed predicted values (accuracy).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ratio of performance to deviation ‚Äî rpd","text":"","code":"rpd(data, ...)  # S3 method for class 'data.frame' rpd(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  rpd_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ratio of performance to deviation ‚Äî rpd","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ratio of performance to deviation ‚Äî rpd","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. rpd_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ratio of performance to deviation ‚Äî rpd","text":"field spectroscopy particular, ratio performance deviation (RPD) used standard way report quality model. ratio standard deviation variable standard error prediction variable given model. However, systematic use criticized several authors, since using standard deviation represent spread variable can misleading skewed dataset. ratio performance inter-quartile introduced Bellon-Maurel et al. (2010) address issues, generalise RPD non-normally distributed variables.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ratio of performance to deviation ‚Äî rpd","text":"Williams, P.C. (1987) Variables affecting near-infrared reflectance spectroscopic analysis. : Near Infrared Technology Agriculture Food Industries. 1st Ed. P.Williams K.Norris, Eds. . Cereal Assoc. Cereal Chem., St. Paul, MN. Bellon-Maurel, V., Fernandez-Ahumada, E., Palagos, B., Roger, J.M. McBratney, ., (2010). Critical review chemometric indicators commonly used assessing quality prediction soil attributes NIR spectroscopy. TrAC Trends Analytical Chemistry, 29(9), pp.1073-1081.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Ratio of performance to deviation ‚Äî rpd","text":"Pierre Roudier","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ratio of performance to deviation ‚Äî rpd","text":"","code":"# Supply truth and predictions as bare column names rpd(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rpd     standard        2.88  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   rpd(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        rpd     standard        2.78 #>  2 10       rpd     standard        2.87 #>  3 2        rpd     standard        3.04 #>  4 3        rpd     standard        3.41 #>  5 4        rpd     standard        3.02 #>  6 5        rpd     standard        2.66 #>  7 6        rpd     standard        2.81 #>  8 7        rpd     standard        2.61 #>  9 8        rpd     standard        3.45 #> 10 9        rpd     standard        2.93  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1         2.96"},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":null,"dir":"Reference","previous_headings":"","what":"Ratio of performance to inter-quartile ‚Äî rpiq","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"functions appropriate cases model outcome numeric. ratio performance deviation (rpd()) ratio performance inter-quartile (rpiq()) measures consistency/correlation observed predicted values (accuracy).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"","code":"rpiq(data, ...)  # S3 method for class 'data.frame' rpiq(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  rpiq_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. rpd_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"field spectroscopy particular, ratio performance deviation (RPD) used standard way report quality model. ratio standard deviation variable standard error prediction variable given model. However, systematic use criticized several authors, since using standard deviation represent spread variable can misleading skewed dataset. ratio performance inter-quartile introduced Bellon-Maurel et al. (2010) address issues, generalise RPD non-normally distributed variables.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"Williams, P.C. (1987) Variables affecting near-infrared reflectance spectroscopic analysis. : Near Infrared Technology Agriculture Food Industries. 1st Ed. P.Williams K.Norris, Eds. . Cereal Assoc. Cereal Chem., St. Paul, MN. Bellon-Maurel, V., Fernandez-Ahumada, E., Palagos, B., Roger, J.M. McBratney, ., (2010). Critical review chemometric indicators commonly used assessing quality prediction soil attributes NIR spectroscopy. TrAC Trends Analytical Chemistry, 29(9), pp.1073-1081.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"Pierre Roudier","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rpiq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ratio of performance to inter-quartile ‚Äî rpiq","text":"","code":"# Supply truth and predictions as bare column names rpd(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rpd     standard        2.88  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   rpd(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        rpd     standard        2.78 #>  2 10       rpd     standard        2.87 #>  3 2        rpd     standard        3.04 #>  4 3        rpd     standard        3.41 #>  5 4        rpd     standard        3.02 #>  6 5        rpd     standard        2.66 #>  7 6        rpd     standard        2.81 #>  8 7        rpd     standard        2.61 #>  9 8        rpd     standard        3.45 #> 10 9        rpd     standard        2.93  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1         2.96"},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":null,"dir":"Reference","previous_headings":"","what":"R squared ‚Äî rsq","title":"R squared ‚Äî rsq","text":"Calculate coefficient determination using correlation. traditional measure R squared, see rsq_trad().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R squared ‚Äî rsq","text":"","code":"rsq(data, ...)  # S3 method for class 'data.frame' rsq(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  rsq_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R squared ‚Äî rsq","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"R squared ‚Äî rsq","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. rsq_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"R squared ‚Äî rsq","text":"two estimates coefficient determination, rsq() rsq_trad(), differ formula. former guarantees value (0, 1) latter can generate inaccurate values model non-informative (see examples). measures consistency/correlation accuracy. rsq() simply squared correlation truth estimate. rsq() internally computes correlation, either truth estimate constant can result divide zero error. cases, warning thrown NA returned. can occur model predicts single value samples. example, regularized model eliminates predictors except intercept . Another example CART model contains splits.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"R squared ‚Äî rsq","text":"Kvalseth. Cautionary note \\(R^2\\). American Statistician (1985) vol. 39 (4) pp. 279-285.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"R squared ‚Äî rsq","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"R squared ‚Äî rsq","text":"","code":"# Supply truth and predictions as bare column names rsq(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rsq     standard       0.879  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   rsq(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        rsq     standard       0.874 #>  2 10       rsq     standard       0.879 #>  3 2        rsq     standard       0.891 #>  4 3        rsq     standard       0.916 #>  5 4        rsq     standard       0.892 #>  6 5        rsq     standard       0.858 #>  7 6        rsq     standard       0.873 #>  8 7        rsq     standard       0.852 #>  9 8        rsq     standard       0.915 #> 10 9        rsq     standard       0.884  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.883 # With uninformitive data, the traditional version of R^2 can return # negative values. set.seed(2291) solubility_test$randomized <- sample(solubility_test$prediction) rsq(solubility_test, solubility, randomized) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rsq     standard     0.00199 rsq_trad(solubility_test, solubility, randomized) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 rsq_trad standard       -1.01  # A constant `truth` or `estimate` vector results in a warning from # a divide by zero error in the correlation calculation. # `NA` will be returned in these cases. truth <- c(1, 2) estimate <- c(1, 1) rsq_vec(truth, estimate) #> Warning: A correlation computation is required, but `estimate` is constant and #> has 0 standard deviation, resulting in a divide by 0 error. `NA` will #> be returned. #> [1] NA"},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":null,"dir":"Reference","previous_headings":"","what":"R squared - traditional ‚Äî rsq_trad","title":"R squared - traditional ‚Äî rsq_trad","text":"Calculate coefficient determination using traditional definition R squared using sum squares. measure R squared strictly (0, 1), see rsq().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R squared - traditional ‚Äî rsq_trad","text":"","code":"rsq_trad(data, ...)  # S3 method for class 'data.frame' rsq_trad(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  rsq_trad_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R squared - traditional ‚Äî rsq_trad","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"R squared - traditional ‚Äî rsq_trad","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. rsq_trad_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"R squared - traditional ‚Äî rsq_trad","text":"two estimates coefficient determination, rsq() rsq_trad(), differ formula. former guarantees value (0, 1) latter can generate inaccurate values model non-informative (see examples). measures consistency/correlation accuracy.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"R squared - traditional ‚Äî rsq_trad","text":"Kvalseth. Cautionary note \\(R^2\\). American Statistician (1985) vol. 39 (4) pp. 279-285.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"R squared - traditional ‚Äî rsq_trad","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/rsq_trad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"R squared - traditional ‚Äî rsq_trad","text":"","code":"# Supply truth and predictions as bare column names rsq_trad(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 rsq_trad standard       0.879  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   rsq_trad(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric  .estimator .estimate #>    <chr>    <chr>    <chr>          <dbl> #>  1 1        rsq_trad standard       0.870 #>  2 10       rsq_trad standard       0.878 #>  3 2        rsq_trad standard       0.891 #>  4 3        rsq_trad standard       0.913 #>  5 4        rsq_trad standard       0.889 #>  6 5        rsq_trad standard       0.857 #>  7 6        rsq_trad standard       0.872 #>  8 7        rsq_trad standard       0.852 #>  9 8        rsq_trad standard       0.915 #> 10 9        rsq_trad standard       0.883  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1        0.882 # With uninformitive data, the traditional version of R^2 can return # negative values. set.seed(2291) solubility_test$randomized <- sample(solubility_test$prediction) rsq(solubility_test, solubility, randomized) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 rsq     standard     0.00199 rsq_trad(solubility_test, solubility, randomized) #> # A tibble: 1 √ó 3 #>   .metric  .estimator .estimate #>   <chr>    <chr>          <dbl> #> 1 rsq_trad standard       -1.01"},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensitivity ‚Äî sens","title":"Sensitivity ‚Äî sens","text":"functions calculate sens() (sensitivity) measurement system compared reference result (\"truth\" gold standard). Highly related functions spec(), ppv(), npv().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensitivity ‚Äî sens","text":"","code":"sens(data, ...)  # S3 method for class 'data.frame' sens(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  sens_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  sensitivity(data, ...)  # S3 method for class 'data.frame' sensitivity(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  sensitivity_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sensitivity ‚Äî sens","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sensitivity ‚Äî sens","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. sens_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sensitivity ‚Äî sens","text":"sensitivity (sens()) defined proportion positive results number samples actually positive. denominator calculation 0, sensitivity undefined. happens # true_positive = 0 # false_negative = 0 true, mean true events. computing binary sensitivity, NA value returned warning. computing multiclass sensitivity, individual NA values removed, computation procede, warning.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Sensitivity ‚Äî sens","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Sensitivity ‚Äî sens","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Sensitivity ‚Äî sens","text":"Suppose 2x2 table notation: formulas used : $$Sensitivity = /(+C)$$ $$Specificity = D/(B+D)$$ $$Prevalence = (+C)/(+B+C+D)$$ $$PPV = (Sensitivity * Prevalence) / ((Sensitivity * Prevalence) + ((1-Specificity) * (1-Prevalence)))$$ $$NPV = (Specificity * (1-Prevalence)) / (((1-Sensitivity) * Prevalence) + ((Specificity) * (1-Prevalence)))$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sensitivity ‚Äî sens","text":"Altman, D.G., Bland, J.M. (1994) ‚ÄúDiagnostic tests 1: sensitivity specificity,‚Äù British Medical Journal, vol 308, 1552.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sensitivity ‚Äî sens","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/sens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sensitivity ‚Äî sens","text":"","code":"# Two class data(\"two_class_example\") sens(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 sens    binary         0.880  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   sens(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 sens    macro          0.548  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   sens(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   sens    macro          0.548 #>  2 Fold02   sens    macro          0.541 #>  3 Fold03   sens    macro          0.634 #>  4 Fold04   sens    macro          0.570 #>  5 Fold05   sens    macro          0.550 #>  6 Fold06   sens    macro          0.540 #>  7 Fold07   sens    macro          0.531 #>  8 Fold08   sens    macro          0.584 #>  9 Fold09   sens    macro          0.568 #> 10 Fold10   sens    macro          0.537  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   sens(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   sens    macro_weighted     0.726 #>  2 Fold02   sens    macro_weighted     0.712 #>  3 Fold03   sens    macro_weighted     0.758 #>  4 Fold04   sens    macro_weighted     0.712 #>  5 Fold05   sens    macro_weighted     0.712 #>  6 Fold06   sens    macro_weighted     0.697 #>  7 Fold07   sens    macro_weighted     0.675 #>  8 Fold08   sens    macro_weighted     0.721 #>  9 Fold09   sens    macro_weighted     0.673 #> 10 Fold10   sens    macro_weighted     0.699  # Vector version sens_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.879845  # Making Class2 the \"relevant\" level sens_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.7933884"},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":null,"dir":"Reference","previous_headings":"","what":"Symmetric mean absolute percentage error ‚Äî smape","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"Calculate symmetric mean absolute percentage error. metric relative units.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"","code":"smape(data, ...)  # S3 method for class 'data.frame' smape(data, truth, estimate, na_rm = TRUE, case_weights = NULL, ...)  smape_vec(truth, estimate, na_rm = TRUE, case_weights = NULL, ...)"},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"data data.frame containing columns specified truth estimate arguments. ... currently used. truth column identifier true results (numeric). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, numeric vector. estimate column identifier predicted results (also numeric). truth can specified different ways primary method use unquoted variable name. _vec() functions, numeric vector. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. smape_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"implementation smape() \"usual definition\" denominator divided two.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"Max Kuhn, Riaz Hedayati","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/smape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Symmetric mean absolute percentage error ‚Äî smape","text":"","code":"# Supply truth and predictions as bare column names smape(solubility_test, solubility, prediction) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 smape   standard        36.7  library(dplyr)  set.seed(1234) size <- 100 times <- 10  # create 10 resamples solubility_resampled <- bind_rows(   replicate(     n = times,     expr = sample_n(solubility_test, size, replace = TRUE),     simplify = FALSE   ),   .id = \"resample\" )  # Compute the metric by group metric_results <- solubility_resampled %>%   group_by(resample) %>%   smape(solubility, prediction)  metric_results #> # A tibble: 10 √ó 4 #>    resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 1        smape   standard        33.5 #>  2 10       smape   standard        28.9 #>  3 2        smape   standard        41.6 #>  4 3        smape   standard        28.4 #>  5 4        smape   standard        37.0 #>  6 5        smape   standard        31.8 #>  7 6        smape   standard        48.3 #>  8 7        smape   standard        27.8 #>  9 8        smape   standard        35.6 #> 10 9        smape   standard        30.2  # Resampled mean estimate metric_results %>%   summarise(avg_estimate = mean(.estimate)) #> # A tibble: 1 √ó 1 #>   avg_estimate #>          <dbl> #> 1         34.3"},{"path":"https://yardstick.tidymodels.org/dev/reference/solubility_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Solubility Predictions from MARS Model ‚Äî solubility_test","title":"Solubility Predictions from MARS Model ‚Äî solubility_test","text":"Solubility Predictions MARS Model","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/solubility_test.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Solubility Predictions from MARS Model ‚Äî solubility_test","text":"Kuhn, M., Johnson, K. (2013) Applied Predictive Modeling, Springer","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/solubility_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solubility Predictions from MARS Model ‚Äî solubility_test","text":"solubility_test data frame","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/solubility_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solubility Predictions from MARS Model ‚Äî solubility_test","text":"solubility data Kuhn Johnson (2013), data test set results MARS model. observed solubility (column solubility) model results (prediction) contained data.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/solubility_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solubility Predictions from MARS Model ‚Äî solubility_test","text":"","code":"data(solubility_test) str(solubility_test) #> 'data.frame':\t316 obs. of  2 variables: #>  $ solubility: num  0.93 0.85 0.81 0.74 0.61 0.58 0.57 0.56 0.52 0.45 ... #>  $ prediction: num  0.368 -0.15 -0.505 0.54 -0.479 ..."},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Specificity ‚Äî spec","title":"Specificity ‚Äî spec","text":"functions calculate spec() (specificity) measurement system compared reference result (\"truth\" gold standard). Highly related functions sens(), ppv(), npv().","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specificity ‚Äî spec","text":"","code":"spec(data, ...)  # S3 method for class 'data.frame' spec(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  spec_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  specificity(data, ...)  # S3 method for class 'data.frame' specificity(   data,   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )  specificity_vec(   truth,   estimate,   estimator = NULL,   na_rm = TRUE,   case_weights = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specificity ‚Äî spec","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. case_weights optional column identifier case weights. unquoted column name evaluates numeric column data. _vec() functions, numeric vector, hardhat::importance_weights(), hardhat::frequency_weights(). event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\".","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specificity ‚Äî spec","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. spec_vec(), single numeric value (NA).","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Specificity ‚Äî spec","text":"specificity measures proportion negatives correctly identified negatives. denominator calculation 0, specificity undefined. happens # true_negative = 0 # false_positive = 0 true, mean true negatives. computing binary specificity, NA value returned warning. computing multiclass specificity, individual NA values removed, computation procede, warning.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Specificity ‚Äî spec","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"multiclass","dir":"Reference","previous_headings":"","what":"Multiclass","title":"Specificity ‚Äî spec","text":"Macro, micro, macro-weighted averaging available metric. default select macro averaging truth factor 2 levels provided. Otherwise, standard binary calculation done. See vignette(\"multiclass\", \"yardstick\") information.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"implementation","dir":"Reference","previous_headings":"","what":"Implementation","title":"Specificity ‚Äî spec","text":"Suppose 2x2 table notation: formulas used : $$Sensitivity = /(+C)$$ $$Specificity = D/(B+D)$$ $$Prevalence = (+C)/(+B+C+D)$$ $$PPV = (Sensitivity * Prevalence) / ((Sensitivity * Prevalence) + ((1-Specificity) * (1-Prevalence)))$$ $$NPV = (Specificity * (1-Prevalence)) / (((1-Sensitivity) * Prevalence) + ((Specificity) * (1-Prevalence)))$$ See references discussions statistics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Specificity ‚Äî spec","text":"Altman, D.G., Bland, J.M. (1994) ‚ÄúDiagnostic tests 1: sensitivity specificity,‚Äù British Medical Journal, vol 308, 1552.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Specificity ‚Äî spec","text":"Max Kuhn","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specificity ‚Äî spec","text":"","code":"# Two class data(\"two_class_example\") spec(two_class_example, truth, predicted) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 spec    binary         0.793  # Multiclass library(dplyr) data(hpc_cv)  hpc_cv %>%   filter(Resample == \"Fold01\") %>%   spec(obs, pred) #> # A tibble: 1 √ó 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 spec    macro          0.886  # Groups are respected hpc_cv %>%   group_by(Resample) %>%   spec(obs, pred) #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator .estimate #>    <chr>    <chr>   <chr>          <dbl> #>  1 Fold01   spec    macro          0.886 #>  2 Fold02   spec    macro          0.882 #>  3 Fold03   spec    macro          0.899 #>  4 Fold04   spec    macro          0.879 #>  5 Fold05   spec    macro          0.881 #>  6 Fold06   spec    macro          0.873 #>  7 Fold07   spec    macro          0.866 #>  8 Fold08   spec    macro          0.884 #>  9 Fold09   spec    macro          0.867 #> 10 Fold10   spec    macro          0.875  # Weighted macro averaging hpc_cv %>%   group_by(Resample) %>%   spec(obs, pred, estimator = \"macro_weighted\") #> # A tibble: 10 √ó 4 #>    Resample .metric .estimator     .estimate #>    <chr>    <chr>   <chr>              <dbl> #>  1 Fold01   spec    macro_weighted     0.816 #>  2 Fold02   spec    macro_weighted     0.815 #>  3 Fold03   spec    macro_weighted     0.839 #>  4 Fold04   spec    macro_weighted     0.803 #>  5 Fold05   spec    macro_weighted     0.812 #>  6 Fold06   spec    macro_weighted     0.795 #>  7 Fold07   spec    macro_weighted     0.790 #>  8 Fold08   spec    macro_weighted     0.814 #>  9 Fold09   spec    macro_weighted     0.795 #> 10 Fold10   spec    macro_weighted     0.801  # Vector version spec_vec(   two_class_example$truth,   two_class_example$predicted ) #> [1] 0.7933884  # Making Class2 the \"relevant\" level spec_vec(   two_class_example$truth,   two_class_example$predicted,   event_level = \"second\" ) #> [1] 0.879845"},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"Various statistical summaries confusion matrices produced returned tibble. include shown help pages sens(), recall(), accuracy(), among others.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"","code":"# S3 method for class 'conf_mat' summary(   object,   prevalence = NULL,   beta = 1,   estimator = NULL,   event_level = yardstick_event_level(),   ... )"},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"object object class conf_mat(). prevalence number (0, 1) prevalence (.e. prior) event. left default, data used derive value. beta numeric value used weight precision recall f_meas(). estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper defaults \"first\". ... currently used.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"tibble containing various classification metrics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":"relevant-level","dir":"Reference","previous_headings":"","what":"Relevant Level","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"common convention factor level automatically considered \"event\" \"positive\" result computing binary classification metrics. yardstick, default use first level. alter , change argument event_level \"second\" consider last level factor level interest. multiclass extensions involving one-vs-comparisons (macro averaging), option ignored \"one\" level always relevant result.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/summary.conf_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for Confusion Matrices ‚Äî summary.conf_mat","text":"","code":"data(\"two_class_example\")  cmat <- conf_mat(two_class_example, truth = \"truth\", estimate = \"predicted\") summary(cmat) #> # A tibble: 13 √ó 3 #>    .metric              .estimator .estimate #>    <chr>                <chr>          <dbl> #>  1 accuracy             binary         0.838 #>  2 kap                  binary         0.675 #>  3 sens                 binary         0.880 #>  4 spec                 binary         0.793 #>  5 ppv                  binary         0.819 #>  6 npv                  binary         0.861 #>  7 mcc                  binary         0.677 #>  8 j_index              binary         0.673 #>  9 bal_accuracy         binary         0.837 #> 10 detection_prevalence binary         0.554 #> 11 precision            binary         0.819 #> 12 recall               binary         0.880 #> 13 f_meas               binary         0.849 summary(cmat, prevalence = 0.70) #> # A tibble: 13 √ó 3 #>    .metric              .estimator .estimate #>    <chr>                <chr>          <dbl> #>  1 accuracy             binary         0.838 #>  2 kap                  binary         0.675 #>  3 sens                 binary         0.880 #>  4 spec                 binary         0.793 #>  5 ppv                  binary         0.909 #>  6 npv                  binary         0.739 #>  7 mcc                  binary         0.677 #>  8 j_index              binary         0.673 #>  9 bal_accuracy         binary         0.837 #> 10 detection_prevalence binary         0.554 #> 11 precision            binary         0.819 #> 12 recall               binary         0.880 #> 13 f_meas               binary         0.849  library(dplyr) library(tidyr) data(\"hpc_cv\")  # Compute statistics per resample then summarize all_metrics <- hpc_cv %>%   group_by(Resample) %>%   conf_mat(obs, pred) %>%   mutate(summary_tbl = lapply(conf_mat, summary)) %>%   unnest(summary_tbl)  all_metrics %>%   group_by(.metric) %>%   summarise(     mean = mean(.estimate, na.rm = TRUE),     sd = sd(.estimate, na.rm = TRUE)   ) #> # A tibble: 13 √ó 3 #>    .metric               mean       sd #>    <chr>                <dbl>    <dbl> #>  1 accuracy             0.709 2.47e- 2 #>  2 bal_accuracy         0.720 1.92e- 2 #>  3 detection_prevalence 0.25  9.25e-18 #>  4 f_meas               0.569 3.46e- 2 #>  5 j_index              0.439 3.85e- 2 #>  6 kap                  0.508 4.10e- 2 #>  7 mcc                  0.515 4.16e- 2 #>  8 npv                  0.896 1.11e- 2 #>  9 ppv                  0.633 3.87e- 2 #> 10 precision            0.633 3.87e- 2 #> 11 recall               0.560 3.09e- 2 #> 12 sens                 0.560 3.09e- 2 #> 13 spec                 0.879 9.67e- 3"},{"path":"https://yardstick.tidymodels.org/dev/reference/two_class_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Two Class Predictions ‚Äî two_class_example","title":"Two Class Predictions ‚Äî two_class_example","text":"Two Class Predictions","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/two_class_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two Class Predictions ‚Äî two_class_example","text":"two_class_example data frame","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/two_class_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Two Class Predictions ‚Äî two_class_example","text":"data test set form model built two classes (\"Class1\" \"Class2\"). columns true predicted classes column probabilities class.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/two_class_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two Class Predictions ‚Äî two_class_example","text":"","code":"data(two_class_example) str(two_class_example) #> 'data.frame':\t500 obs. of  4 variables: #>  $ truth    : Factor w/ 2 levels \"Class1\",\"Class2\": 2 1 2 1 2 1 1 1 2 2 ... #>  $ Class1   : num  0.00359 0.67862 0.11089 0.73516 0.01624 ... #>  $ Class2   : num  0.996 0.321 0.889 0.265 0.984 ... #>  $ predicted: Factor w/ 2 levels \"Class1\",\"Class2\": 2 1 2 1 2 1 1 1 2 2 ...  # `truth` is a 2 level factor. The first level is `\"Class1\"`, which is the # \"event of interest\" by default in yardstick. See the Relevant Level # section in any classification function (such as `?pr_auc`) to see how # to change this. levels(hpc_cv$obs) #> [1] \"VF\" \"F\"  \"M\"  \"L\""},{"path":"https://yardstick.tidymodels.org/dev/reference/yardstick-package.html","id":null,"dir":"Reference","previous_headings":"","what":"yardstick: Tidy Characterizations of Model Performance ‚Äî yardstick-package","title":"yardstick: Tidy Characterizations of Model Performance ‚Äî yardstick-package","text":"Tidy tools quantifying well model fits data set confusion matrices, class probability curve summaries, regression metrics (e.g., RMSE).","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/reference/yardstick-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"yardstick: Tidy Characterizations of Model Performance ‚Äî yardstick-package","text":"Maintainer: Emil Hvitfeldt emil.hvitfeldt@posit.co (ORCID) Authors: Max Kuhn max@posit.co Davis Vaughan davis@posit.co contributors: Posit Software, PBC [copyright holder, funder]","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/yardstick_remove_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for handling missing values in new metrics ‚Äî yardstick_remove_missing","title":"Developer function for handling missing values in new metrics ‚Äî yardstick_remove_missing","text":"yardstick_remove_missing(),  yardstick_any_missing() useful alongside metric-summarizers functions implementing new custom metrics. yardstick_remove_missing() removes observations contains missing values across, truth, estimate case_weights. yardstick_any_missing() returns FALSE missing values inputs.","code":""},{"path":"https://yardstick.tidymodels.org/dev/reference/yardstick_remove_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for handling missing values in new metrics ‚Äî yardstick_remove_missing","text":"","code":"yardstick_remove_missing(truth, estimate, case_weights)  yardstick_any_missing(truth, estimate, case_weights)"},{"path":"https://yardstick.tidymodels.org/dev/reference/yardstick_remove_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for handling missing values in new metrics ‚Äî yardstick_remove_missing","text":"truth, estimate Vectors length. case_weights vector length truth estimate, NULL case weights used.","code":""},{"path":[]},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-development-version","dir":"Changelog","previous_headings":"","what":"yardstick (development version)","title":"yardstick (development version)","text":"ranked probability score ordinal classification data added ranked_prob_score(). (#524) poisson_log_loss() enhanced handle 0 valued estimates, longer returning Inf NaN. (#513) Fixed bug ranked probability metrics didn‚Äôt work combination classificiation metrics metric_set(). (#539)","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-132","dir":"Changelog","previous_headings":"","what":"yardstick 1.3.2","title":"yardstick 1.3.2","text":"CRAN release: 2025-01-22 messages, warnings errors translated use {cli} package (#517, #522).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-131","dir":"Changelog","previous_headings":"","what":"yardstick 1.3.1","title":"yardstick 1.3.1","text":"CRAN release: 2024-03-21","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"bug-fixes-1-3-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"yardstick 1.3.1","text":"Bug fixed roc_curve_survival() wrong weights used. (#495, @asb2111). Output roc_curve_survival() now returns columns order roc_curve(). (#498)","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-130","dir":"Changelog","previous_headings":"","what":"yardstick 1.3.0","title":"yardstick 1.3.0","text":"CRAN release: 2024-01-19","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"new-metrics-1-3-0","dir":"Changelog","previous_headings":"","what":"New Metrics","title":"yardstick 1.3.0","text":"Brier score survival data added brier_survival(). Integrated Brier score survival data added brier_survival_integrated(). Concordance index survival data added concordance_survival(). Time-Dependent ROC curves estimation right-censored data can now calculated roc_curve_survival(). Time-Dependent ROC AUC estimation right-censored data can now calculated roc_auc_survival().","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"improvements-1-3-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"yardstick 1.3.0","text":"demographic_parity(), equalized_odds(), equal_opportunity() new metrics measuring model fairness. implemented new_groupwise_metric() constructor, general interface defining group-aware metrics allows quickly flexibly defining fairness metrics problem context mind. metric_set() can now used combination dynamic static survival metrics. Added print method metrics metric sets (#435). warnings errors updated use cli package increased clarity consistency. (#456, #457, #458) brier_survival_integrated() now throws error input data includes 1 evalution time point. (#460) Clarifying documentation event_level always default \"first. (#432)","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"bug-fixes-1-3-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"yardstick 1.3.0","text":"Metrics now throw informative error estimate argument wrongly used. (#443)","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"breaking-changes-1-3-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"yardstick 1.3.0","text":"Curve metrics now throw informative error instead returning NA missing values found na_rm = FALSE. (#344)","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-120","dir":"Changelog","previous_headings":"","what":"yardstick 1.2.0","title":"yardstick 1.2.0","text":"CRAN release: 2023-04-21","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"new-metrics-1-2-0","dir":"Changelog","previous_headings":"","what":"New Metrics","title":"yardstick 1.2.0","text":"Brier score classification added brier_class() (#139).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"improvements-1-2-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"yardstick 1.2.0","text":"global option, yardstick.event_first, hard deprecated favor using explicit argument, event_level. Setting option now produce warning, won‚Äôt effect. (#173) Removed start-message event_level argument. yardstick metric functions now use pure tidyselect interface truth, estimate, ... class probability metrics (#322). Changed default aspect ratio PR curves 1.0. Error messages now show user-facing function called (#348). classification probability metrics now fully support class_pred objects {probably} package (#341).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"bug-fixes-1-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"yardstick 1.2.0","text":"Using metric_set() metric created metric_tweak() longer produces error, favor arguments set metric_tweak() (#351). Metric summarizers longer error column names data conflict argument names (#382). conf_mat() longer throw errors listed internal (#327).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"developer-1-2-0","dir":"Changelog","previous_headings":"","what":"Developer","title":"yardstick 1.2.0","text":"metric_vec_template() soft deprecated favor manual flexible metric creation approach. yardstick_remove_missing() yardstick_any_missing() added treatment missing values. check_class_metric(), check_numeric_metric(), check_prob_metric() added perform standardized input checking classification, regression class probability metrics respectively. changes mean developer‚Äôs responsibility perform validation truth estimate input. (#337). metric_summarizer() soft deprecated favor specific newly added class_metric_summarizer(), numeric_metric_summarizer(), prob_metric_summarizer(), curve_metric_summarizer() (#322). dots_to_estimate() soft deprecated along metric_summarizer(). dots_to_estimate() needed prob_metric_summarizer(), curve_metric_summarizer() (#329).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-110","dir":"Changelog","previous_headings":"","what":"yardstick 1.1.0","title":"yardstick 1.1.0","text":"CRAN release: 2022-09-07 Emil Hvitfeldt now maintainer (#315). Improved chained error thrown metric_set() one metric computations fails (#313).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-100","dir":"Changelog","previous_headings":"","what":"yardstick 1.0.0","title":"yardstick 1.0.0","text":"CRAN release: 2022-06-06 yardstick metrics now support case weights new case_weights argument. also includes metric-adjacent functions like roc_curve(), pr_curve(), conf_mat(), metric_set(). options argument roc_curve(), roc_auc(), roc_aunp(), roc_aunu(), metrics() passed along pROC package now deprecated longer affect. result changing ROC curve implementation supports case weights, support previous options. need options, suggest wrapping pROC custom metric (#296). conf_mat() now ignores inputs passed ... warns try thing. Previously, passed base::table(), addition case weight support, table() longer used (#295). Fixed small mistake ccc() unbiased covariance wasn‚Äôt used bias = FALSE. j_index() now throws correct warning 0 denominator computing sens() internally. Additionally, multiclass case now removes levels occurs multiclass weighted average computation, consistent metrics updated handle #118 (#265). Improved possible ambiguity documentation data argument metrics (#255). purrr removed Suggests. pROC package removed dependency (#300). Moved Custom Metrics vignette tidymodels.org (#236).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-009","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.9","title":"yardstick 0.0.9","text":"CRAN release: 2021-11-22 New metric poisson_log_loss() added (#146). sensitivity() specificity() now work correctly tune workflowsets packages (#232). roc_curve() now throws informative error truth doesn‚Äôt control event observations. dplyr 1.0.0 now required. allowed us remove multiple usages dplyr::() favor dplyr::summarise(), can now return packed data frame columns multiple rows per group. Removed internal hardcoding \"dplyr_error\" avoid issues upcoming dplyr 1.0.8 release (#244). Updated test suite testthat 3e (#243). Internal upkeep done move rlang::warn(.subclass = ) rlang::warn(class = ), since .subclass argument deprecated (#225).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-008","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.8","title":"yardstick 0.0.8","text":"CRAN release: 2021-03-28 New metric_tweak() adjusting default values optional arguments existing yardstick metric. useful quickly adjust defaults metric included metric_set(), especially metric set going used tuning tune package (#206, #182). New classification_cost() metric computing cost poor class probability prediction using user-defined costs (#3). New msd() computing mean signed deviation (also called mean signed difference, mean signed error) (#183, @datenzauberai). class_pred objects probably package now supported, automatically converted factors computing metric. Note means equivocal values materialized NA (#198). kap() metric new weighting argument apply linear quadratic weightings computing kappa value (#2, #125, @jonthegeek). sens() undefined computing ppv(), npv(), j_index(), bal_accuracy(), sensitivity warning now correctly thrown, rather recall warning (#101). autoplot() method gain curves now plots curve line top shaded polygon, resulting sharper look line (#192, @eddjberry). autoplot() methods conf_mat now respect user-defined dimension names added conf_mat(dnn = ) converting table dimension names conf_mat (#191). Added as_tibble() method metric_set objects. Printing metric_set now uses print tibble rather data frame (#186). Re-licensed package GPL-2 MIT. See consent copyright holders (#204).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-007","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.7","title":"yardstick 0.0.7","text":"CRAN release: 2020-07-13 global option, yardstick.event_first, deprecated favor new explicit argument, event_level. metric functions previously supported changing ‚Äúevent‚Äù level gained new argument. global option historical design decision can classified case hidden argument. Existing code relied global option continue work version yardstick, however now get -per-session warning requests update instead use explicit event_level argument. global option completely removed future version. update, follow guide (#163). roc_auc() Hand-Till multiclass estimator now ignore levels truth occur zero times actual data. methods multiclass averaging, usually returns NA, however, ignoring levels manner consistent implementations HandTill2001 pROC packages (#123). roc_auc() roc_curve() now set direction = \"<\" computing ROC curve using pROC::roc(). Results computed incorrectly direction = \"auto\" probability values predicting wrong class (#123). mn_log_loss() now respects (deprecated) global option yardstick.event_first. However, instead change relevant event level event_level argument. metric_set() now strips package name auto-labeling functions (@rorynolan, #151). three new helper functions easily creating custom metric functions: new_class_metric(), new_prob_metric(), new_numeric_metric(). Rcpp removed direct dependency.","code":"`options(yardstick.event_first = TRUE)`  -> `event_level = \"first\"` (the default) `options(yardstick.event_first = FALSE)` -> `event_level = \"second\"`"},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-006","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.6","title":"yardstick 0.0.6","text":"CRAN release: 2020-03-17 roc_auc() now warns events controls provided truth column, returns NA (@dpastling, #132). Adds sensitivity() specificity() aliases sens() spec() respectively, avoids conflict packages e.g.¬†readr::spec(). roc_aunu() roc_aunp() two new ROC AUC metrics multiclass classifiers. measure AUC class rest, roc_aunu() using uniform class distribution (#69) roc_aunp() using priori class distribution (#70).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-005","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.5","title":"yardstick 0.0.5","text":"CRAN release: 2020-01-23","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"other-improvements-0-0-5","dir":"Changelog","previous_headings":"","what":"Other improvements","title":"yardstick 0.0.5","text":"autoplot() heat map confusion matrices now places predicted values x axis truth values y axis consistent confusion matrix print() method. autoplot() mosaic plot confusion matrices x y axis labels backwards. corrected.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-004","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.4","title":"yardstick 0.0.4","text":"CRAN release: 2019-08-26","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"new-metrics-and-functionality-0-0-4","dir":"Changelog","previous_headings":"","what":"New metrics and functionality","title":"yardstick 0.0.4","text":"iic() new numeric metric computing index ideality correlation. can seen potential alternative traditional correlation coefficient, used QSAR models (@jyuu, #115). average_precision() new probability metric can used alternative pr_auc(). benefit avoiding issues ambiguity case recall == 0 current number false positives 0.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"other-improvements-0-0-4","dir":"Changelog","previous_headings":"","what":"Other improvements","title":"yardstick 0.0.4","text":"metric_set() output now includes metrics attribute contains list original metric functions used generate metric set. metric function now direction attribute attached , specifying whether minimize maximize metric. Classification metrics can potentially 0 value denominator now throw informative warning case occurs. include recall(), precision(), sens(), spec() (#98). autoplot() method pr_curve() improved always set axis limits c(0, 1). valid arguments pROC::roc() now utilized, including passed pROC::auc(). Documentation class probability metrics improved informative examples (@rudeboybert, #100).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"bug-fixes-0-0-4","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"yardstick 0.0.4","text":"mn_log_loss() now uses min/max rule computing log estimated probabilities avoid problematic undefined log values (#103). pr_curve() now places 1 first precision value, rather NA. NA technically correct precision undefined , 1 practically correct generates correct PR Curve graph , importantly, allows pr_auc() compute correct AUC. pr_curve() generate wrong results somewhat rare case two class probability estimates , different truth values. pr_curve() (subsequently pr_auc()) now generates correct curve duplicate class probability values (reported @dariyasydykova, #93). Binary mcc() now avoids integer overflow confusion matrix elements large (#108).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-003","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.3","title":"yardstick 0.0.3","text":"CRAN release: 2019-03-08","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"new-metrics-and-functionality-0-0-3","dir":"Changelog","previous_headings":"","what":"New metrics and functionality","title":"yardstick 0.0.3","text":"mase() numeric metric mean absolute scaled error. generally useful forecasting time series (@alexhallam, #68). huber_loss() numeric metric less sensitive outliers rmse(), sensitive mae() small errors (@blairj09, #71). huber_loss_pseudo() smoothed form huber_loss() (@blairj09, #71). smape() numeric metric based percentage errors (@riazhedayati, #67). conf_mat objects now two ggplot2::autoplot() methods easy visualization confusion matrix either heat map mosaic plot (@EmilHvitfeldt, #10).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"other-improvements-0-0-3","dir":"Changelog","previous_headings":"","what":"Other improvements","title":"yardstick 0.0.3","text":"metric_set() now returns classed function. numeric metrics used, \"numeric_metric_set\" function returned. class probability metrics used, \"class_prob_metric_set\" returned.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"bug-fixes-0-0-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"yardstick 0.0.3","text":"Tests related fixed R 3.6 sample() function fixed. f_meas() propagates NA values precision() recall() correctly (#77). \"micro\" estimators now propagate NA values correctly. roc_auc(estimator = \"hand_till\") now correctly computes metric column names probability matrix exact levels truth. Note computation still assumes order supplied probability matrix columns still matches order levels(truth), like multiclass metrics (#86).","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-002","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.2","title":"yardstick 0.0.2","text":"CRAN release: 2018-11-05","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"breaking-changes-0-0-2","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"yardstick 0.0.2","text":"desire standardize yardstick API drove breaking changes. output metric now line tidy principles, returning tibble rather single numeric. Additionally, metrics now standard argument list able switch metrics combine together effortlessly. metrics now return tibble rather single numeric value. format allows metrics work grouped data frames (resamples). also allows bundle multiple metrics together new function, metric_set(). class probability metrics, now 1 column can passed ... binary implementation used. metrics longer select first column multiple columns supplied, instead throw error. summary() method conf_mat objects now returns tibble consistent change metric functions. naming consistency, mnLogLoss() renamed mn_log_loss() mn_log_loss() now returns negative log loss multinomial distribution. argument na.rm changed na_rm metrics align tidymodels model implementation principles.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"core-features-0-0-2","dir":"Changelog","previous_headings":"","what":"Core features","title":"yardstick 0.0.2","text":"metric now vector interface go alongside data frame interface. vector functions end _vec(). vector interface accepts vector/matrix inputs returns single numeric value. Multiclass support added classification metric. support varies one metric next, generally macro micro averaging available metrics, metrics specialized multiclass implementations (example, roc_auc() supports multiclass generalization presented paper Hand Till). information, see vignette(\"multiclass\", \"yardstick\"). metrics now work grouped data frames. produces tibble many rows groups, useful used alongside resampling techniques.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"new-metrics-and-functionality-0-0-2","dir":"Changelog","previous_headings":"","what":"New metrics and functionality","title":"yardstick 0.0.2","text":"mape() calculates mean absolute percent error. kap() metric similar accuracy() calculates Cohen‚Äôs kappa. detection_prevalence() calculates number predicted positive events relative total number predictions. bal_accuracy() calculates balanced accuracy average sensitivity specificity. roc_curve() calculates receiver operator curves returns results tibble. pr_curve() calculates precision recall curves. gain_curve() lift_curve() calculate information used gain lift curves. gain_capture() measure performance similar spirit AUC applied gain curve. pr_curve(), roc_curve(), gain_curve() lift_curve() ggplot2::autoplot() methods easy visualization. metric_set() constructs functions calculate multiple metrics .","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"other-improvements-0-0-2","dir":"Changelog","previous_headings":"","what":"Other improvements","title":"yardstick 0.0.2","text":"infrastructure creating metrics exposed allow users extend yardstick work metrics. might want want metrics work grouped data frames box, want standardization error checking yardstick already provides. See vignette(\"custom-metrics\", \"yardstick\") examples. vignette describing three classes metrics used yardstick added. also includes list every metric available, grouped class. See vignette(\"metric-types\", \"yardstick\"). error messages yardstick now much informative, better feedback types input metric can use kinds metrics can used together (.e.¬†metric_set()). now grouped_df method conf_mat() returns tibble list column conf_mat objects. metric now help page. allows us better document nuances metric without cluttering help pages metrics.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"dependencies-0-0-2","dir":"Changelog","previous_headings":"","what":"Dependencies","title":"yardstick 0.0.2","text":"broom removed Depends, replaced generics Suggests. tidyr ggplot2 moved Suggests. MLmetrics removed dependency.","code":""},{"path":"https://yardstick.tidymodels.org/dev/news/index.html","id":"yardstick-001","dir":"Changelog","previous_headings":"","what":"yardstick 0.0.1","title":"yardstick 0.0.1","text":"CRAN release: 2017-11-12 First CRAN release","code":""}]
